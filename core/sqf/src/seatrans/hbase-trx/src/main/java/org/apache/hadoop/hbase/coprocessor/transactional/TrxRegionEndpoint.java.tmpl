/**
* @@@ START COPYRIGHT @@@
*
* Licensed to the Apache Software Foundation (ASF) under one
* or more contributor license agreements.  See the NOTICE file
* distributed with this work for additional information
* regarding copyright ownership.  The ASF licenses this file
* to you under the Apache License, Version 2.0 (the
* "License"); you may not use this file except in compliance
* with the License.  You may obtain a copy of the License at
*
*   http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing,
* software distributed under the License is distributed on an
* "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
* KIND, either express or implied.  See the License for the
* specific language governing permissions and limitations
* under the License.
*
* @@@ END COPYRIGHT @@@
**/

package org.apache.hadoop.hbase.coprocessor.transactional;

import org.apache.commons.codec.binary.Hex;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.Coprocessor;
import org.apache.hadoop.hbase.CoprocessorEnvironment;
import org.apache.hadoop.hbase.coprocessor.ColumnInterpreter;
import org.apache.hadoop.hbase.coprocessor.CoprocessorService;
import org.apache.hadoop.hbase.coprocessor.transactional.lock.exception.LockTimeOutException;
import org.apache.hadoop.hbase.coprocessor.transactional.lock.exception.DeadLockException;
import org.apache.hadoop.hbase.coprocessor.transactional.lock.exception.LockNotEnoughResourcsException;
import org.apache.hadoop.hbase.coprocessor.transactional.lock.LockManager;
import org.apache.hadoop.hbase.coprocessor.transactional.server.RSServer;
import org.apache.hadoop.hbase.coprocessor.transactional.lock.LockMode;
import org.apache.hadoop.hbase.coprocessor.transactional.lock.message.LMLockInfoReqMessage;
import org.apache.hadoop.hbase.coprocessor.transactional.message.RSMessage;
import org.apache.hadoop.hbase.coprocessor.transactional.lock.LockConstants;
import org.apache.hadoop.hbase.coprocessor.transactional.server.RSConstants;
import org.apache.hadoop.hbase.coprocessor.transactional.lock.RowKey;
import org.apache.hadoop.hbase.coprocessor.transactional.lock.RetCode;
import java.io.*;
import java.io.IOException;
import java.lang.management.ManagementFactory;
import java.lang.management.MemoryMXBean;
import java.lang.StringBuilder;
import java.lang.Thread.UncaughtExceptionHandler;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.ListIterator;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.NavigableMap;
import java.util.Map.Entry;
import java.util.NavigableSet;
import java.util.Set;
import java.util.SortedMap;
import java.util.StringTokenizer;
import java.util.TreeMap;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentLinkedQueue;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantReadWriteLock;
import java.util.concurrent.TimeUnit;
import java.util.Date;
import java.text.SimpleDateFormat;

import org.apache.hadoop.hbase.ipc.CallerDisconnectedException;
import org.apache.hadoop.hbase.io.hfile.CacheConfig;
import org.apache.hadoop.hbase.io.hfile.HFile;
import org.apache.hadoop.hbase.io.hfile.HFileContext;
import org.apache.hadoop.hbase.io.hfile.HFileContextBuilder;
import org.apache.hadoop.hbase.io.hfile.HFileScanner;
import org.apache.hadoop.hbase.io.hfile.HFileWriterV2;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TransactionPersist;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TransactionStateMsg;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TransactionMutationMsg;
import org.apache.hadoop.hbase.pit.HBaseBinlog;

import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
#ifdef HDP2.3 HDP2.4 CDH5.5 CDH5.7 APACHE1.2 CDH5.16
import org.apache.hadoop.hbase.ChoreService;
import org.apache.hadoop.hbase.ScheduledChore;
#endif
import org.apache.hadoop.hbase.client.Delete;
import org.apache.hadoop.hbase.client.Durability;
import org.apache.hadoop.hbase.client.Get;
import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.client.Mutation;
import org.apache.hadoop.hbase.client.Scan;
import org.apache.hadoop.hbase.client.ScannerTimeoutException;
import org.apache.hadoop.hbase.client.Result;
import org.apache.hadoop.hbase.client.transactional.MemoryUsageException;
import org.apache.hadoop.hbase.client.transactional.OutOfOrderProtocolException;
import org.apache.hadoop.hbase.client.transactional.RegionShieldedException;
import org.apache.hadoop.hbase.client.transactional.UnknownTransactionException;
import org.apache.hadoop.hbase.client.transactional.BatchException;
import org.apache.hadoop.hbase.client.transactional.TransState;
import org.apache.hadoop.hbase.client.transactional.STRConfig;
import org.apache.hadoop.hbase.client.transactional.ATRConfig;
import org.apache.hadoop.hbase.client.transactional.PeerInfo;

import org.apache.hadoop.classification.InterfaceAudience;
import org.apache.hadoop.classification.InterfaceStability;
import org.apache.hadoop.hbase.Cell;
import org.apache.hadoop.hbase.CellUtil;
import org.apache.hadoop.hbase.HColumnDescriptor;
#ifdef HDP2.3 HDP2.4 CDH5.5 CDH5.7 APACHE1.2 CDH5.16 
import org.apache.hadoop.hbase.ChoreService;
import org.apache.hadoop.hbase.ScheduledChore;
#endif
import org.apache.hadoop.hbase.filter.FilterBase;
import org.apache.hadoop.hbase.filter.FilterList;
import org.apache.hadoop.hbase.KeyValueUtil;
import org.apache.hadoop.hbase.KeyValue;
import org.apache.hadoop.hbase.KeyValue.Type;
import org.apache.hadoop.hbase.Coprocessor;
import org.apache.hadoop.hbase.CoprocessorEnvironment;
import org.apache.hadoop.hbase.coprocessor.CoprocessorException;
import org.apache.hadoop.hbase.coprocessor.CoprocessorService;
import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;
import org.apache.hadoop.hbase.exceptions.OutOfOrderScannerNextException;
import org.apache.hadoop.hbase.filter.FirstKeyOnlyFilter;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.HBaseInterfaceAudience;
import org.apache.hadoop.hbase.HConstants;
import org.apache.hadoop.hbase.HRegionInfo;
import org.apache.hadoop.hbase.ServerName;
import org.apache.hadoop.hbase.Tag;
import org.apache.hadoop.hbase.regionserver.RegionServerServices;
import org.apache.hadoop.hbase.regionserver.StoreFileInfo;
import org.apache.hadoop.hbase.Stoppable;
import org.apache.hadoop.hbase.NotServingRegionException;
import org.apache.hadoop.hbase.UnknownScannerException;
import org.apache.hadoop.hbase.regionserver.HRegion;
import org.apache.hadoop.hbase.regionserver.InternalScanner;
import org.apache.hadoop.hbase.regionserver.KeyValueScanner;
import org.apache.hadoop.hbase.regionserver.LeaseException;
import org.apache.hadoop.hbase.regionserver.LeaseListener;
import org.apache.hadoop.hbase.regionserver.Leases;
import org.apache.hadoop.hbase.regionserver.Leases.LeaseStillHeldException;
import org.apache.hadoop.hbase.regionserver.OperationStatus;
import org.apache.hadoop.hbase.HConstants.OperationStatusCode;
//import org.apache.hadoop.hbase.regionserver.MultiVersionConsistencyControl;
#ifdef CDH5.7 APACHE1.2 CDH5.16
import org.apache.hadoop.hbase.regionserver.Region;
#endif
import org.apache.hadoop.hbase.regionserver.RegionScanner;
import org.apache.hadoop.hbase.regionserver.WrongRegionException;
//import org.apache.hadoop.hbase.regionserver.wal.HLog;
import org.apache.hadoop.hbase.wal.WAL;
import org.apache.hadoop.hbase.wal.WALKey;
//import org.apache.hadoop.hbase.regionserver.wal.HLogUtil;
import org.apache.hadoop.hbase.regionserver.wal.WALEdit;
import org.apache.hadoop.hbase.regionserver.transactional.CleanOldTransactionsChore;
import org.apache.hadoop.hbase.regionserver.transactional.MemoryUsageChore;
import org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegion;
import org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionScannerHolder;
import org.apache.hadoop.hbase.regionserver.transactional.TransactionState;
import org.apache.hadoop.hbase.regionserver.transactional.TrxTransactionState;
import org.apache.hadoop.hbase.regionserver.transactional.TrxTransactionState.ScanRange;
import org.apache.hadoop.hbase.regionserver.transactional.TrxTransactionState.WriteAction;
import org.apache.hadoop.hbase.regionserver.transactional.TrxTransactionState.SavepointState;
import org.apache.hadoop.hbase.regionserver.transactional.TrxTransactionState.SavepointOp;
import org.apache.hadoop.hbase.regionserver.transactional.TransactionState.CommitProgress;
import org.apache.hadoop.hbase.regionserver.transactional.TransactionState.Status;
import org.apache.hadoop.hbase.util.Bytes;
import org.apache.hadoop.hbase.util.FSUtils;
import org.apache.hadoop.hbase.util.Threads;
import org.apache.hadoop.hbase.protobuf.ProtobufUtil;
import org.apache.hadoop.hbase.protobuf.ResponseConverter;
import org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto;
import org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.MutationType;
import org.apache.hadoop.hbase.coprocessor.transactional.TrxRegionObserver;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.AbortSavepointRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.AbortSavepointResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.AbortTransactionRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.GeneralBinlogCommandRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.GeneralBinlogCommandResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.AbortTransactionResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.BeginTransactionRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.BeginTransactionResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.BroadcastRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.BroadcastResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.ImportLaunchRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.ImportLaunchResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.ImportStatusRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.ImportStatusResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CloseScannerRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CloseScannerResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CommitSavepointRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CommitSavepointResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CommitRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CommitResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CommitIfPossibleRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CommitIfPossibleResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CommitRequestRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CommitRequestResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CheckAndDeleteRegionTxRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CheckAndDeleteRegionTxResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CheckAndDeleteRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CheckAndDeleteResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CheckAndPutRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CheckAndPutResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CheckAndPutRegionTxRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CheckAndPutRegionTxResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.DeleteMultipleTransactionalRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.DeleteMultipleTransactionalResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.DeleteMultipleNonTransactionalRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.DeleteMultipleNonTransactionalResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.DeleteRegionTxRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.DeleteRegionTxResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.DeleteTransactionalRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.DeleteTransactionalResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.GetTransactionalRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.GetTransactionalResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.GetMultipleTransactionalRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.GetMultipleTransactionalResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.LockRequiredRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.LockRequiredResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.ReleaseLockRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.ReleaseLockResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.PerformScanRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.PerformScanResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.OpenScannerRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.OpenScannerResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.PutRegionTxRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.PutRegionTxResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.PutTransactionalRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.PutTransactionalResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.PutMultipleTransactionalRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.PutMultipleTransactionalResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.PutMultipleNonTransactionalRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.PutMultipleNonTransactionalResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.PushEpochRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.PushEpochResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.RecoveryRequestRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.RecoveryRequestResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TlogDeleteRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TlogDeleteResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TlogTransactionStatesFromIntervalRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TlogTransactionStatesFromIntervalResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TlogWriteRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TlogWriteResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TrafEstimateRowCountRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TrafEstimateRowCountResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TransactionalAggregateRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TransactionalAggregateResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TrafSetStoragePolicyResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TrafSetStoragePolicyRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TrxRegionService;
#ifdef CDH5.7 APACHE1.2 CDH5.16
import org.apache.hadoop.hbase.regionserver.MultiVersionConcurrencyControl;
#endif
import org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher;
import org.apache.hadoop.hbase.zookeeper.ZKUtil;
import org.apache.hadoop.hbase.ZooKeeperConnectionException;
import org.apache.zookeeper.KeeperException;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.AbortTransactionMultipleRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.AbortTransactionMultipleResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CommitMultipleRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CommitMultipleResponse;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CommitRequestMultipleRequest;
import org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CommitRequestMultipleResponse;

import org.apache.hadoop.hbase.regionserver.transactional.IdTm;
import org.apache.hadoop.hbase.regionserver.transactional.IdTmId;

import com.google.protobuf.ByteString;
import com.google.protobuf.Message;
import com.google.protobuf.RpcCallback;
import com.google.protobuf.RpcController;
import com.google.protobuf.Service;

import org.apache.hadoop.hbase.pit.MutationCapture2;
import org.apache.hadoop.hbase.pit.MutationCapture;
import org.apache.hadoop.hbase.pit.LobMeta;
import org.apache.hadoop.hbase.pit.MutationMeta;
import org.apache.hadoop.hbase.pit.MutationMetaRecord;
import org.apache.hadoop.hbase.pit.SnapshotMeta;
import org.apache.hadoop.hbase.pit.SnapshotImportJob;
import java.lang.reflect.InvocationTargetException;
import java.lang.reflect.Method;

import org.apache.hadoop.hbase.util.ByteArrayKey;
import org.apache.hadoop.hbase.util.TrxEnvironmentEdgeManager;


@InterfaceAudience.LimitedPrivate(HBaseInterfaceAudience.COPROC)
@InterfaceStability.Evolving
public class TrxRegionEndpoint<T, S, P extends Message, Q extends Message, R extends Message> extends TrxRegionService implements
CoprocessorService, Coprocessor {

  private static final Log LOG = LogFactory.getLog(TrxRegionEndpoint.class);

  private static final String REGION_NAME_MISMATCH_EXCEPTION = "RegionNameMismatchException";

  private static ConcurrentLinkedQueue<EndpointCostStats> ecsQueue = new ConcurrentLinkedQueue<>();

  private LockManager lockManager = null;

  private static RSServer rsServer = null;

  //private ReentrantReadWriteLock rwLock = new ReentrantReadWriteLock();

  private static int lockTimeOut = 3000; // default lock time out 3s

  private static int forUpdLockTimeOut = 3;

  private static int maxForUpdLockCheckTime = 10;
  
  private static int maxTmpWriterLockSize = 10000;

  private static int commitUseBatchMutateNum = 0;

  private static int putBatchMutateNum = 0;

  private static Boolean enableTmpWriterLock = false;

  private static Boolean enableTmpReadWriterLock = false;

  private static Boolean enableUseWaitQueue = true;  //use wait queue by default

  private boolean noConflictCheckForIndex = false; 

  private long MAX_TMP_WRITE_LOCK_LIVE_TIME = 10000;   //10s

  private static int maxForUpdateScanLockRetryTimes = 60*1000; 

  private static final char[] HEX_CHAR = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F'};

  static RegionServerStoppable regionServerStopper = new RegionServerStoppable();

  private static final int SINGLE_ROW_SCAN = 0, FULL_TABLE_SCAN = 1, RANGE_SCAN = 2;
  //for log to OM
  private static final String HBASE_LOG_DIR = "hbase.log.dir";

  private static final int READUNCOMMITTED = 0, READCOMMITTED = 1, REPEATEABLEREAD = 2, SERIALIZABLE = 3;
  private static final int SEL_ROW_LOCK = 0, SEL_TAB_LOCK = 1, SEL_UPD_ROW_LOCK = 2, SEL_UPD_TAB_LOCK = 3, DML_LOCK = 4, SEL_META_ROW_LOCK = 5, SEL_META_TAB_LOCK = 6, DML_META_TAB_LOCK = 7;
  private static final int BEGIN_LOG_MARK = 0x1, COMMIT_LOG_MARK = 0x2, ABORT_LOG_MARK = 0x4, COMMIT_SAVEPOINT_LOG_MARK = 0x8, ABORT_SAVEPOINT_LOG_MARK = 0x10, COMMIT_MEMORY_CHECK_LOG_MARK = 0x20;

  public static int[][] lockMapping = {
      /* Select row,      Select table,      Select update row, Select update table, DML,              SEL_META_ROW_LOCK, SEL_META_TAB_LOCK DML_META_TAB_LOCK*/
      {LockMode.LOCK_NO,  LockMode.LOCK_NO,  LockMode.LOCK_NO,  LockMode.LOCK_NO,    LockMode.LOCK_NO, LockMode.LOCK_NO,  LockMode.LOCK_NO, LockMode.LOCK_NO},    // read uncommitted
      {LockMode.LOCK_NO,  LockMode.LOCK_IS,  LockMode.LOCK_U,   LockMode.LOCK_X,     LockMode.LOCK_X,  LockMode.LOCK_NO,  LockMode.LOCK_IS, LockMode.LOCK_IX},     // read committed
      {LockMode.LOCK_S,   LockMode.LOCK_S,   LockMode.LOCK_U,   LockMode.LOCK_X,     LockMode.LOCK_X,  LockMode.LOCK_NO,  LockMode.LOCK_IS, LockMode.LOCK_IX},     // repeateable read
      {LockMode.LOCK_S,   LockMode.LOCK_S,   LockMode.LOCK_U,   LockMode.LOCK_X,     LockMode.LOCK_X,  LockMode.LOCK_NO,  LockMode.LOCK_IS, LockMode.LOCK_IX}};    // serializable not support


  // TBD Maybe we should just use HashMap to improve the performance, ConcurrentHashMap could be too strict
  static ConcurrentHashMap<String, TrxRegionEndpoint> transactionsEPCPMap;

  static String getNotEmptyEnvVar(String envName) {
      String envVar = System.getenv(envName);
      if (envVar != null) {
          envVar = envVar.trim();
          return !envVar.isEmpty() ? envVar : null;
      }
      return null;
  }

  static {
      String envPrintTransactionLog = getNotEmptyEnvVar("PRINT_TRANSACTION_LOG");
      if (envPrintTransactionLog != null)
          RSConstants.PRINT_TRANSACTION_LOG = Integer.parseInt(envPrintTransactionLog.trim());

      String envLockTimeOut = getNotEmptyEnvVar("LOCK_TIME_OUT");
      if (envLockTimeOut != null)
          lockTimeOut = Integer.parseInt(envLockTimeOut.trim());
          
      String envForUpdLockTimeOut = getNotEmptyEnvVar("FOR_UPDATE_LOCK_TIME_OUT");
      if (envForUpdLockTimeOut != null)
          forUpdLockTimeOut = Integer.parseInt(envForUpdLockTimeOut.trim());

      String envForUpdLockCheckTime = getNotEmptyEnvVar("FOR_UPDATE_LOCK_CHECK_TIMES");
      if (envForUpdLockCheckTime != null)
          maxForUpdLockCheckTime = Integer.parseInt(envForUpdLockCheckTime.trim());

      String ennTmpWriterLockMaxSize = getNotEmptyEnvVar("MAX_TMP_WRITER_LOCK_SIZE");
      if (ennTmpWriterLockMaxSize != null)
          maxTmpWriterLockSize = Integer.parseInt(ennTmpWriterLockMaxSize.trim());

      String envMaxForUpdateScanLockRetryTime = getNotEmptyEnvVar("MAX_TMP_SCAN_LOCK_RETRY_TIMES");
      if (envMaxForUpdateScanLockRetryTime!= null)
          maxForUpdateScanLockRetryTimes= Integer.parseInt(envMaxForUpdateScanLockRetryTime.trim());
		  
      String envEnableTmpWriterLock = getNotEmptyEnvVar("ENABLE_TMP_WRITER_LOCK");
      if (envEnableTmpWriterLock!= null)
          enableTmpWriterLock= (Integer.parseInt(envEnableTmpWriterLock.trim()) == 0) ? false : true;
		  
      String envEnableTmpReadWriterLock = getNotEmptyEnvVar("ENABLE_TMP_READ_WRITER_LOCK");
      if (envEnableTmpReadWriterLock!= null)
          enableTmpReadWriterLock= (Integer.parseInt(envEnableTmpReadWriterLock.trim()) == 0) ? false : true;

      String envEnableLockForSelect = getNotEmptyEnvVar("ENABLE_LOCK_FOR_SELECT");
      if (envEnableLockForSelect != null) {
          try {
              LockConstants.ENABLE_LOCK_FOR_SELECT = (Integer.parseInt(envEnableLockForSelect.trim()) == 0) ? false : true;
          } catch (Exception e) {
              LOG.error("value of ENABLE_LOCK_FOR_SELECT is illegal " + envEnableLockForSelect);
          }
      }

      if (LockConstants.ENABLE_LOCK_FOR_SELECT) {
          lockMapping[READCOMMITTED][SEL_ROW_LOCK] = LockMode.LOCK_S;
          lockMapping[READCOMMITTED][SEL_TAB_LOCK] = LockMode.LOCK_S;
      }

      String envUseWaitQueue = getNotEmptyEnvVar("USE_WAIT_QUEUE_FORUPDATE");
      if (envUseWaitQueue!= null)
          enableUseWaitQueue= (Integer.parseInt(envUseWaitQueue.trim()) == 0) ? false : true;

      String costThreshold = getNotEmptyEnvVar("RECORD_TIME_COST_COPRO");
      if (costThreshold != null && false == costThreshold.trim().isEmpty())
          RSConstants.RECORD_TIME_COST_COPRO = Integer.parseInt(costThreshold);

      String envRecordScanRowThreshold = getNotEmptyEnvVar("RECORD_SCAN_ROW_THRESHOLD");
      if (envRecordScanRowThreshold != null)
          RSConstants.RECORD_SCAN_ROW_THRESHOLD = Integer.parseInt(envRecordScanRowThreshold);

      String evnMaxBlockCheckRetryTimes = getNotEmptyEnvVar("MAX_BLOCK_CHECK_RETRY_TIMES");
      if (evnMaxBlockCheckRetryTimes != null)
          RSConstants.MAX_BLOCK_CHECK_RETRY_TIMES = Integer.parseInt(evnMaxBlockCheckRetryTimes);

      String envCommitUseBatchMutate = System.getenv("NUMBER_COMMIT_USE_BATCHMUTATE");
      if (envCommitUseBatchMutate != null)
          commitUseBatchMutateNum = Integer.parseInt(envCommitUseBatchMutate.trim());

      if (transactionsEPCPMap == null) {
          transactionsEPCPMap = new ConcurrentHashMap<String, TrxRegionEndpoint>();
      }

      String envPutBatch = System.getenv("NUMBER_PUT_BATCH");
      if (envPutBatch != null)
         putBatchMutateNum = Integer.parseInt(envPutBatch.trim());
	  String envDisableNewObjectForEndpoint = getNotEmptyEnvVar("DISABLE_NEWOBJECT_FOR_ENDPOINT");
	  if (envDisableNewObjectForEndpoint != null)
	  	  RSConstants.DISABLE_NEWOBJECT_FOR_ENDPOINT = Integer.parseInt(envDisableNewObjectForEndpoint);
  }

  private RegionCoprocessorEnvironment env;

  protected Map<Long, Long> transactionsByIdTest = null;
  ConcurrentHashMap<String, Object> transactionsByIdTestz = null;

  // Collection of active transactions (PENDING) keyed by id.
  protected ConcurrentHashMap<Long, TrxTransactionState> transactionsById = new ConcurrentHashMap<Long, TrxTransactionState>();

  protected ConcurrentHashMap<ByteArrayKey, Long> selectForUpdateLockHashmap = new ConcurrentHashMap<ByteArrayKey, Long>();
  protected ConcurrentHashMap<Long , Long> binlogWidMap = new ConcurrentHashMap<Long , Long>();
  protected ConcurrentHashMap<ByteArrayKey, List<Long>> selectForUpdateLockWaitQueue= new ConcurrentHashMap<ByteArrayKey, List<Long>>();
  protected ConcurrentHashMap<ByteArrayKey, Long> prevSelectForUpdateLockHashmap = new ConcurrentHashMap<ByteArrayKey, Long>();
  protected ConcurrentHashMap<Long, Integer> longTransHavingLocks = new ConcurrentHashMap< Long, Integer>();

  //this is to hold all write row level lock
  protected ConcurrentHashMap<ByteArrayKey, trafLockInfo> tmpWriteLockHashmap = new ConcurrentHashMap<ByteArrayKey, trafLockInfo>();
  protected ConcurrentHashMap<Long, Long> tmpRangeLockTime= new ConcurrentHashMap<Long, Long>();
  protected Set<trafLockInfo> tmpRangeLock =  Collections.synchronizedSet(new HashSet<trafLockInfo>());

  // Map of recent transactions that are COMMIT_PENDING or COMMITED keyed 
  // by their sequence number

  private SortedMap<Long, TrxTransactionState> commitedTransactionsBySequenceNumber = Collections.synchronizedSortedMap(new TreeMap<Long, TrxTransactionState>());

  // Collection of transactions that are COMMIT_PENDING
  private Set<TrxTransactionState> commitPendingTransactions = Collections.synchronizedSet(new HashSet<TrxTransactionState>());
  private Set<TrxTransactionState> drainCPL = new HashSet<TrxTransactionState>();
  private boolean drainMC2Request = false;

  // an in-doubt transaction list during recovery WALEdit replay
  private Map<Long, List<WALEdit>> indoubtTransactionsById = new TreeMap<Long, List<WALEdit>>();

  // list of transactions to check for stale scanners
     private List<Long> cleanScannersForTransactions = Collections.synchronizedList(new LinkedList<Long>());

  // list of transactions to check for long running transactions with leases expired
     private List<Long> longRunningTransactions = Collections.synchronizedList(new LinkedList<Long>());     
     
  // an in-doubt transaction list count by TM id
  private Map<Integer, Integer> indoubtTransactionsCountByTmid = new TreeMap<Integer,Integer>();

  // Concurrent map for transactional region scanner holders
  // Protected by synchronized methods
  private ConcurrentHashMap<Long,
                          TransactionalRegionScannerHolder> scanners =
      new ConcurrentHashMap<Long, TransactionalRegionScannerHolder>();

  //import backup jobs
  protected ConcurrentHashMap<String, SnapshotImportJob> importJobs = new ConcurrentHashMap<String, SnapshotImportJob>();
  
  // Atomic values to manage region scanners
  private AtomicLong performScannerId = new AtomicLong(0);
  private AtomicLong nextSequenceId = new AtomicLong(0);
  
  private AtomicLong totalCheckAndDeleteRegionTx = new AtomicLong(0);
  private AtomicLong totalCheckAndPutRegionTx = new AtomicLong(0);  
  private AtomicLong totalDeleteRegionTx = new AtomicLong(0);
  private AtomicLong totalPutRegionTx = new AtomicLong(0);

  private static volatile AtomicLong nextRegionTxId = new AtomicLong(0);
  private Object commitCheckLock = new Object();
  private Object recoveryCheckLock = new Object();
  private Object editReplay = new Object();
  private static Object stoppableLock = new Object();
  private int reconstructIndoubts = 0; 
  //temporary THLog getSequenceNumber() replacement
  private AtomicLong nextLogSequenceId = new AtomicLong(0);
  public AtomicLong controlPointEpoch = new AtomicLong(1);
  static Leases transactionLeases = null;
  CleanOldTransactionsChore cleanOldTransactionsThread;
  static MemoryUsageChore memoryUsageThread = null;
  static long choreFlush = 0;
  Stoppable stoppable = new StoppableImplementation();
  private int cleanTimer = 10000;  // 10 secs overriden by DEFAULT_SLEEP
  private int memoryUsageTimer = 60000; // One minute   
  private AtomicInteger regionState = new AtomicInteger(REGION_STATE_REPLAY); 
  private Path recoveryTrxPath = null;
  private long onlineEpoch = TrxEnvironmentEdgeManager.currentTime();
  private long maxWriteLockFreeTs = 0L;
  
  //Object bufferPh2HLOGWrite = new Object();
  int txnCountPh2HLOG = 0;
  int maxTxnPh2HLOG = 1;
  //boolean toWritePh2HLOG = false;
  //byte [][] txnListTidPh2HLOG = new byte [maxTxnPh2HLOG][];
  //byte [][] txnListCidPh2HLOG = new byte [maxTxnPh2HLOG][];
  //byte [][] txnListMClientPh2HLOG = new byte [maxTxnPh2HLOG][];
  //Cell cellPh2HLOG = null;
  //ByteArrayOutputStream outputPh2HLOGStream = null;
  //ByteArrayOutputStream bufferCommitTxnStream = null;
  public static final byte TS_TRAFODION_TXN_TAG_TYPE = 41;
  public static final byte TS_TRAFODION_BINLOG_TAG_TYPE = 42;
  public static final byte TS_TRAFODION_ISUPSERT_TAG_TYPE = 43;
  
  private long[] commitCheckTimes   = new long[50];
  private long[] hasConflictTimes   = new long[50];
  private long[] putBySequenceTimes = new long[50];
  private long[] writeToLogTimes    = new long[50];

  private AtomicInteger  timeIndex               =    new AtomicInteger (0);
  private AtomicInteger  totalCommits            =    new AtomicInteger (0);
  private AtomicInteger  writeToLogOperations    =    new AtomicInteger (0);
  private AtomicInteger  putBySequenceOperations =    new AtomicInteger (0);
  private long   totalCommitCheckTime =    0;
  private long   totalConflictTime    =    0;
  private long   totalPutTime         =    0;
  private long   totalWriteToLogTime  =    0;
  private long   minCommitCheckTime   =    1000000000;
  private long   maxCommitCheckTime   =    0;
  private double avgCommitCheckTime   =    0;
  private long   minConflictTime      =    1000000000;
  private long   maxConflictTime      =    0;
  private double avgConflictTime      =    0;
  private long   minPutTime           =    1000000000;
  private long   maxPutTime           =    0;
  private double avgPutTime           =    0;
  private long   minWriteToLogTime    =    1000000000;
  private long   maxWriteToLogTime    =    0;
  private double avgWriteToLogTime    =    0;

  public static final int PIT_MAX_TXN_MUTATION_PER_KV = 2;
  public static final int PIT_MAX_TXN_MUTATION_PER_FILE = 5;

  public static final int MUTATION_CLIENT_PIT = 1;
  public static final int MUTATION_CLIENT_XDC = 2;
  public static final int MUTATION_CLIENT_IBR = 3;

  public static final int MAX_TIME_FOR_UPD_LOCK_EXPIRE = 10;

  public static final int GENERIC_SHIELD = 1;
  public static final int GENERIC_FLUSH_MUTATION_FILES = 2;
  public static final int GENERIC_RECOVERY_COMPLETE = 3;
  public static final int GENERIC_DEFER_SPLIT = 4;
  public static final int GENERIC_BLOCK_PHASE1 = 5;
  public static final int GENERIC_UNBLOCK_PHASE1 = 6;

  private static final int GENERIC_OK = 0;
  private static final int GENERIC_WAIT = 1;
  private static final int GENERIC_ERROR = -1;

  private HRegionInfo regionInfo = null;
#ifdef CDH5.7 APACHE1.2 CDH5.16
  private Region m_Region = null;
#else
  private HRegion m_Region = null;
#endif
  private String m_regionName = null;
  private String m_regionEncodedName = null;
  private String m_regionDetails = null;
  private boolean m_isTrafodionMetadata = false;
  private boolean m_isTrafodionStatTable = false;
  private boolean m_isTrafodionBRTable = false;
  private boolean m_detailedLogging = false;
#ifdef CDH5.7 APACHE1.2 CDH5.16
  private HRegion t_Region = null;
#else
  private TransactionalRegion t_Region = null;
#endif
  private FileSystem fs = null;
  private WAL tHLog = null;
  private AtomicBoolean closing = new AtomicBoolean(false);
  private AtomicBoolean onlineBalance = new AtomicBoolean(false);
  private AtomicBoolean blockAll = new AtomicBoolean(false);
  private AtomicBoolean blockPhase1 = new AtomicBoolean(false);
  private AtomicBoolean blockNonPhase2 = new AtomicBoolean(false);
  private AtomicBoolean blockNewTrans = new AtomicBoolean(false);
  private AtomicBoolean deferRegionSplit = new AtomicBoolean(false);
  private boolean configuredEarlyLogging = false;
  private boolean configuredConflictReinstate = false;
  private boolean configuredPITRecovery = false;
  private boolean configuredPITRecoveryHA = false;
  private boolean shieldFromRemote = false;
  private boolean readDefaultShieldFromZK = true;
  private int PIT_max_txn_mutation_per_KV = 10; // many KV in file, each one has 10 txn, no impact on file size
  private int PIT_max_txn_mutation_per_FILE = 10000; // 10K transaction branch
  private long PIT_max_size_mutation_per_FILE = 128000000; // 128 MB size
  private static Object zkRecoveryCheckLock = new Object();
  //private static Object choreDetectStaleBranchLock = new Object();
  private Object choreDetectStaleBranchLock = new Object(); // should let chores run concurrently
  private static ZooKeeperWatcher zkw1 = null;
  static Object choreFlushLock = new Object();
  String lv_hostName;
  int lv_port;
  private static String zNodePath = "/trafodion/recovery/";
  private static String zRecoveryLocal = "/local";
  private static final String COMMITTED_TXNS_KEY = "1_COMMITED_TXNS_KEY";
  private static final String TXNS_BY_ID_KEY = "2_TXNS_BY_ID_KEY";
  private HFileContext context = new HFileContextBuilder().withIncludesTags(false).build();

  private static final int DEFAULT_LEASE_TIME = 7200 * 1000 ;
  private static final int MINIMUM_LEASE_TIME = 60 * 1000;
  private static final int LEASE_CHECK_FREQUENCY = 1000;
  private static final int DEFAULT_SLEEP = 10 * 1000; // 10 seconds
  private static final int DEFAULT_MEMORY_THRESHOLD = 100; // 100% memory used
  private static final int DEFAULT_STARTUP_MEMORY_THRESHOLD = 90; // initial value : 90% memory used
  private static final int DEFAULT_MEMORY_SLEEP = 15 * 1000;
  private static final boolean DEFAULT_MEMORY_WARN_ONLY = true;        
  private static final boolean DEFAULT_MEMORY_PERFORM_GC = false;
  private static final int DEFAULT_ASYNC_WAL = 1;
  private static final boolean DEFAULT_SKIP_WAL = false;
  private static final boolean DEFAULT_COMMIT_EDIT = false;
  private static final boolean DEFAULT_XDC_SHIELDZKW = true;
  private static final boolean DEFAULT_SUPPRESS_OOP = false;
  private static final boolean DEFAULT_TM_USE_COMMIT_ID_IN_CELLS = false;
  private static final String SLEEP_CONF = "hbase.transaction.clean.sleep";
  private static final String LEASE_CONF  = "hbase.transaction.lease.timeout";
  private static final String MEMORY_THRESHOLD = "hbase.transaction.memory.threshold";
  private static final String MEMORY_WARN_ONLY = "hbase.transaction.memory.warn.only";
  private static final String MEMORY_CONF = "hbase.transaction.memory.sleep";
  private static final String MEMORY_PERFORM_GC = "hbase.transaction.memory.perform.GC";
  private static final String CONF_ASYNC_WAL  = "hbase.trafodion.async.wal";
  private static final String CONF_SKIP_WAL  = "hbase.trafodion.skip.wal";
  private static final String CONF_COMMIT_EDIT  = "hbase.trafodion.full.commit.edit";
  private static final String XDC_SHIELD_FROM_ZKW  = "hbase.transaction.xdc.shieldzkw";
  private static final String SUPPRESS_OOP = "hbase.transaction.suppress.OOP.exception";
//  private static final String CHECK_ROW = "hbase.transaction.check.row";
  private static final String CONF_TM_USE_COMMIT_ID_IN_CELLS = "hbase.transaction.use.commitId";
  // The following can trigger detailed logging on a specific table
  private static final String DETAILED_LOGGING_STRING = "hbase.transaction.detailed.logging.string";
  protected static int hbaseRpcTimeout = 6000;
  protected static int transactionLeaseTimeout = 0;
  private static int scannerLeaseTimeoutPeriod = 0;
  private static int scannerThreadWakeFrequency = 0;
  private static int memoryUsageThreshold = DEFAULT_MEMORY_THRESHOLD;
  private static boolean memoryUsagePerformGC = DEFAULT_MEMORY_PERFORM_GC;
  private static boolean memoryUsageWarnOnly = DEFAULT_MEMORY_WARN_ONLY;
  private static int asyncWal = DEFAULT_ASYNC_WAL;
  private static boolean skipWal = DEFAULT_SKIP_WAL;
  private static boolean fullEditInCommit = DEFAULT_COMMIT_EDIT;
  private static boolean useCommitIdInCells = DEFAULT_TM_USE_COMMIT_ID_IN_CELLS;
  private static boolean shieldZKW = DEFAULT_XDC_SHIELDZKW;
  private static MemoryMXBean memoryBean = null;
  private static float memoryPercentage = 0;
  private static boolean memoryThrottle = false;
  private static boolean suppressOutOfOrderProtocolException = DEFAULT_SUPPRESS_OOP;
  private Configuration config;

  private static final int BINLOG_CMD_WID_FLUSHED = 1;

//  private static boolean checkRowBelongs = true;

  public static  int regionTxnOptimization  = 5;
  private int txnStatisticsCollection = 0;

  // Transaction state defines
  private static final int COMMIT_OK = 1;
  private static final int COMMIT_OK_READ_ONLY = 2;
  private static final int COMMIT_UNSUCCESSFUL_FROM_COPROCESSOR = 3;
  private static final int COMMIT_CONFLICT = 5;
  private static final int COMMIT_RESEND = 6;
  private static final int COMMIT_SHIELDED = 7;
  private static final int COMMIT_DOOMED = 8;
  private static final int PREPARE_REFRESH = 9;
  private static final int EPOCH_VIOLATION = 13;

  private static final int MAX_COMMIT_PENDING_WAITS = 0;
  private Thread ChoreThread = null;
  private static Thread ChoreThread2 = null;
  //private static Thread ScannerLeasesThread = null;
  private static Thread TransactionalLeasesThread = null;

  public static final int TS_ACTIVE = 0;
  public static final int TS_COMMIT_REQUEST = 1;
  public static final int TS_COMMIT = 2;
  public static final int TS_ABORT = 3;
  public static final int TS_CONTROL_POINT_COMMIT = 4;
  public static final int TS_REGION_TX_ACTIVE = 5;
  public static final int TS_REGION_TX_COMMIT_REQUEST = 6;
  public static final int TS_REGION_TX_COMMIT = 7;
  public static final int TS_GROUP_COMMIT = 8;
  
  public static final int TIMELINE  = 512;      // 1000000000   

  public static final int REGION_STATE_REPLAY = 0;
  public static final int REGION_STATE_RECOVERING = 1;
  public static final int REGION_STATE_START = 2;

  private static Method hdfsSetStoragePolicyMethod = null;
  private static String hdfsSetStoragePolicyReflectErrorMsg = "";
  
  static final long NULL_SAVEPOINT = -1;
  /*static final int NULL_SVPT_STATE = -1;
  static final int ACTIVE_SVPT_STATE = 0;
  static final int COMMIT_SVPT_STATE = 1;
  static final int ABORT_SVPT_STATE = 2;
  
  static final int NULL_SVPT_OP = -1;
  static final int DML_SVPT_OP = 0;
  static final int COMMIT_SVPT_OP = 1;
  static final int ABORT_SVPT_OP = 2;
*/
  static final int OK_SVPT_ERROR = 0;
  static final int LATE_CHECKIN_SVPT_ERROR = -2;
  static final int COMMIT_INCONSISTENT_SVPT_ERROR = -3; 
  static final int ABORT_INCONSISTENT_SVPT_ERROR = -4; 
  static final int INVALID_OP_SVPT_ERROR = -5;
  static final int INIT_SVPT_ERROR = -99;
  static final int DUP_COMMIT_SVPT_ERROR = 1;
  static final int DUP_ABORT_SVPT_ERROR = 2;
  static final int COMMIT_NOTFOUND_SVPT_ERROR = 3;
  static final int ABORT_NOTFOUND_SVPT_ERROR = 4;
    
  public static final String trxkeyEPCPinstance = "EPCPinstance";
  #ifdef HDP2.3 HDP2.4 CDH5.5 CDH5.7 APACHE1.2 CDH5.16
  static ChoreService s_ChoreService = null;
  #endif
  static int txnChoreServiceThreadPoolSize = 1;
  public static final int DEFAULT_TXN_CHORE_SERVICE_THREAD_POOL_SIZE=15;
  
  STRConfig pSTRConfig = null;
  // boolean skip = true;
  
  // PIT Mutation Capturer
  ByteArrayOutputStream mutationOutput;
  HFileWriterV2 mutationWriter = null;
  long mutationCount;
  long mutationTotalCount;
  long mutationTotalSize;
  long mutationSet;
  long currentFileKey = -1;
  long smallestCommitId = -1;
  Path currentPITPath;
  long currentSnapshotId = 0;
  boolean[] tmPrepareRefresh = new boolean[1024];
  
  static IdTmId timeId = null;
  static IdTm idServer = null;
  static final int ID_TM_SERVER_TIMEOUT = 1000;
  static MutationMeta meta = null;
  static SnapshotMeta snapMeta = null;
  MutationCapture mutationCapture;
  MutationCapture2 mutationCapture2;
  boolean useMC2 = true;
  int mutationFlushed = 0;
  long choreCount = 1;

  public static final int PIT_MUTATION_CREATE = 1;
  public static final int PIT_MUTATION_APPEND = 2;
  public static final int PIT_MUTATION_FLUSH = 3;
  public static final int PIT_MUTATION_CLOSE = 4;
  public static final int PIT_MUTATION_ROLLOVER = 5;
  public static final int PIT_MUTATION_CLOSE_STOP = 6;

  public static final int PIT_MUTATION_WRITER_CREATE = 11;
  public static final int PIT_MUTATION_WRITER_FLUSH = 12;
  public static final int PIT_MUTATION_WRITER_CLOSE = 13;
  public static final int PIT_MUTATION_WRITER_APPEND = 14;
  public static final int PIT_MUTATION_WRITER_CLOSE_STOP = 15;
 
  public static final int PIT2_MUTATION_WRITER_CREATE = 31;
  public static final int PIT2_MUTATION_WRITER_APPEND = 32;
  public static final int PIT2_MUTATION_WRITER_CLOSE = 33;
  public static final int PIT2_MUTATION_WRITER_METAUPDATE = 34;
  
   public static final int XDC_UP          = 1;   //         1
   public static final int XDC_DOWN        = 2;   //        10
   public static final int SYNCHRONIZED    = 4;   //       100
   public static final int SKIP_CONFLICT   = 8;   //      1000
   public static final int SKIP_REMOTE_CK  = 16;  //     10000
   public static final int INCREMENTALBR   = 32;  //    100000
   public static final int TABLE_ATTR_SET  = 64;  //   1000000
   public static final int SKIP_SDN_CDC    = 128; //  10000000
   public static final int PIT_ALL         = 256; // 100000000
  
   private static double[] costSum = new double[40];
   private static long[] callCount = new long[40];
   private static ConcurrentHashMap<Long, EndpointCostStats> transStatMap = new ConcurrentHashMap<Long, EndpointCostStats>();;
   private static final String newLine = System.getProperty("line.separator");
  // TrxRegionService methods
    
  @Override
  public void abortSavepoint(RpcController controller,
			       AbortSavepointRequest request,
			       RpcCallback<AbortSavepointResponse> done) {
// The default response seems redundant
//    AbortSavepointResponse response = AbortSavepointResponse.getDefaultInstance();

    long transactionId = request.getTransactionId();
    long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
    long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
    boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
    boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());
    boolean ignoreUnknownTransaction = request.getIgnoreUnknownTransactionException();
    String requestRegionName = request.getRegionName().toStringUtf8();
    if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & ABORT_SAVEPOINT_LOG_MARK) > 0) {
        LOG.info("abortSavepoint enter - txId " + transactionId +
        " savepointId " + savepointId + " implicit savepoint " + implicitSavepoint +
        ", request regionName " + requestRegionName +
        ", regionName " + m_regionDetails);
    }

    IOException ioe = null;
    UnknownTransactionException ute = null;
    long startTime = System.currentTimeMillis();

    int status = 0;

    // ignore region name check if requestRegionName is ""
    if (requestRegionName.length() == 0 || m_regionName.equals(requestRegionName)) {
      // Process in local memory
      int participant = request.getParticipantNum();
      try {
        abortSavepoint(transactionId, savepointId, ignoreUnknownTransaction);
      } catch (UnknownTransactionException u) {
        LOG.error("abortSavepoint - txId " + transactionId
              + " savepointId " + savepointId + " participant " + participant
              + ", Caught UnknownTransactionException after internal abortSavepoint call ", u);
        ute = u;
      } catch (IOException e) {
        LOG.error("abortSavepoint - txId " + transactionId + " savepointId " + savepointId
            + " participant " + participant + ", Caught IOException after internal abortSavepoint call ", e);
        ioe = e;
      }
    }
    else {
      // request RegionName and current RegionName does not equals, 
      // need to refresh region locations in TransactionManager
      status = PREPARE_REFRESH;
    }

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.AbortSavepointResponse.Builder abortSavepointResponseBuilder = AbortSavepointResponse.newBuilder();

    abortSavepointResponseBuilder.setHasException(false);

    if (ioe != null)
    {
      abortSavepointResponseBuilder.setHasException(true);
      abortSavepointResponseBuilder.setException(ioe.toString());
    }

    if (ute != null)
    {
      abortSavepointResponseBuilder.setHasException(true);
      abortSavepointResponseBuilder.setException(ute.toString());
    }

    abortSavepointResponseBuilder.setResult(status);

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, false);
      long timeCost = System.currentTimeMillis();
      abortSavepointResponseBuilder.setCoproSTime(startTime);
      abortSavepointResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[0] += timeCost;
      callCount[0]++;
      costStats.callCountPlus(1L);
      costStats.sumCostPlus(1L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
        if (LOG.isWarnEnabled()) {
            LOG.warn(m_regionName + " abortSavepoint txID " + transactionId + " CC " + callCount[0] + " ATC " + (costSum[0] / callCount[0]) + " TC " + timeCost);
        }
    }

    AbortSavepointResponse aresponse = abortSavepointResponseBuilder.build();
    done.run(aresponse);

    if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & ABORT_SAVEPOINT_LOG_MARK) > 0) {
        LOG.info("abortSavepoint exit - txId " + transactionId +
        " savepointId " + savepointId + " implicit savepoint " + implicitSavepoint +
        ", request regionName " + requestRegionName +
        ", regionName " + m_regionDetails +
        ", status " + status);
     }
  }

   @Override
  public void generalBinlogCommand(RpcController controller,
                             GeneralBinlogCommandRequest request,
                             RpcCallback<GeneralBinlogCommandResponse> done) {

    int commandId = request.getCommandId();
    long transactionId = request.getTransactionId();
    String args= request.getArgs().toStringUtf8();
    int seqnum = request.getSeqnum();
    String retmsg = "";
    int retcode = 0;

    if (LOG.isTraceEnabled()) LOG.trace("generalBinlogCommand - input args " + args
        + " command ID " + commandId+
        ", region " + m_regionDetails);

    try {
      if (mutationCapture2 == null) {
        mutationCapture2 = MutationCapture2.MC2_getInstance(this.config,
                              this.fs,
                              context,
                              regionInfo,
                              0, 1);
      }
    }
    catch(Exception e) {
      LOG.error("HBaseBinlog: cannot get MutationCapture instance");
      //return error
      commandId = -1; //bypass command handling
      retcode = -1;
    }
    //command handling
    switch(commandId) {
      case BINLOG_CMD_WID_FLUSHED:
        //parse args for this command
        //it should have wid only
        long widToCheck = -1;
        try {
          widToCheck = Long.parseLong(args);
        }
        catch (Exception e) {
          LOG.error("HBaseBinlog: perform command flush check get wrong wid " + args + " for tid " + transactionId);
          break;
        }

        //if we get same request more than 50 times, print debug info
        if(seqnum > 50 && seqnum % 10 == 0)
            if (LOG.isWarnEnabled()) {
                LOG.warn("HBaseBinlog: perform command flush check for wid " + widToCheck + " for tid " + transactionId);
            }

        retcode = mutationCapture2.isThisWidFlushed(widToCheck, transactionId) ;

        break;
      default:
        break;
    }

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.GeneralBinlogCommandResponse.Builder respb = GeneralBinlogCommandResponse.newBuilder();

    respb.setRetmsg(ByteString.copyFromUtf8(retmsg));
    respb.setRetcode(retcode);
    GeneralBinlogCommandResponse resp = respb.build();
    done.run(resp);
  }

  @Override
  public void abortTransaction(RpcController controller,
			       AbortTransactionRequest request,
			       RpcCallback<AbortTransactionResponse> done) {
// The default response seems redundant
//    AbortTransactionResponse response = AbortTransactionResponse.getDefaultInstance();

    long transactionId = request.getTransactionId();
    boolean dropTableRecorded = request.getDropTableRecorded();
    boolean ignoreUnknownTransaction = request.getIgnoreUnknownTransactionException();
    if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & ABORT_LOG_MARK) > 0) 
	    LOG.info("abortTransaction - txId " + transactionId +
             ", dropTableRecoded " + dropTableRecorded + ", regionName " + m_regionDetails);

    IOException ioe = null;
    UnknownTransactionException ute = null;
    long startTime = System.currentTimeMillis();

      // Process in local memory
      int participant = request.getParticipantNum();
      try {
        abortTransaction(transactionId, dropTableRecorded, ignoreUnknownTransaction);
      } catch (UnknownTransactionException u) {
         if (ignoreUnknownTransaction == true) {
            if (LOG.isInfoEnabled()) LOG.info("TrxRegionEndpoint coprocessor:abort - txId "
					    + transactionId
					    + " participant " + participant
					    + ", ignoring UnknownTransaction after internal abortTransaction call - "
					    + u.getMessage());
         }
         else {
            LOG.error("TrxRegionEndpoint coprocessor:abort - txId "
					    + transactionId 
					    + " participant " + participant
					    + ", Caught UnknownTransactionException after internal abortTransaction call - " 
					    + u.getMessage() + " " 
					    + stackTraceToString(u));
            ute = u;
         }
      } catch (IOException e) {
        LOG.error("TrxRegionEndpoint coprocessor:abort - txId " + transactionId + " participant " + participant
         + ", Caught IOException after internal abortTransaction call - ", e);
        ioe = e;
      }

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.AbortTransactionResponse.Builder abortTransactionResponseBuilder = AbortTransactionResponse.newBuilder();

    abortTransactionResponseBuilder.setHasException(false);

    if (ioe != null)
    {
      abortTransactionResponseBuilder.setHasException(true);
      abortTransactionResponseBuilder.setException(ioe.toString());
    }

    if (ute != null)
    {
      abortTransactionResponseBuilder.setHasException(true);
      abortTransactionResponseBuilder.setException(ute.toString());
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, true);
      long timeCost = System.currentTimeMillis();
      abortTransactionResponseBuilder.setCoproSTime(startTime);
      abortTransactionResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[1] += timeCost;
      callCount[1]++;
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " abortTransaction txID " + transactionId + " CC " + callCount[1] + " ATC " + (costSum[1] / callCount[1]) + " TC " + timeCost);
          }
      if (costStats != null) {
        costStats.callCountPlus(2L);
        costStats.sumCostPlus(2L, timeCost);
        costStats.printLog(transactionId);
        releaseEndpointCostStats(costStats);
      }
    }

    AbortTransactionResponse aresponse = abortTransactionResponseBuilder.build();
    done.run(aresponse);
  }

  @Override
  public void abortTransactionMultiple(RpcController controller,
                                AbortTransactionMultipleRequest request,
                                RpcCallback<AbortTransactionMultipleResponse> done) {
// The default response seems redundant
//    AbortTransactionMultipleResponse response = AbortTransactionMultipleResponse.getDefaultInstance();

    long transactionId = request.getTransactionId();
    int i = 0;
    int numOfRegion = request.getRegionNameCount();
    String requestRegionName;
    IOException ioe = null;
    UnknownTransactionException ute = null;
    Throwable t = null;
    long startTime = System.currentTimeMillis();

    if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & ABORT_LOG_MARK) > 0) 
	    LOG.info("abortMultiple - txId " + transactionId + " number of region is commitMultiple "
            + numOfRegion + ", master regionName " + m_regionName);

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.AbortTransactionMultipleResponse.Builder abortTransactionMultipleResponseBuilder = AbortTransactionMultipleResponse.newBuilder();
    abortTransactionMultipleResponseBuilder.setHasException(false);

    int participant = 0;
    while (i < numOfRegion) {
         requestRegionName = request.getRegionName(i).toStringUtf8();    
         abortTransactionMultipleResponseBuilder.addException(BatchException.EXCEPTION_OK.toString());
         try {
              participant = request.getParticipantNum();
              if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint abortMultiple begins for region " + requestRegionName);
              TrxRegionEndpoint regionEPCP = transactionsEPCPMap.get(requestRegionName+trxkeyEPCPinstance);
              if (regionEPCP == null) {
                 if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint abortMultiple region NOT FOUND in EPCP map " + requestRegionName);
                 abortTransactionMultipleResponseBuilder.setHasException(true);
                 abortTransactionMultipleResponseBuilder.setException(i, BatchException.EXCEPTION_REGIONNOTFOUND_ERR.toString());
              }
              else {
                 regionEPCP.abortTransaction(transactionId);
              }
              if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint abortMultiple ends");
             // abortTransaction(transactionId);
         } catch (UnknownTransactionException u) {
              LOG.error("TrxRegionEndpoint coprocessor:abort - txId " + transactionId + " participant " + participant + ", Caught UnknownTransactionException after internal abortTransaction call - " + u.getMessage() + " " + stackTraceToString(u));
              ute = u;
         } catch (IOException e) {
              LOG.error("TrxRegionEndpoint coprocessor:abort - txId " + transactionId + " participant " + participant
               + ", Caught IOException after internal abortTransaction call - ", e);
              ioe = e;
         }

         if (t != null)
         {
              abortTransactionMultipleResponseBuilder.setHasException(true);
              abortTransactionMultipleResponseBuilder.setException(i, t.toString());
         }

         if (ioe != null)
         {
              abortTransactionMultipleResponseBuilder.setHasException(true);
              abortTransactionMultipleResponseBuilder.setException(i, ioe.toString());
         }

         if (ute != null)
         {
              abortTransactionMultipleResponseBuilder.setHasException(true);
              abortTransactionMultipleResponseBuilder.setException(i, ute.toString());
         }

         i++; // move to next region 

    } // end of while-loop on all the regions in thecommitMultiple request

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, true);
      long timeCost = System.currentTimeMillis();
      abortTransactionMultipleResponseBuilder.setCoproSTime(startTime);
      abortTransactionMultipleResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[2] += timeCost;
      callCount[2]++;
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " abortTransactionMultiple txID " + transactionId + " CC " + callCount[2] + " ATC " + (costSum[2] / callCount[2]) + " TC " + timeCost);
          }
      if (costStats != null) {
        costStats.callCountPlus(3L);
        costStats.sumCostPlus(3L, timeCost);
        costStats.printLog(transactionId);
        releaseEndpointCostStats(costStats);
      }
    }

    AbortTransactionMultipleResponse aresponse = abortTransactionMultipleResponseBuilder.build();
    done.run(aresponse);
  }

  @Override
  public void beginTransaction(RpcController controller,
                                BeginTransactionRequest request,
      RpcCallback<BeginTransactionResponse> done) {
// The default response seems redundant
//    BeginTransactionResponse response = BeginTransactionResponse.getDefaultInstance();

    Throwable t = null;
    MemoryUsageException mue = null;
    long transactionId = request.getTransactionId();
    long startId = request.getStartId();
    long startTime = System.currentTimeMillis();

    if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & BEGIN_LOG_MARK) > 0) 
	    LOG.info("beginTransaction - txId "  + transactionId + ", regionName " + m_regionDetails);

    {
      if (memoryThrottle == true) {
        if(memoryUsageWarnOnly == true)  {
            if (LOG.isWarnEnabled()) {
                LOG.warn("beginTransaction - performing memoryPercentage " + memoryPercentage + ", warning memory usage exceeds indicated percentage");
            }
        }
        else {
          if (LOG.isTraceEnabled()) LOG.trace("beginTransaction - performing memoryPercentage " + memoryPercentage + ", generating memory usage exceeds indicated percentage");
          mue = new MemoryUsageException("beginTransaction memory usage exceeds " + memoryUsageThreshold + " percent, trxId is " + transactionId);
        }
      }
      else
      {
        try {
          beginTransaction(transactionId, startId);
        } catch (Throwable e) {
           if (LOG.isWarnEnabled()) LOG.warn("beginTransaction - txId "
                 + transactionId + ", Caught exception ", e);
           t = e;
        }        
      }        
    }        
     
    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.BeginTransactionResponse.Builder beginTransactionResponseBuilder = BeginTransactionResponse.newBuilder();

    beginTransactionResponseBuilder.setHasException(false);

    if (t != null)
    {
      beginTransactionResponseBuilder.setHasException(true);
      beginTransactionResponseBuilder.setException(t.toString());
    }

    if (mue != null)
    {
      if (LOG.isTraceEnabled()) LOG.trace("beginTransaction - performing memoryPercentage " + memoryPercentage + ", posting memory usage exceeds indicated percentage");
      beginTransactionResponseBuilder.setHasException(true);
      beginTransactionResponseBuilder.setException(mue.toString());
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, false);
      long timeCost = System.currentTimeMillis();
      beginTransactionResponseBuilder.setCoproSTime(startTime);
      beginTransactionResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[3] += timeCost;
      callCount[3]++;
      costStats.callCountPlus(4L);
      costStats.sumCostPlus(4L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " beginTransaction txID " + transactionId + " CC " + callCount[3] + " ATC " + (costSum[3] / callCount[3]) + " TC " + timeCost);
          }
    }

    BeginTransactionResponse bresponse = beginTransactionResponseBuilder.build();
    done.run(bresponse);
  }

  @Override
  public void commit(RpcController controller,
                     CommitRequest request,
      RpcCallback<CommitResponse> done) {
// The default response seems redundant
//    CommitResponse response = CommitResponse.getDefaultInstance();

    Throwable t = null;
    long transactionId = request.getTransactionId();
    long commitId = request.getCommitId();
    boolean walSync = false;

    final int participantNum = request.getParticipantNum();
    final int tmTableCDCAttr = request.getTmTableCDCAttr();
    long startTime = System.currentTimeMillis();
    final short totalNum = (short) request.getTotalNum();
    final int ddlNum = request.getDdlNum();

    if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_LOG_MARK) > 0) 
	    LOG.info("commit - txId "
         + transactionId + ", commitId " + commitId + ", participantNum " + participantNum
         + ", tmTableCDCAttr " + tmTableCDCAttr + ", region " + m_regionDetails
         + ", totalNum " + totalNum);

    // Process local memory
    try {
       walSync = commit(transactionId, commitId, participantNum, tmTableCDCAttr, request.getIgnoreUnknownTransactionException(), totalNum, ddlNum);
    } catch (Throwable e) {
       if (LOG.isWarnEnabled()) LOG.warn("commit - txId " + transactionId
           + ", participantNum " + participantNum + ", region " + m_regionDetails
           + ", Caught exception ", e);
       t = e;
       walSync = false;
    }

    long currBinlogWid = 0l;

    //this is not a good way to pass a long value out of commit() method, but I cannot find a better way for now
    //in long run, we wish to move all binlog write operation into CommitRequest
    //then we can get rid if this binlogWidMap and use TransactionState instead
    //the reason we cannot use TransactionState at this point is that object is detroyed out of commit() function above by retireTransaction
    if(binlogWidMap != null) {
      if(binlogWidMap.containsKey(transactionId)) {
        currBinlogWid = binlogWidMap.get(transactionId);
        binlogWidMap.remove(transactionId);
      }
    }

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CommitResponse.Builder commitResponseBuilder = CommitResponse.newBuilder();

    commitResponseBuilder.setCommitOk(walSync);
    commitResponseBuilder.setHasException(false);
    commitResponseBuilder.setCurrentWid(currBinlogWid); //tell the caller what is the current binlog wid

    if (t != null)
    {
      commitResponseBuilder.setHasException(true);
      commitResponseBuilder.setException(t.toString());
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, true);
      long timeCost = System.currentTimeMillis();
      commitResponseBuilder.setCoproSTime(startTime);
      commitResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[4] += timeCost;
      callCount[4]++;
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " commit txID " + transactionId + " CC " + callCount[4] + " ATC " + (costSum[4] / callCount[4]) + " TC " + timeCost);
          }
      if (costStats != null) {
        costStats.callCountPlus(5L);
        costStats.sumCostPlus(5L, timeCost);
        costStats.printLog(transactionId);
        releaseEndpointCostStats(costStats);
      }
    }

    CommitResponse cresponse = commitResponseBuilder.build();
    done.run(cresponse);
  }

  @Override
  public void commitMultiple(RpcController controller,
                     CommitMultipleRequest request,
                     RpcCallback<CommitMultipleResponse> done) {
// The default response seems redundant
//    CommitMultipleResponse response = CommitMultipleResponse.getDefaultInstance();

    Throwable t = null;
    long transactionId = request.getTransactionId();
    long commitId = request.getCommitId();
    int tmTableCDCAttr = 0; 

    int i = 0;
    int numOfRegion = request.getRegionNameCount();
    String requestRegionName;
    long startTime = System.currentTimeMillis();

    if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_LOG_MARK) > 0) 
	    LOG.info("commitMultiple - txId " + transactionId + " master regionName " + regionInfo.getRegionNameAsString()
                    + " number of region is commitMultiple " + numOfRegion);

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CommitMultipleResponse.Builder commitMultipleResponseBuilder = CommitMultipleResponse.newBuilder();
    commitMultipleResponseBuilder.setHasException(false);

    while (i < numOfRegion) {
         requestRegionName = request.getRegionName(i).toStringUtf8();    
         tmTableCDCAttr = request.getTmTableCDCAttr(i);
         commitMultipleResponseBuilder.addException(BatchException.EXCEPTION_OK.toString());

         try {
              if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint commitMultiple begins for region " + requestRegionName);
              TrxRegionEndpoint regionEPCP = transactionsEPCPMap.get(requestRegionName+trxkeyEPCPinstance);
              if (regionEPCP == null) {
                 if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint commitMultiple region NOT FOUND in EPCP map " + requestRegionName);
                 commitMultipleResponseBuilder.setHasException(true);
                 commitMultipleResponseBuilder.setException(i, BatchException.EXCEPTION_REGIONNOTFOUND_ERR.toString());
              }
              else {
                 regionEPCP.commit(transactionId, commitId, i, tmTableCDCAttr, request.getIgnoreUnknownTransactionException(), (short)1, 0);
              }
              if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint commitMultiple ends");
             //commit(transactionId, tmTableCDCAttr, request.getIgnoreUnknownTransactionException());
         } catch (Throwable e) {
              if (LOG.isWarnEnabled()) {
                  LOG.warn("commitMultiple - txId " + transactionId
                              + ", Caught exception ", e);
              }
              t = e;
         }

         if (t != null)
         {
              commitMultipleResponseBuilder.setHasException(true);
              commitMultipleResponseBuilder.setException(i, t.toString());
         }

         i++; // move to next region 

    } // end of while-loop on all the regions in thecommitMultiple request

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, true);
      long timeCost = System.currentTimeMillis();
      commitMultipleResponseBuilder.setCoproSTime(startTime);
      commitMultipleResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[5] += timeCost;
      callCount[5]++;
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " commitMultiple txID " + transactionId + " CC " + callCount[5] + " ATC " + (costSum[5] / callCount[5]) + " TC " + timeCost);
          }
      if (costStats != null) {
        costStats.callCountPlus(6L);
        costStats.sumCostPlus(6L, timeCost);
        costStats.printLog(transactionId);
        releaseEndpointCostStats(costStats);
      }
    }

    CommitMultipleResponse cresponse = commitMultipleResponseBuilder.build();
    done.run(cresponse);
  }

  @Override
  public void commitIfPossible(RpcController controller,
                                CommitIfPossibleRequest request,
      RpcCallback<CommitIfPossibleResponse> done) {
// The default response seems redundant
//    CommitIfPossibleResponse response = CommitIfPossibleResponse.getDefaultInstance();

    long transactionId = request.getTransactionId();
    long commitId = request.getCommitId();
    long startEpoch = request.getStartEpoch();
    final int tmTableCDCAttr = request.getTmTableCDCAttr();
    final short totalNum = 0; //(short) request.getTotalNum();

    final int participantNum = request.getParticipantNum();
    Throwable t = null;
    long startTime = System.currentTimeMillis();

    // Process local memory
    try {
       if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_LOG_MARK) > 0) 
	       LOG.info("commitIfPossible - txId "  + transactionId
                 + ", startEpoch " + startEpoch + ", commitId " + commitId
                 + ", tmTableCDCAttr " + tmTableCDCAttr
                 + ", regionName, " + m_regionDetails + "calling internal commitIfPossible");
       commitIfPossible(transactionId, startEpoch, commitId, participantNum, tmTableCDCAttr, totalNum);
    } catch (Throwable e) {
       if (LOG.isWarnEnabled()) LOG.warn("commitIfPossible - txId " + transactionId
                + ", Caught exception ", e);
       t = e;
    }

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CommitIfPossibleResponse.Builder commitIfPossibleResponseBuilder = CommitIfPossibleResponse.newBuilder();

    commitIfPossibleResponseBuilder.setHasException(false);

    if (t != null)
    {
      commitIfPossibleResponseBuilder.setHasException(true);
      commitIfPossibleResponseBuilder.setException(t.toString());
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, true);
      long timeCost = System.currentTimeMillis();
      commitIfPossibleResponseBuilder.setCoproSTime(startTime);
      commitIfPossibleResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[6] += timeCost;
      callCount[6]++;
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " commitIfPossible txID " + transactionId + " CC " + callCount[6] + " ATC " + (costSum[6] / callCount[6]) + " TC " + timeCost);
          }
      if (costStats != null) {
        costStats.callCountPlus(7L);
        costStats.sumCostPlus(7L, timeCost);
        costStats.printLog(transactionId);
        releaseEndpointCostStats(costStats);
      }
    }

    CommitIfPossibleResponse cresponse = commitIfPossibleResponseBuilder.build();
    done.run(cresponse);
  }

  @Override
  public void commitRequest(RpcController controller,
                            CommitRequestRequest request,
                            RpcCallback<CommitRequestResponse> done) {

// The default response seems redundant
//    CommitRequestResponse response = CommitRequestResponse.getDefaultInstance();

    int status = 0;
    IOException ioe = null;
    UnknownTransactionException ute = null;
    CommitConflictException cce = null;
    CommitDoomedException cde = null;
    RegionShieldedException rse = null;
    EpochViolationException eve = null;
    long transactionId = request.getTransactionId();
    long binlogCommitId = request.getSavepointId();
    long startEpoch = request.getStartEpoch();
    int participantNum = request.getParticipantNum();
    boolean dropTableRecorded = request.getDropTableRecorded();
    boolean skipConflictDetection = request.getSkipConflictDetection();
    short totalNum = (short) request.getTotalNum();
    //String query = null;
    String query = Bytes.toString(request.getQueryContext().toByteArray());
    long startTime = System.currentTimeMillis();
    TrxTransactionState state = null;

    if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_LOG_MARK) > 0) 
	    LOG.info("commitRequest(CommitRequestRequest) - ENTRY  txId "
         + transactionId + ", startEpoch " + startEpoch + ", participantNum " + participantNum + ", dropTableRecorded " + dropTableRecorded
         + ", skipConflictDetection " + skipConflictDetection + ", regionName " + m_regionDetails);
    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CommitRequestResponse.Builder commitRequestResponseBuilder = CommitRequestResponse.newBuilder();
    if (false == m_regionName.equals(request.getRegionName().toStringUtf8())) {
      if (LOG.isWarnEnabled()) {
           LOG.warn("commitRequest - Regions' name mismatch. Input name is: "
             + request.getRegionName().toStringUtf8() + " and actual name is: " +  m_regionName);
      }
      int tmid = TransactionState.getNodeId(transactionId);
      if (tmid >= 0 && tmid < tmPrepareRefresh.length)
        tmPrepareRefresh[tmid] = true;
      commitRequestResponseBuilder.setResult(PREPARE_REFRESH);
      done.run(commitRequestResponseBuilder.build());
      return;
    }


    //for binlog to be able to flush in prepare phase, we have to set the commitID here from the request
    //since I don't want to add a new param in the commitRequest again, so I need to get the state at this point
    try {
      state = getTransactionState(transactionId);
      if (state != null)
        state.setCommitId(binlogCommitId);
    } catch (UnknownTransactionException e) {
      //unknown transaction will be handled as before later, so at this point, just do nothing
    }
    // Process local memory
    try {
      status = commitRequest(transactionId, skipConflictDetection, startEpoch, participantNum, dropTableRecorded,
                                      request.getIgnoreUnknownTransactionException(), query, totalNum);
    } catch (UnknownTransactionException u) {
       if (LOG.isInfoEnabled()) {
           LOG.info("TrxRegionEndpoint coprocessor: commitRequest - txId " + transactionId + ", Caught UnknownTransactionException after internal commitRequest call in region " + m_regionDetails, u);
       }
       ute = u;
       status = COMMIT_UNSUCCESSFUL_FROM_COPROCESSOR;
    } catch (RegionShieldedException r){
       if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor: commitRequest - txId " + transactionId + ", Caught RegionShieldedException after internal commitRequest call ", r);
       rse = r;
       status = COMMIT_SHIELDED;
    } catch (CommitConflictException c) {
       if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor: commitRequest - txId " + transactionId + ", Caught CommitConflictException after internal commitRequest call - "+ c.toString());
       cce = c;
       status = COMMIT_CONFLICT;
    } catch (CommitDoomedException d) {
       LOG.error("TrxRegionEndpoint coprocessor: commitRequest - txId " + transactionId + ", Caught CommitDoomedException after internal commitRequest call - "+ d.toString());
       cde = d;
       status = COMMIT_DOOMED;       
    } catch (EpochViolationException e) {
       if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor: commitRequest - txId " + transactionId + ", Caught EpochViolationException after internal commitRequest call - "+ e.toString());
       eve = e;
       status = EPOCH_VIOLATION;
    } catch (IOException e) {
       LOG.error("TrxRegionEndpoint coprocessor: commitRequest - txId " + transactionId + " participant " + participantNum
         +" , Caught IOException after internal commitRequest call - ", e);
       ioe = e;
       status = COMMIT_UNSUCCESSFUL_FROM_COPROCESSOR;
    }

    if (onlineBalance.get() == true) {
       LOG.warn("TrxRegionEndpoint coprocessor: commitRequest - txId " + transactionId + ", Region-closing cause this transaction to fail");
       if (state != null) {
         synchronized (commitCheckLock) {
           state.setStatus(Status.ABORTED);
           retireTransactionAndWriteAbortWal(state);
         }
       }
       try {
          unLockRegionAll(transactionId);
       } catch (Exception e) {}
       status = COMMIT_UNSUCCESSFUL_FROM_COPROCESSOR;
       ioe = new IOException("Region is closing"); 
    }

    commitRequestResponseBuilder.setHasException(false);

    if (cce != null)
    {
      commitRequestResponseBuilder.setHasException(true);
      commitRequestResponseBuilder.setException(cce.toString());
    }

    if (cde != null)
    {
      commitRequestResponseBuilder.setHasException(true);
      commitRequestResponseBuilder.setException(cde.toString());
    }

    if (eve != null)
    {
      commitRequestResponseBuilder.setHasException(true);
      commitRequestResponseBuilder.setException(eve.toString());
    }

    if (ioe != null)
    {
      commitRequestResponseBuilder.setHasException(true);
      commitRequestResponseBuilder.setException(ioe.toString());
    }

    if (ute != null)
    {
      commitRequestResponseBuilder.setHasException(true);
      commitRequestResponseBuilder.setException(ute.toString());
    }

    if (rse != null)
    {
      commitRequestResponseBuilder.setHasException(true);
      commitRequestResponseBuilder.setException(rse.toString());
    }

    commitRequestResponseBuilder.setResult(status);
    commitRequestResponseBuilder.setRegionName(ByteString.copyFromUtf8(m_regionName));

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, false);
      long timeCost = System.currentTimeMillis();
      commitRequestResponseBuilder.setCoproSTime(startTime);
      commitRequestResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[7] += timeCost;
      callCount[7]++;
      costStats.callCountPlus(8L);
      costStats.sumCostPlus(8L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " commitRequest txID " + transactionId + " CC " + callCount[7] + " ATC " + (costSum[7] / callCount[7]) + " TC " + timeCost);
          }
    }

    CommitRequestResponse cresponse = commitRequestResponseBuilder.build();
    done.run(cresponse);
  }

  @Override
  public void commitRequestMultiple(RpcController controller,
                            CommitRequestMultipleRequest request,
                            RpcCallback<CommitRequestMultipleResponse> done) {

// The default response seems redundant
//    CommitRequestMultipleResponse response = CommitRequestMultipleResponse.getDefaultInstance();

    int status = 0;
    IOException ioe = null;
    UnknownTransactionException ute = null;
    Throwable t = null;
    long transactionId = request.getTransactionId();
    long startEpoch = request.getStartEpoch();
    int i = 0;
    int numOfRegion = request.getRegionNameCount();
    boolean skipConflictDetection = request.getSkipConflictDetection();
    String requestRegionName;
    long startTime = System.currentTimeMillis();

    if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_LOG_MARK) > 0) 
	    LOG.info("TrxRegionEndpoint coprocessor: commitRequestMultiple - txId " + transactionId
          + " skipConflictDetection " + skipConflictDetection
          + " number of region is commitMultiple " + numOfRegion + ", master regionName " + regionInfo.getRegionNameAsString());

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CommitRequestMultipleResponse.Builder commitRequestMultipleResponseBuilder = CommitRequestMultipleResponse.newBuilder();
    commitRequestMultipleResponseBuilder.setHasException(false);

    while (i < numOfRegion) {
         requestRegionName = request.getRegionName(i).toStringUtf8();    
/*
         if (LOG.isTraceEnabled()) LOG.trace("EPCP AA0 Region Key " + Hex.encodeHexString(request.getRegionName(i).toStringUtf8().getBytes()));
         if (LOG.isTraceEnabled()) LOG.trace("EPCP AA0 Region Key " + regionInfo.getRegionNameAsString());
         if (LOG.isTraceEnabled()) LOG.trace("EPCP AA0 Region Key " + this.m_Region.getRegionName().toString());
         if (LOG.isTraceEnabled()) LOG.trace("EPCP AA0 Region Key " + Hex.encodeHexString(ByteString.copyFrom(this.m_Region.getRegionName()).toString().getBytes()));
         if (LOG.isTraceEnabled()) LOG.trace("EPCP AA1 Region Key " + Hex.encodeHexString(requestRegionName.getBytes()));
         if (LOG.isTraceEnabled()) LOG.trace("EPCP AA2 Region Key " + Hex.encodeHexString(regionInfo.getRegionNameAsString().getBytes()));
         if (LOG.isTraceEnabled()) LOG.trace("EPCP AA2 Region Key " + Hex.encodeHexString(this.m_Region.getRegionName()));

         if (requestRegionName.equals(ByteString.copyFrom(this.m_Region.getRegionName()).toString())) {
            if (LOG.isTraceEnabled()) { LOG.trace("EPCP BB0 Region Key matches !! " + request.getRegionName(i).toString()); }
         }
         if (Arrays.equals(request.getRegionName(i).toStringUtf8().getBytes(), regionInfo.getRegionNameAsString().getBytes())) {
            if (LOG.isTraceEnabled()) { LOG.trace("EPCP BB1 Region Key matches !! " + request.getRegionName(i).toString()); }
         }
         if (request.getRegionName(i).toStringUtf8().equals(regionInfo.getRegionNameAsString())) {
            if (LOG.isTraceEnabled()) { LOG.trace("EPCP BB2 Region Key matches !! " + request.getRegionName(i).toString()); }
         }
*/         
         commitRequestMultipleResponseBuilder.addException(BatchException.EXCEPTION_OK.toString());

         try {
              if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint commitRequestMultiple begins for region " + requestRegionName);
              TrxRegionEndpoint regionEPCP = transactionsEPCPMap.get(requestRegionName+trxkeyEPCPinstance);
              if (regionEPCP == null) {
                 if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint commitRequestMultiple region NOT FOUND in EPCP map " + requestRegionName);
                 commitRequestMultipleResponseBuilder.setHasException(true);
                 commitRequestMultipleResponseBuilder.setException(i, BatchException.EXCEPTION_REGIONNOTFOUND_ERR.toString());
              }
              else {
                 if (i == (numOfRegion - 1)) {status = regionEPCP.commitRequest(transactionId, skipConflictDetection, startEpoch, i, true);} // only the last region flush
                 else {status = regionEPCP.commitRequest(transactionId, skipConflictDetection, startEpoch, i, false);}
              }
              if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint commitRequestMultiple ends");
             //status = commitRequest(transactionId);
         } catch (UnknownTransactionException u) {
              if (LOG.isTraceEnabled()) LOG.trace("commitRequestMultiple - txId " + transactionId + ", Caught UnknownTransactionException after internal commitRequest call - " + u.toString());
              status = COMMIT_UNSUCCESSFUL_FROM_COPROCESSOR;
              ute = u;
         } catch (IOException e) {
              LOG.error("commitRequestMultiple - txId " + transactionId
                  + ", Caught IOException after internal commitRequest call - ", e);
              status = COMMIT_UNSUCCESSFUL_FROM_COPROCESSOR;
              ioe = e;
         }

         if (onlineBalance.get() == true) {
              LOG.warn("commitRequestMultiple - txId " + transactionId + ", Region-closing cause this transaction to fail");
              status = COMMIT_UNSUCCESSFUL_FROM_COPROCESSOR;
              ioe = new IOException("Region is closing"); 
         }

          if (t != null)
         {
              commitRequestMultipleResponseBuilder.setHasException(true);
              commitRequestMultipleResponseBuilder.setException(i, BatchException.EXCEPTION_SKIPREMAININGREGIONS_OK.toString());
         }

         if (ioe != null)
         {
              commitRequestMultipleResponseBuilder.setHasException(true);
              commitRequestMultipleResponseBuilder.setException(i, BatchException.EXCEPTION_SKIPREMAININGREGIONS_OK.toString());
         }

         if (ute != null)
         {
              commitRequestMultipleResponseBuilder.setHasException(true);
              commitRequestMultipleResponseBuilder.setException(i, BatchException.EXCEPTION_SKIPREMAININGREGIONS_OK.toString());
         }

         commitRequestMultipleResponseBuilder.addResult(status);

         i++; // move to next region 

    } // end of while-loop on all the regions in thecommitMultiple request

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, false);
      long timeCost = System.currentTimeMillis();
      commitRequestMultipleResponseBuilder.setCoproSTime(startTime);
      commitRequestMultipleResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[8] += timeCost;
      callCount[8]++;
      costStats.callCountPlus(9L);
      costStats.sumCostPlus(9L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " commitRequestMultiple txID " + transactionId + " CC " + callCount[8] + " ATC " + (costSum[8] / callCount[8]) + " TC " + timeCost);
          }
    }

    CommitRequestMultipleResponse cresponse = commitRequestMultipleResponseBuilder.build();
    done.run(cresponse);
  }

  @Override
  public void commitSavepoint(RpcController controller,
                     CommitSavepointRequest request,
      RpcCallback<CommitSavepointResponse> done) {
// The default response seems redundant
//    CommitSavepointResponse response = CommitSavepointResponse.getDefaultInstance();

    Throwable t = null;
    long transactionId = request.getTransactionId();
    long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
    long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
    boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
    boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());
    final int participantNum = request.getParticipantNum();
    String requestRegionName = request.getRegionName().toStringUtf8();
    long startTime = System.currentTimeMillis();

    int status = 0;

    if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_SAVEPOINT_LOG_MARK) > 0) {
        LOG.info("commitSavepoint enter - txId "
         + transactionId + ", savepointId " + savepointId + " implicit savepoint " + implicitSavepoint
         + ", participantNum " + participantNum
         + ", request region " + requestRegionName
         + ", region " + m_regionDetails);
    }

    // ignore region name check if requestRegionName is ""
    if (requestRegionName.length() == 0 || m_regionName.equals(requestRegionName)) {
      // Process local memory
      try {
         commitSavepoint(transactionId, savepointId, participantNum, request.getIgnoreUnknownTransactionException());
      } catch (Throwable e) {
         if (LOG.isWarnEnabled()) LOG.warn("commitSavepoint - txId " + transactionId + " savepointId " + savepointId
             + ", Caught exception ", e);
         t = e;
      }
    }
    else {
      // request RegionName and current RegionName does not equals,
      // need to refresh region locations in TransactionManager
      status = PREPARE_REFRESH;
    }

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CommitSavepointResponse.Builder commitSavepointResponseBuilder = CommitSavepointResponse.newBuilder();

    commitSavepointResponseBuilder.setHasException(false);

    if (t != null)
    {
      commitSavepointResponseBuilder.setHasException(true);
      commitSavepointResponseBuilder.setException(t.toString());
    }

    commitSavepointResponseBuilder.setResult(status);

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, false);
      long timeCost = System.currentTimeMillis();
      commitSavepointResponseBuilder.setCoproSTime(startTime);
      commitSavepointResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[9] += timeCost;
      callCount[9]++;
      costStats.callCountPlus(10L);
      costStats.sumCostPlus(10L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " commitSavepoint txID " + transactionId + " CC " + callCount[9] + " ATC " + (costSum[9] / callCount[9]) + " TC " + timeCost);
          }
    }

    CommitSavepointResponse cresponse = commitSavepointResponseBuilder.build();
    done.run(cresponse);

    if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_SAVEPOINT_LOG_MARK) > 0) {
        LOG.info("commitSavepoint exit - txId "
         + transactionId + ", savepointId " + savepointId + " implicit savepoint " + implicitSavepoint
         + ", participantNum " + participantNum
         + ", request regionName " + requestRegionName
         + ", regionName " + m_regionDetails
         + ", status " + status);
    }
  }

  public void checkAndDeleteRegionTx(RpcController controller,
                          CheckAndDeleteRegionTxRequest request,
                          RpcCallback<CheckAndDeleteRegionTxResponse> done) {

// The default response seems redundant
//    CheckAndDeleteRegionTxResponse response = CheckAndDeleteRegionTxResponse.getDefaultInstance();

    MutationProto proto = request.getDelete();
    MutationType type = proto.getMutateType();
    Delete delete = null;
    Throwable t = null;
    MemoryUsageException mue = null;
    boolean result = false;
    long tid = request.getTid();
    long commitId = request.getCommitId();
    boolean autoCommit = request.getAutoCommit();
    boolean skipCheck = false;
    long startTime = System.currentTimeMillis();
    String query = Bytes.toString(request.getQueryContext().toByteArray());

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CheckAndDeleteRegionTxResponse.Builder checkAndDeleteRegionTxResponseBuilder = CheckAndDeleteRegionTxResponse.newBuilder();

    if (false == m_regionName.equals(request.getRegionName().toStringUtf8())) {
      if (LOG.isWarnEnabled()) {
          LOG.warn("checkAndDeleteRegionTx - Regions' name mismatch. Input name is: "
             + request.getRegionName().toStringUtf8() + " and actual name is: " +  m_regionName);
      }

      checkAndDeleteRegionTxResponseBuilder.setResult(false);
      checkAndDeleteRegionTxResponseBuilder.setHasException(true);
      checkAndDeleteRegionTxResponseBuilder.setException(REGION_NAME_MISMATCH_EXCEPTION);
      done.run(checkAndDeleteRegionTxResponseBuilder.build());
      return;
    }
 
    totalCheckAndDeleteRegionTx.getAndIncrement();

    // If commitId is not set, then we didn't get a tid in the RMInterface and we get an id internally here
    if (commitId < 2) {
       tid = nextRegionTxId.getAndIncrement();
       if (LOG.isTraceEnabled()) LOG.trace("checkAndDeleteRegionTx - getting new tid "
            + tid + ", region " + m_regionDetails);
    }
    else {
       if (LOG.isTraceEnabled()) LOG.trace("checkAndDeleteRegionTx - using provided tid "
            + tid + ", region " + m_regionDetails);
    }

    if (memoryThrottle == true) {
      if(memoryUsageWarnOnly == true)  {
        if (LOG.isWarnEnabled()) LOG.warn("checkAndDeleteRegionTx - performing memoryPercentage " + memoryPercentage
             + ", warning memory usage exceeds indicated percentage");
      }
      else {
        if (LOG.isWarnEnabled()) LOG.warn("checkAndDeleteRegionTx - performing memoryPercentage " + memoryPercentage
         + ", generating memory usage exceeds indicated percentage");
        mue = new MemoryUsageException("checkAndDelete memory usage exceeds " + memoryUsageThreshold
                   + " percent, tid is " + tid);
      }
    }

    if (mue == null && 
        type == MutationType.DELETE && 
        proto.hasRow()){
      try {
          delete = ProtobufUtil.toDelete(proto);
      } catch (Throwable e) {
        if (LOG.isWarnEnabled()) LOG.warn("checkAndDeleteRegionTx - tid " + tid
            + ", Caught exception ", e);
        t = e;
      }

      // Process in local memory
      if ((delete != null) && (t == null)){
        if (request.hasRow()) {

           if (!Bytes.equals(proto.getRow().toByteArray(), request.getRow().toByteArray()))
              t = new org.apache.hadoop.hbase.DoNotRetryIOException("Action's " +
                  "checkAndDeleteRegionTx row must match the passed row");
           }

           if (t == null) {

             try {
               result = checkAndDeleteRegionTx(tid, tid,
                commitId,
                request.getRow().toByteArray(),
                request.getFamily().toByteArray(),
                request.getQualifier().toByteArray(),
                request.getValue().toByteArray(),
                skipCheck,
                delete,
                autoCommit, query);
             } catch (Throwable e) {
                if (!isLockException(e)) {
                    if (LOG.isWarnEnabled()) LOG.warn("checkAndDeleteRegionTx - tid " + tid
                          + ", regionName " + m_regionName + ", Caught exception ", e);
                }
                t = e;
             }
           }

          checkAndDeleteRegionTxResponseBuilder.setResult(result);
        }
     }
     else{
       result = false;
       checkAndDeleteRegionTxResponseBuilder.setResult(result);
     }

     if (LOG.isTraceEnabled()) LOG.trace("checkAndDeleteRegionTx - tid " + tid + ", result is " + result);

     checkAndDeleteRegionTxResponseBuilder.setHasException(false);

     if (t != null){
       checkAndDeleteRegionTxResponseBuilder.setHasException(true);
       checkAndDeleteRegionTxResponseBuilder.setException(t.toString());
     }

     if (mue != null){
       if (LOG.isWarnEnabled()) LOG.warn("checkAndDeleteRegionTx - performing memoryPercentage " + memoryPercentage
        + ", posting memory usage exceeds indicated percentage");
       checkAndDeleteRegionTxResponseBuilder.setHasException(true);
       checkAndDeleteRegionTxResponseBuilder.setException(mue.toString());
     }

     if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      long timeCost = System.currentTimeMillis();
      checkAndDeleteRegionTxResponseBuilder.setCoproSTime(startTime);
      checkAndDeleteRegionTxResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[10] += timeCost;
      callCount[10]++;
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " checkAndDeleteRegionTx CC " + callCount[10] + " ATC " + (costSum[10] / callCount[10]) + " TC " + timeCost);
          }
     }

     CheckAndDeleteRegionTxResponse checkAndDeleteRegionTxResponse = checkAndDeleteRegionTxResponseBuilder.build();
     done.run(checkAndDeleteRegionTxResponse);
  }

  @Override
  public void checkAndDelete(RpcController controller,
                          CheckAndDeleteRequest request,
                          RpcCallback<CheckAndDeleteResponse> done) {

// The default response seems redundant
//    CheckAndDeleteResponse response = CheckAndDeleteResponse.getDefaultInstance();
    long startTime = System.currentTimeMillis();
    MutationProto proto = request.getDelete();
    MutationType type = proto.getMutateType();
    Delete delete = null;
    Throwable t = null;
    MemoryUsageException mue = null;
    boolean result = false;
    long transactionId = request.getTransactionId();
    long startId = request.getStartId();
    long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
    long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
    boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
    boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());
    boolean skipCheck = request.getSkipCheck();
    String query = Bytes.toString(request.getQueryContext().toByteArray());

    // First test if this region matches our region name

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CheckAndDeleteResponse.Builder checkAndDeleteResponseBuilder = CheckAndDeleteResponse.newBuilder();

    if (false == m_regionName.equals(request.getRegionName().toStringUtf8())) {
      if (LOG.isWarnEnabled()) {
          LOG.warn("checkAndDelete - Regions' name mismatch. Input name is: "
             + request.getRegionName().toStringUtf8() + " and actual name is: " +  m_regionName);
      }

      checkAndDeleteResponseBuilder.setResult(false);
      checkAndDeleteResponseBuilder.setHasException(true);
      checkAndDeleteResponseBuilder.setException(REGION_NAME_MISMATCH_EXCEPTION);
      done.run(checkAndDeleteResponseBuilder.build());
      return;
    }

    if (LOG.isTraceEnabled()) LOG.trace("checkAndDelete - transactionId " + transactionId +
        ", savepointId " + savepointId + " implicit savepoint " + implicitSavepoint +
        ", region " + m_regionDetails);

      if (memoryThrottle == true) {
        if(memoryUsageWarnOnly == true)  {
            if (LOG.isWarnEnabled()) {
                LOG.warn("checkAndDelete - performing memoryPercentage " + memoryPercentage + ", warning memory usage exceeds indicated percentage");
            }
        }
        else {
          if (LOG.isTraceEnabled()) LOG.trace("checkAndDelete - performing memoryPercentage " + memoryPercentage + ", generating memory usage exceeds indicated percentage");
          mue = new MemoryUsageException("checkAndDelete memory usage exceeds " + memoryUsageThreshold + " percent, trxId is " + transactionId);
        }
      }

    if (mue == null && 
        type == MutationType.DELETE && 
        proto.hasRow())
    {
      try {
          delete = ProtobufUtil.toDelete(proto);
      } catch (Throwable e) {
        if (LOG.isWarnEnabled()) LOG.warn("checkAndDelete - txId " + transactionId
              + ", Caught exception ", e);
        t = e;
      }

      // Process in local memory
      if ((delete != null) && (t == null))
      {
        if (request.hasRow()) {

        if (!Bytes.equals(proto.getRow().toByteArray(), request.getRow().toByteArray()))
          t = new org.apache.hadoop.hbase.DoNotRetryIOException("Action's " +
          "Delete row must match the passed row");
        }

        if (t == null) {
      
          try {
           result = checkAndDelete(transactionId,
               savepointId,
               pSavepointId,
               startId,
               request.getRow().toByteArray(),
               request.getFamily().toByteArray(),
               request.getQualifier().toByteArray(),
               request.getValue().toByteArray(),
               skipCheck,
               delete,
               implicitSavepoint,
               query);
           } catch (Throwable e) {
             if (!isLockException(e)) {
                 if (LOG.isWarnEnabled()) LOG.warn("checkAndDelete - txId " + transactionId
                      + ", regionName " + m_regionName + ", Caught exception", e);
             }
             t = e;
           }
         }

       checkAndDeleteResponseBuilder.setResult(result);
     }
    }
    else
    {
      result = false;
      checkAndDeleteResponseBuilder.setResult(result);
    }

    if (LOG.isTraceEnabled()) LOG.trace("checkAndDelete - txId " + transactionId + ", result is " + result);

    checkAndDeleteResponseBuilder.setHasException(false);

    if (t != null)
    {
      checkAndDeleteResponseBuilder.setHasException(true);
      checkAndDeleteResponseBuilder.setException(t.toString());
    }

    if (mue != null)
    {
      if (LOG.isTraceEnabled()) LOG.trace("checkAndDelete - performing memoryPercentage " + memoryPercentage + ", posting memory usage exceeds indicated percentage");
      checkAndDeleteResponseBuilder.setHasException(true);
      checkAndDeleteResponseBuilder.setException(mue.toString());
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, false);
      long timeCost = System.currentTimeMillis();
      checkAndDeleteResponseBuilder.setCoproSTime(startTime);
      checkAndDeleteResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[11] += timeCost;
      callCount[11]++;
      costStats.callCountPlus(12L);
      costStats.sumCostPlus(12L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " checkAndDelete txID " + transactionId + " CC " + callCount[11] + " ATC " + (costSum[11] / callCount[11]) + " TC " + timeCost);
          }
    }

    CheckAndDeleteResponse checkAndDeleteResponse = checkAndDeleteResponseBuilder.build();
    done.run(checkAndDeleteResponse);
  }

  @Override
  public void checkAndPut(RpcController controller,
                          CheckAndPutRequest request,
                          RpcCallback<CheckAndPutResponse> done) {

// The default response seems redundant
//    CheckAndPutResponse response = CheckAndPutResponse.getDefaultInstance();
    long startTime = System.currentTimeMillis();
    MutationProto proto = request.getPut();
    MutationType type = proto.getMutateType();
    Put put = null;
    MemoryUsageException mue = null;
    Throwable t = null;
    boolean result = false;
    long transactionId = request.getTransactionId();
    long startId = request.getStartId();
    long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
    long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
    boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
    boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());
    boolean skipCheck = request.getSkipCheck();
    String query = Bytes.toString(request.getQueryContext().toByteArray());
    boolean keepOldRow = request.getKeepOldRow();

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CheckAndPutResponse.Builder checkAndPutResponseBuilder = CheckAndPutResponse.newBuilder();

    if (LOG.isTraceEnabled()) LOG.trace("checkAndPut - transactionId " + transactionId +
            ", savepointId " + savepointId + " implicit savepoint " + implicitSavepoint +
            ", region " + m_regionDetails);

    if (false == m_regionName.equals(request.getRegionName().toStringUtf8())) {
      if (LOG.isWarnEnabled()) {
          LOG.warn("checkAndPut - Regions' name mismatch. Input name is: "
             + request.getRegionName().toStringUtf8() + " and actual name is: " +  m_regionName);
      }

      checkAndPutResponseBuilder.setResult(false);
      checkAndPutResponseBuilder.setHasException(true);
      checkAndPutResponseBuilder.setException(REGION_NAME_MISMATCH_EXCEPTION);
      done.run(checkAndPutResponseBuilder.build());
      return;
    }

    if (memoryThrottle == true) {
        if(memoryUsageWarnOnly == true)  {
            if (LOG.isWarnEnabled()) {
                LOG.warn("checkAndPut - performing memoryPercentage " + memoryPercentage + ", warning memory usage exceeds indicated percentage");
            }
        }
        else {
          mue = new MemoryUsageException("checkAndPut memory usage exceeds " + memoryUsageThreshold + " percent, trxId is " + transactionId);
          if (LOG.isTraceEnabled()) LOG.trace("checkAndPut - performing memoryPercentage " + memoryPercentage + ", generating memory usage exceeds indicated percentage exception");
        }
    }

    if (mue == null &&
        type == MutationType.PUT && 
        proto.hasRow())
    {
      try {
          checkMemeoryUsage(transactionId);
          put = ProtobufUtil.toPut(proto);
      } catch (Throwable e) {
        if (LOG.isWarnEnabled()) LOG.warn("checkAndPut - txId " + transactionId
             + ", Caught exception ", e);
        t = e;
      }

      // Process in local memory
      if ((put != null) && (t == null))
      {
        if (t == null) {
          try {
           result = checkAndPut(transactionId,
               savepointId,
               pSavepointId,
               startId,
               request.getRow().toByteArray(),
               request.getFamily().toByteArray(),
               request.getQualifier().toByteArray(),
               request.getValue().toByteArray(),
               skipCheck,
               put,
               implicitSavepoint,
               request.getCapValue().toByteArray(), query, keepOldRow);
           } catch (Throwable e) {
             if (!isLockException(e)) {
                 if (LOG.isWarnEnabled()) LOG.warn("checkAndPut - txId "
                     + transactionId + ", regionName " + m_regionName + ", Caught exception ", e);
             }
             t = e;
           }
         }

       checkAndPutResponseBuilder.setResult(result);
     }
    }
    else
    {
      result = false;
      checkAndPutResponseBuilder.setResult(result);
    }

    if (LOG.isTraceEnabled()) LOG.trace("checkAndPut - txId " + transactionId + ", result is " + result);

    checkAndPutResponseBuilder.setHasException(false);

    if (t != null)
    {
      checkAndPutResponseBuilder.setHasException(true);
      checkAndPutResponseBuilder.setException(t.toString());
    }

    if (mue != null)
    {
      if (LOG.isTraceEnabled()) LOG.trace("checkAndPut - performing memoryPercentage " + memoryPercentage + ", posting memory usage exceeds indicated percentage exception");
      checkAndPutResponseBuilder.setHasException(true);
      checkAndPutResponseBuilder.setException(mue.toString());
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, false);
      long timeCost = System.currentTimeMillis();
      checkAndPutResponseBuilder.setCoproSTime(startTime);
      checkAndPutResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[12] += timeCost;
      callCount[12]++;
      costStats.callCountPlus(13L);
      costStats.sumCostPlus(13L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + "checkAndPut txID " + transactionId + " CC " + callCount[12] + " ATC " + (costSum[12] / callCount[12]) + " TC " + timeCost);
          }
    }

    CheckAndPutResponse checkAndPutResponse = checkAndPutResponseBuilder.build();
    done.run(checkAndPutResponse);
  }

  @Override
  public void checkAndPutRegionTx(RpcController controller,
                          CheckAndPutRegionTxRequest request,
                          RpcCallback<CheckAndPutRegionTxResponse> done) {

// The default response seems redundant
//    CheckAndPutRegionTxResponse response = CheckAndPutRegionTxResponse.getDefaultInstance();

    long tid = request.getTid();
    long commitId = request.getCommitId();
    MutationProto proto = request.getPut();
    MutationType type = proto.getMutateType();
    boolean autoCommit = request.getAutoCommit();
    Put put = null;
    MemoryUsageException mue = null;
    Throwable t = null;
    boolean result = false;
    long startId = tid;
    long startTime = System.currentTimeMillis();
    String query = Bytes.toString(request.getQueryContext().toByteArray());

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CheckAndPutRegionTxResponse.Builder checkAndPutRegionTxResponseBuilder = CheckAndPutRegionTxResponse.newBuilder();

    if (false == m_regionName.equals(request.getRegionName().toStringUtf8())) {
      if (LOG.isWarnEnabled()) {
          LOG.warn("checkAndPutRegionTx - Regions' name mismatch. Input name is: "
             + request.getRegionName().toStringUtf8() + " and actual name is: " +  m_regionName);
      }

      checkAndPutRegionTxResponseBuilder.setResult(false);
      checkAndPutRegionTxResponseBuilder.setHasException(true);
      checkAndPutRegionTxResponseBuilder.setException(REGION_NAME_MISMATCH_EXCEPTION);
      done.run(checkAndPutRegionTxResponseBuilder.build());
      return;
    }

    totalCheckAndPutRegionTx.getAndIncrement();
        
    // If commitId is not set, then we didn't get a tid in the RMInterface and we get an id internally here
    if (commitId < 2) {
       tid = nextRegionTxId.getAndIncrement();// exists issue
       if (LOG.isTraceEnabled()) LOG.trace("checkAndPutRegionTx - getting new tid "
            + tid + ", region " + m_regionDetails);
    }
    else {
       if (LOG.isTraceEnabled()) LOG.trace("checkAndPutRegionTx - using provided tid "
            + tid + ", region " + m_regionDetails);
    }

    if (memoryThrottle == true) {
        if(memoryUsageWarnOnly == true)  {
            if (LOG.isWarnEnabled()) {
                LOG.warn("TrxRegionEndpoint coprocessor: checkAndPutRegionTx - performing memoryPercentage " + memoryPercentage + ", warning memory usage exceeds indicated percentage");
            }
        }
        else {
          mue = new MemoryUsageException("checkAndPutRegionTx memory usage exceeds " + memoryUsageThreshold + " percent, tid is " + tid);
          if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor: checkAndPutRegionTx - performing memoryPercentage " + memoryPercentage + ", generating memory usage exceeds indicated percentage exception");
        }
    }

    if (mue == null &&
        type == MutationType.PUT && 
        proto.hasRow())
    {
      try {
          checkMemeoryUsage(tid);
          put = ProtobufUtil.toPut(proto);
      } catch (Throwable e) {
        if (LOG.isWarnEnabled()) LOG.warn("checkAndPutRegionTx - tid " + tid
            + ", Caught exception ", e);
        t = e;
      }

      // Process in local memory
      if ((put != null) && (t == null))
      {
        if (t == null) {
          try {
           result = checkAndPutRegionTx(tid,
               startId, commitId,
               request.getRow().toByteArray(),
               request.getFamily().toByteArray(),
               request.getQualifier().toByteArray(),
               request.getValue().toByteArray(),
               false, /* skipCheck */
               put,
               autoCommit,
               query);
           } catch (Throwable e) {
             if (!isLockException(e)) {
                 if (LOG.isWarnEnabled()) LOG.warn("checkAndPutRegionTx - tid " + tid
                        + ", regionName " + m_regionName + ", Caught exception ", e);
             }
             t = e;
           }
         }

       checkAndPutRegionTxResponseBuilder.setResult(result);
     }
    }
    else
    {
      result = false;
      checkAndPutRegionTxResponseBuilder.setResult(result);
    }

    if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor: checkAndPutRegionTx - tid " + tid + ", result is " + result);

    checkAndPutRegionTxResponseBuilder.setHasException(false);

    if (t != null)
    {
      checkAndPutRegionTxResponseBuilder.setHasException(true);
      checkAndPutRegionTxResponseBuilder.setException(t.toString());
    }

    if (mue != null)
    {
      if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor: checkAndPutRegionTx - performing memoryPercentage " + memoryPercentage + ", posting memory usage exceeds indicated percentage exception");
      checkAndPutRegionTxResponseBuilder.setHasException(true);
      checkAndPutRegionTxResponseBuilder.setException(mue.toString());
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      long timeCost = System.currentTimeMillis();
      checkAndPutRegionTxResponseBuilder.setCoproSTime(startTime);
      checkAndPutRegionTxResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[13] += timeCost;
      callCount[13]++;
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " CheckAndPutRegionTx CC " + callCount[13] + " ATC " + (costSum[13] / callCount[13]) + " TC " + timeCost);
          }
    }

    CheckAndPutRegionTxResponse checkAndPutRegionTxResponse = checkAndPutRegionTxResponseBuilder.build();
    done.run(checkAndPutRegionTxResponse);
  }

  @Override
  public void closeScanner(RpcController controller,
                           CloseScannerRequest request,
                           RpcCallback<CloseScannerResponse> done) {

    RegionScanner scanner = null;
    Throwable t = null;
    OutOfOrderProtocolException oop = null;
    Exception ce = null;
    long transId = request.getTransactionId();
    long scannerId = request.getScannerId();
    long startTime = System.currentTimeMillis();

    if (LOG.isTraceEnabled()) LOG.trace("closeScanner - txId " + transId + ", scanner id " + scannerId + ", regionName " + m_regionDetails);

    // There should be a matching key in the transactionsById map
    // associated with this transaction id.  If there is not
    // one, then the initial openScanner call for the transaction
    // id was not called.  This is a protocol error requiring
    // openScanner, performScan followed by a closeScanner.

    Long key = getTransactionalUniqueId(transId);
    boolean keyFound = transactionsById.containsKey(key);

    if (keyFound != true)
    {
      if (LOG.isTraceEnabled()) LOG.trace("closeScanner - Unknown transaction [" + transId
             + "] in region [" + m_regionDetails
             + "], will create an OutOfOrderProtocol exception ");
      oop = new OutOfOrderProtocolException("closeScanner does not have an active transaction with an open scanner, txId: " + transId);
    }

    if (oop == null) {
      try {
         // we want to allow closing scanners and remove operations up until the very end.
         checkBlockAll(transId);
         scanner = removeScanner(scannerId);

         if (scanner != null) { 
             scanner.close();
         }
         else
           if (LOG.isTraceEnabled()) LOG.trace("closeScanner - txId " + transId + ", scanner was null for scanner id " + scannerId);

/*
         try {
           scannerLeases.cancelLease(getScannerLeaseId(scannerId));
         } catch (LeaseException le) {
           // ignore
           if (LOG.isTraceEnabled()) LOG.trace("closeScanner failed to get a lease " + scannerId);
         }
*/

      } catch(Exception e) {
        if (LOG.isWarnEnabled()) LOG.warn("closeScanner - txId " + transId + ", Caught exception ", e);
        ce = e;
      } catch(Throwable e) {
         if (LOG.isWarnEnabled()) LOG.warn("closeScanner - txId " + transId + ", Caught exception ", e);
         t = e;
      }
    }

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.CloseScannerResponse.Builder closeResponseBuilder = CloseScannerResponse.newBuilder();

    closeResponseBuilder.setHasException(false);

    if (t != null)
    {
      closeResponseBuilder.setHasException(true);
      closeResponseBuilder.setException(t.toString());
    }

    if (ce != null)
    {
      closeResponseBuilder.setHasException(true);
      closeResponseBuilder.setException(ce.toString());
    }

    if (oop != null)
    {
      if (TrxRegionEndpoint.suppressOutOfOrderProtocolException == false)
      {
        closeResponseBuilder.setHasException(true);
        closeResponseBuilder.setException(oop.toString());
        if (LOG.isWarnEnabled()) {
            LOG.warn("closeScanner - OutOfOrderProtocolExc, transaction was not found, txId: " + transId + ",returned exception" + ", region " + m_regionDetails);
        }
      }
      else
         if (LOG.isWarnEnabled()) {
             LOG.warn("closeScanner - suppressing OutOfOrderProtocolExc, transaction was not found, txId: " + transId + ", region " + m_regionDetails);
         }
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transId, false);
      long timeCost = System.currentTimeMillis();
      closeResponseBuilder.setCoproSTime(startTime);
      closeResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[14] += timeCost;
      callCount[14]++;
      costStats.callCountPlus(15L);
      costStats.sumCostPlus(15L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " closeScanner txID " + transId + " CC " + callCount[14] + " ATC " + (costSum[14] / callCount[14]) + " TC " + timeCost);
          }
    }

    CloseScannerResponse cresponse = closeResponseBuilder.build();
    done.run(cresponse);
  }

  @Override
  public void deleteMultiple(RpcController controller,
                                DeleteMultipleTransactionalRequest request,
      RpcCallback<DeleteMultipleTransactionalResponse> done) {
// The default response seems redundant
//    DeleteMultipleTransactionalResponse response = DeleteMultipleTransactionalResponse.getDefaultInstance();

   java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto> results;
   results = request.getDeleteList();
   Delete delete = null;
   MutationType type;
   Throwable t = null;
   MemoryUsageException mue = null;
   long transactionId = request.getTransactionId();
   long startId = request.getStartId();
   long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
   long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
   boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
   boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());
   noConflictCheckForIndex = request.getNoConflictCheckForIndex();
   long startTime = System.currentTimeMillis();
   String query = Bytes.toString(request.getQueryContext().toByteArray());
   boolean keep_old_row = request.getKeepOldRow() ;

    if (LOG.isTraceEnabled()) LOG.trace("deleteMultiple - transactionId " + transactionId +
        ", savepointId " + savepointId + " implicit savepoint " + implicitSavepoint +
        ", region " + m_regionDetails);

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.DeleteMultipleTransactionalResponse.Builder deleteMultipleTransactionalResponseBuilder = DeleteMultipleTransactionalResponse.newBuilder();

   if (false == m_regionName.equals(request.getRegionName().toStringUtf8())) {
      if (LOG.isWarnEnabled()) {
            LOG.warn("deleteMultiple - Regions' name mismatch. Input name is: "
             + request.getRegionName().toStringUtf8() + " and actual name is: " +  m_regionName);
      }

      deleteMultipleTransactionalResponseBuilder.setHasException(true);
      deleteMultipleTransactionalResponseBuilder.setException(REGION_NAME_MISMATCH_EXCEPTION);
      done.run(deleteMultipleTransactionalResponseBuilder.build());
      return;
    }

   if (memoryThrottle == true) {
        if(memoryUsageWarnOnly == true)  {
            if (LOG.isWarnEnabled()) {
                LOG.warn("deleteMultiple - performing memoryPercentage " + memoryPercentage + ", warning memory usage exceeds indicated percentage");
            }
        }
        else {
          if (LOG.isTraceEnabled()) LOG.trace("deleteMultiple - performing memoryPercentage " + memoryPercentage + ", generating memory usage exceeds indicated percentage exception");
          mue = new MemoryUsageException("deleteMultiple memory usage exceeds " + memoryUsageThreshold + " percent, trxId is " + transactionId);
       }
   }

   if (mue == null) {
     for (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto proto : results)
     { 
       delete = null;

       if (proto != null)
       {
         type = proto.getMutateType();

         if (type == MutationType.DELETE && proto.hasRow())
         {
           try {
               checkBlockNonPhase2(transactionId); // throws IOException
               delete = ProtobufUtil.toDelete(proto);
           } catch (Throwable e) {
             if (LOG.isWarnEnabled()) LOG.warn("deleteMultiple - txId " + transactionId + " savepointId " + savepointId
                   + ", Caught exception after protobuf conversion delete ", e);
             t = e;
           }

           // Process in local memory
           if ((delete != null) && (t == null))
           {
             try {
               delete(transactionId, savepointId, pSavepointId, startId, delete, implicitSavepoint, query, keep_old_row);
             } catch (Throwable e) {
               if (!isLockException(e)) {
                   if (LOG.isWarnEnabled()) LOG.warn("deleteMultiple - txId " + transactionId
                         + ", regionName " + m_regionName + ", Caught exception ", e);
               }
               t = e;

               // Return first error rather than keep trying because this batch will fail.
               break;
             }

             if (LOG.isTraceEnabled()) LOG.trace("deleteMultiple - txId "  + transactionId + ", region " + m_regionDetails + ", type " + type + ", row " + Bytes.toStringBinary(proto.getRow().toByteArray()) + ", row in hex " + Hex.encodeHexString(proto.getRow().toByteArray()));
           }
         }
       }
       else
         if (LOG.isTraceEnabled()) LOG.trace("deleteMultiple - txId "  + transactionId + ", region " + m_regionDetails + ", delete proto was null");

      }
    }

    deleteMultipleTransactionalResponseBuilder.setHasException(false);

    if (t != null)
    {
      deleteMultipleTransactionalResponseBuilder.setHasException(true);
      deleteMultipleTransactionalResponseBuilder.setException(t.toString());
    }

    if (mue != null)
    {
      if (LOG.isTraceEnabled()) LOG.trace("deleteMultiple - performing memoryPercentage " + memoryPercentage + ", posting memory usage exceeds indicated percentage");
      deleteMultipleTransactionalResponseBuilder.setHasException(true);
      deleteMultipleTransactionalResponseBuilder.setException(mue.toString());
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, false);
      long timeCost = System.currentTimeMillis();
      deleteMultipleTransactionalResponseBuilder.setCoproSTime(startTime);
      deleteMultipleTransactionalResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[15] += timeCost;
      callCount[15]++;
      costStats.callCountPlus(16L);
      costStats.sumCostPlus(16L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " deleteMultiple txID " + transactionId + " CC " + callCount[15] + " ATC " + (costSum[15] / callCount[15]) + " TC " + timeCost);
          }
    }

    DeleteMultipleTransactionalResponse dresponse = deleteMultipleTransactionalResponseBuilder.build();
    if (LOG.isTraceEnabled()) LOG.trace("deleteMultiple return - transactionId "
            + transactionId + " hasException " + dresponse.getHasException() + ", region " + m_regionDetails);
    done.run(dresponse);
  }

  //@Override
  public void deleteMultipleNonTxn(RpcController controller,
                                DeleteMultipleNonTransactionalRequest request,
      RpcCallback<DeleteMultipleNonTransactionalResponse> done) {
// The default response seems redundant
//    DeleteMultipleTransactionalResponse response = DeleteMultipleTransactionalResponse.getDefaultInstance();

   TrxTransactionState state;
   java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto> results;
   results = request.getDeleteList();
   Delete delete = null;
   MutationType type;
   long txid = 0;
   Throwable t = null;
   MemoryUsageException mue = null;
   
   #ifdef CDH5.7 APACHE1.2 CDH5.16
    MultiVersionConcurrencyControl.WriteEntry writeEntry = null;
    long mvccNum = 0;
#endif

   long nonTransactionId = request.getNonTransactionId();
   long cid = request.getCommitId();
   long flags = request.getFlags();
   long time1 = 0, time2 = 0, time3 = 0, time4 = 0, time5 = 0;
   long tmpTime = 0, preTime = 0, startTime = System.currentTimeMillis(); 
   if (LOG.isTraceEnabled()) LOG.trace("deleteMultipleNonTxn - nonTransactionId " + nonTransactionId + ", region " + m_regionDetails);
  
   org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.DeleteMultipleNonTransactionalResponse.Builder deleteMultipleNonTransactionalResponseBuilder = DeleteMultipleNonTransactionalResponse.newBuilder();

   if (false == m_regionName.equals(request.getRegionName().toStringUtf8())) {
      if (LOG.isWarnEnabled()) {
          LOG.warn("deleteMultipleNonTxn - Regions' name mismatch. Input name is: "
             + request.getRegionName().toStringUtf8() + " and actual name is: " +  m_regionName);
      }

      deleteMultipleNonTransactionalResponseBuilder.setHasException(true);
      deleteMultipleNonTransactionalResponseBuilder.setException(REGION_NAME_MISMATCH_EXCEPTION);
      done.run(deleteMultipleNonTransactionalResponseBuilder.build());
      return;
   }
 
   {
      if (memoryThrottle == true) {
        if(memoryUsageWarnOnly == true)  {
            if (LOG.isWarnEnabled()) {
                LOG.warn("deleteMultipleNonTxn - performing memoryPercentage " + memoryPercentage + ", warning memory usage exceeds indicated percentage");
            }
        }
        else { 
          if (LOG.isTraceEnabled()) LOG.trace("deleteMultipleNonTxn - performing memoryPercentage " + memoryPercentage + ", generating memory usage exceeds indicated percentage");
          mue = new MemoryUsageException("deleteMultipleNonTxn memory usage exceeds " + memoryUsageThreshold + " percent, nonTransactionId is " + nonTransactionId);
        }
      }
      else
      {
          // step 1 - create a temp ts object for holding mutations (no adding into any list for transaction processing
         if (LOG.isTraceEnabled()) LOG.trace("deleteMultipleNonTxn - Step 1: create transaction state - nonTransactionId "
                               + nonTransactionId + ", region " + m_regionDetails);          
         state = new TrxTransactionState(nonTransactionId, nextLogSequenceId.getAndIncrement(),
                                      nextLogSequenceId, m_Region.getRegionInfo(), m_Region.getTableDesc(), tHLog, 
#ifdef CDH5.7 APACHE1.2 CDH5.16
                                      configuredEarlyLogging, this.t_Region,
#else                                     
                                      configuredEarlyLogging,
#endif                                                                                                        
                                      flags /* startId*/ , false /*regionTransaction*/ , true /* incremental BR */, m_regionName);          // temporary mutation holders
         state.setMutationClient(MUTATION_CLIENT_IBR); // set Incremental BR as mutation client
         state.setCommitId(cid);
         
          // step 2 - add all delete into ts through a new addDelete proc with new deleteMultiple NonTxn commit tag (~ region txn)
         if (LOG.isTraceEnabled()) LOG.trace("deleteMultipleNonTxn - Step 2: call addWrite2 for all the put - nonTransactionId "
                               + nonTransactionId + ", region " + m_regionDetails);       
         for (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto proto : results) {
             delete = null;
             if (proto != null) {
                type = proto.getMutateType();

                if (type == MutationType.DELETE && proto.hasRow()){
                  try {
                      delete = ProtobufUtil.toDelete(proto);
                  } catch (Throwable e) {
                     if (LOG.isWarnEnabled()) LOG.warn("deleteMultipleNonTxn - nonTransactionId " + nonTransactionId + ", Caught exception ", e);
                     t = e;
                  }
                  if (delete != null) {
                      try { // add the put into temp ts object
                          state.addDelete2(delete); // new addDelete2 proc for IBR operation to add delete into ts waction + WAL edit generation
                      } catch (Throwable e) {
                          if (LOG.isWarnEnabled()) LOG.warn("deleteMultipleNonTxn - nonTransactionId " + nonTransactionId + ", Caught exception after internal put - ", e);
                          t = e;
                      }
                      if (LOG.isTraceEnabled()) LOG.trace("deleteMultipleNonTxn - nonTransactionId " + nonTransactionId + ", region " + m_regionDetails + ", type " + type + ", row " + Bytes.toStringBinary(proto.getRow().toByteArray()) + ", row in hex " + Hex.encodeHexString(proto.getRow().toByteArray()));
                  }
                }
             }
             else
                if (LOG.isTraceEnabled()) LOG.trace("deleteMultipleNonTxn - nonTransactionId " + nonTransactionId + ", region " + m_regionDetails + ", delete proto was null");
         } // for all mutation delete
         if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
           preTime = System.currentTimeMillis();
           time1 = preTime - startTime;
         }
         
         // step 3 - write nonTxn delete multiple commit WALEdit  into HLOG 
         //              - this is for durability only, so the txn is committed and will be replayed during preWALRestore if RS fails
         //              - this operation is non-transactional, so ACI is NOT guaranteed, only  Durability is ensured if HLOG op succeeds

         if (LOG.isTraceEnabled()) LOG.trace("deleteMultipleNonTxn - Step 3: write TS_IBR_COMMIT HLOG WAL edit - nonTransactionId "
                               + nonTransactionId + ", region " + m_regionDetails);
         if (state.hasWrite()) {
                      if (LOG.isTraceEnabled()) LOG.trace("deleteMultipleNonTxn - write IBR commit edit to HLOG");
               try {

#ifdef CDH5.7 APACHE1.2 CDH5.16 
                WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(), 
                                             this.regionInfo.getTable(), 
                                             WALKey.NO_SEQUENCE_ID,
                                             TrxEnvironmentEdgeManager.currentTime(),
                                             WALKey.EMPTY_UUIDS,
                                             HConstants.NO_NONCE,
                                             HConstants.NO_NONCE,
                                             this.t_Region.getMVCC());                                       
#else
                final WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(),
                                          this.regionInfo.getTable(),
                                          TrxEnvironmentEdgeManager.currentTime());

#endif
      
                state.resetEdit();
                WALEdit e2 = state.getPreparedEdit();
                if (LOG.isTraceEnabled()) LOG.trace("deleteMultipleNonTxn - IBR commit WAL edit from ts, WALEdit size = " + e2.size());            
                  
#ifdef CDH5.7 APACHE1.2 CDH5.16  CDH5.16
                txid = this.tHLog.append(this.m_Region.getTableDesc(), this.regionInfo, wk, e2, false);
                writeEntry = wk.getWriteEntry();
                mvccNum = writeEntry.getWriteNumber();
        
                if (LOG.isInfoEnabled()) {
                    LOG.info("deleteMultipleNonTxn - IBR Commit " + m_regionDetails + " txId: " + nonTransactionId  );
                }
#else
                AtomicLong lv_seqid = this.m_Region.getSequenceId();
                txid = this.tHLog.append(this.m_Region.getTableDesc(),
                                         this.regionInfo,  wk,  e2,  lv_seqid,  false,  null);
                                         
                 if (LOG.isInfoEnabled()) {
                     LOG.info("deleteMultipleNonTxn - IBR Commit " + m_regionDetails + " txId: " + nonTransactionId  );
                 }
#endif

                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                  tmpTime = System.currentTimeMillis();
                  time2 = tmpTime - preTime;
                  preTime = tmpTime;
                }
                WALSync(tHLog, nonTransactionId, txid);
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                  tmpTime = System.currentTimeMillis();
                  time3 = tmpTime - preTime;
                  preTime = tmpTime;
                }

#ifdef CDH5.7 APACHE1.2 CDH5.16 
               if (writeEntry != null) {
                     this.t_Region.getMVCC().completeAndWait(writeEntry);
                     writeEntry = null;
               }
#endif
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                  tmpTime = System.currentTimeMillis();
                  time4 = tmpTime - preTime;
                  preTime = tmpTime;
                }
        
               } catch (IOException exp) {
                                   exp.fillInStackTrace();
                                   LOG.error("deleteMultipleNonTxn - IBR commit " + nonTransactionId + " HLog seq " + txid + " Caught IOException in HLOG operations", exp );
                                   t = exp; // throw exp;
                }
 
#ifdef CDH5.7 APACHE1.2 CDH5.16    
               finally {
                       if (writeEntry != null) {
                              this.t_Region.getMVCC().completeAndWait(writeEntry);
                              writeEntry = null;
                       }          
                } // finally
#endif      

         } // has write, need HLOG op
         
         // step 4 - for all the delete in ts, perform region.put and construct related mutation proto if Incremental BR is ON
         if (LOG.isTraceEnabled()) LOG.trace("deleteMultipleNonTxn - Step 4: peform region.delete - nonTransactionId "
                               + nonTransactionId + ", region " + m_regionDetails);
         ListIterator<WriteAction> writeOrderIter = null;
         if (state.hasWrite()) {
              try {
                      int writeOrderIndex = 0;
                      for (writeOrderIter = state.getWriteOrderingIter();  writeOrderIter.hasNext();) {
                             WriteAction action =(WriteAction) writeOrderIter.next();
                             Delete pdelete = action.getDelete();
                             if (null != pdelete) {        // Process Delete
                                       pdelete.setDurability(Durability.ASYNC_WAL);
                                       if (LOG.isTraceEnabled()) LOG.trace("deleteMultipleNonTxn - IBR commit txId "
                                              + nonTransactionId + ", Executing put writeOrderIndex " + writeOrderIndex + " durability "
                                              + delete.getDurability().toString() + " directly to region "  + m_regionDetails  );
                                       try {
                                             m_Region.delete(pdelete);
                                       }
                                      catch (Exception e) {
                                                LOG.error("deleteMultipleNonTxn - IBR commit " + " txId " + nonTransactionId + ", Executing delete caught an exception ",e);
                                                t = e; // throw new IOException("IBR commit -" + " txId " + nonTransactionId + ", Executing delete caught an exception " + e);
                                       }
                             }

                            writeOrderIndex++;
                      } // for every delete
                      if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                        tmpTime = System.currentTimeMillis();
                        time5 = tmpTime - preTime;
                        preTime = tmpTime;
                      }
                      
                      // IBR op will do CDC by default
                      if (LOG.isTraceEnabled()) LOG.trace("deleteMultipleNonTxn - Step 5: IBR CDC operation - nonTransactionId "
                               + nonTransactionId + ", region " + m_regionDetails);
                      if (useMC2) {
                          if (mutationCapture2 == null) {
                              mutationCapture2 = MutationCapture2.MC2_getInstance(this.config, 
                              this.fs,
                              context,
                              regionInfo,
                              0, 1);
                          }
                          mutationCapture2.setNonTrxRecordBinlog(true);
                          mutationCapture2.MC2_doMutationAppend(state, regionInfo.getTable().getNameAsString());
                          mutationCapture2.setNonTrxRecordBinlog(false);
                      }
                      else {
                          mutationCapture.txnMutationBuilder(state, 5000, 15000); 
                      }
                   } catch(IOException e) {
                     LOG.error("deleteMultipleNonTxn -  IBR CDC - Unable to write mutation capture ", e);
                     t = new IOException("Trafodion CDC Exception NonTxnMultipleDelete ", e); // throw new RuntimeException(e);
              }
         } // size > 0
         
       } // else  - no momory issue
    }

    if (LOG.isTraceEnabled()) LOG.trace("deleteMultipleNonTxn - Step 6: process exception handler - nonTransactionId "
                               + nonTransactionId + ", region " + m_regionDetails + " exception caught " + t);    
    
    deleteMultipleNonTransactionalResponseBuilder.setHasException(false);

    if (t != null)
    {
      deleteMultipleNonTransactionalResponseBuilder.setHasException(true);
      deleteMultipleNonTransactionalResponseBuilder.setException(t.toString());
    }

    if (mue != null)
    {
      if (LOG.isTraceEnabled()) LOG.trace("deleteMultipleNonTxn - performing memoryPercentage " + memoryPercentage + ", posting memory usage exceeds indicated percentage");
      deleteMultipleNonTransactionalResponseBuilder.setHasException(true);
      deleteMultipleNonTransactionalResponseBuilder.setException(mue.toString());
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(nonTransactionId, false);
      long timeCost = System.currentTimeMillis();
      deleteMultipleNonTransactionalResponseBuilder.setCoproSTime(startTime);
      deleteMultipleNonTransactionalResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[16] += timeCost;
      callCount[16]++;
      costStats.callCountPlus(17L);
      costStats.sumCostPlus(17L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + "deleteMultipleNonTxn nontid " + nonTransactionId + " CC " + callCount[16] + " ATC " + (costSum[16] / callCount[16]) + " TC " + timeCost
                 + " time1 " + time1 + " time2 " + time2 + " time3 " + time3 + " time4 " + time4 + " time5 " + time5);
          }
    }

    DeleteMultipleNonTransactionalResponse pmresponse = deleteMultipleNonTransactionalResponseBuilder.build();
    done.run(pmresponse);
  }

  
  public void deleteRegionTx(RpcController controller,
                                DeleteRegionTxRequest request,
      RpcCallback<DeleteRegionTxResponse> done) {
// The default response seems redundant
//    DeleteRegionTxResponse response = DeleteRegionTxResponse.getDefaultInstance();

    MutationProto proto = request.getDelete();
    MutationType type = proto.getMutateType();
    Delete delete = null;
    Boolean autoCommit = request.getAutoCommit();
    Throwable t = null;
    MemoryUsageException mue = null;
    long tid = request.getTid();
    long commitId = request.getCommitId();
    long startTime = System.currentTimeMillis();
    String query = Bytes.toString(request.getQueryContext().toByteArray());

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.DeleteRegionTxResponse.Builder deleteRegionTxResponseBuilder = DeleteRegionTxResponse.newBuilder();
    if (false == m_regionName.equals(request.getRegionName().toStringUtf8())) {
      if (LOG.isWarnEnabled()) {
          LOG.warn("deleteRegionTx - Regions' name mismatch. Input name is: "
             + request.getRegionName().toStringUtf8() + " and actual name is: " +  m_regionName);
      }

      deleteRegionTxResponseBuilder.setHasException(true);
      deleteRegionTxResponseBuilder.setException(REGION_NAME_MISMATCH_EXCEPTION);
      done.run(deleteRegionTxResponseBuilder.build());
      return;
    }
    
    totalDeleteRegionTx.getAndIncrement();

    // If commitId is not set, then we didn't get a tid in the RMInterface and we get an id internally here
    if (commitId < 2) {
       tid = nextRegionTxId.getAndIncrement();
       if (LOG.isTraceEnabled()) LOG.trace("deleteRegionTx - getting new tid "
            + tid + ", region " + m_regionDetails);
    }
    else {
       if (LOG.isTraceEnabled()) LOG.trace("deleteRegionTx - using provided tid "
            + tid + ", region " + m_regionDetails);
    }
    if (memoryThrottle == true) {
        if(memoryUsageWarnOnly == true)  {
            if (LOG.isWarnEnabled()) {
                LOG.warn("deleteRegionTx - performing memoryPercentage " + memoryPercentage + ", warning memory usage exceeds indicated percentage");
            }
        }
        else {
          if (LOG.isTraceEnabled()) LOG.trace("deleteRegionTx - performing memoryPercentage " + memoryPercentage + ", generating memory usage exceeds indicated percentage");
          mue = new MemoryUsageException("deleteRegionTx memory usage exceeds " + memoryUsageThreshold + " percent, tid is " + tid);
        }
    }
    else
    {
      try {
          checkBlockNonPhase2(tid); // throws IOException
          delete = ProtobufUtil.toDelete(proto); 
      } catch (Throwable e) {
        if (LOG.isWarnEnabled()) LOG.warn("deleteRegionTx - tid " + tid
            + ", Caught exception ", e);
        t = e;
      }

      // Process in local memory
      if ((delete != null) && (t == null)){
        try {
           deleteRegionTx(tid, tid, commitId, delete, autoCommit, false /* skipcc */, query);
        } catch (Throwable e) {
           if (!isLockException(e)) {
               if (LOG.isWarnEnabled()) LOG.warn("deleteRegionTx - tid " + tid
                    + ", regionName " + m_regionName + ", Caught exception after internal deleteRegionTx - ", e);
           }
           t = e;
        }

        if (LOG.isTraceEnabled()) LOG.trace("deleteRegionTx - tid "  + tid + ", regionName "
           + m_regionDetails + ", type " + type + ", row "
           + Bytes.toStringBinary(proto.getRow().toByteArray()) + ", row in hex "
           + Hex.encodeHexString(proto.getRow().toByteArray()));
      }
      else{
       if (delete == null){
          if (LOG.isTraceEnabled()) LOG.trace("deleteRegionTx - delete is null");
       }
      }
    }

    deleteRegionTxResponseBuilder.setHasException(false);

    if (t != null)
    {
      deleteRegionTxResponseBuilder.setHasException(true);
      deleteRegionTxResponseBuilder.setException(t.toString());
    }

    if (mue != null)
    {
      if (LOG.isTraceEnabled()) LOG.trace("deleteRegionTx - performing memoryPercentage "
           + memoryPercentage + ", posting memory usage exceeds indicated percentage");
      deleteRegionTxResponseBuilder.setHasException(true);
      deleteRegionTxResponseBuilder.setException(mue.toString());
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      long timeCost = System.currentTimeMillis();
      deleteRegionTxResponseBuilder.setCoproSTime(startTime);
      deleteRegionTxResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[17] += timeCost;
      callCount[17]++;
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " deleteRegionTx CC " + callCount[17] + " ATC " + (costSum[17] / callCount[17]) + " TC " + timeCost);
          }
    }

    DeleteRegionTxResponse dresponse = deleteRegionTxResponseBuilder.build();
    done.run(dresponse);
  }

  @Override
  public void delete(RpcController controller,
                                DeleteTransactionalRequest request,
      RpcCallback<DeleteTransactionalResponse> done) {
// The default response seems redundant
//    DeleteTransactionalResponse response = DeleteTransactionalResponse.getDefaultInstance();
    long startTime = System.currentTimeMillis();
    MutationProto proto = request.getDelete();
    MutationType type = proto.getMutateType();
    Delete delete = null;
    Throwable t = null;
    MemoryUsageException mue = null;
    long transactionId = request.getTransactionId();
    long startId = request.getStartId();
    long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
    long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
    boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
    boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());
    noConflictCheckForIndex = request.getNoConflictCheckForIndex();
    String query = Bytes.toString(request.getQueryContext().toByteArray());
    boolean keep_old_row = request.getKeepOldRow();

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.DeleteTransactionalResponse.Builder deleteTransactionalResponseBuilder = DeleteTransactionalResponse.newBuilder();

    if (LOG.isTraceEnabled()) LOG.trace("delete - transactionId " + transactionId +
            ", savepointId " + savepointId + " implicit savepoint " + implicitSavepoint +
            ", region " + m_regionDetails);

    if (false == m_regionName.equals(request.getRegionName().toStringUtf8())) {
      if (LOG.isWarnEnabled()) {
          LOG.warn("delete - Regions' name mismatch. Input name is: "
             + request.getRegionName().toStringUtf8() + " and actual name is: " +  m_regionName);
      }

      deleteTransactionalResponseBuilder.setHasException(true);
      deleteTransactionalResponseBuilder.setException(REGION_NAME_MISMATCH_EXCEPTION);
      done.run(deleteTransactionalResponseBuilder.build());
      return;
    }

    if (memoryThrottle == true) {
        if(memoryUsageWarnOnly == true)  {
            if (LOG.isWarnEnabled()) {
                LOG.warn("delete - performing memoryPercentage " + memoryPercentage + ", warning memory usage exceeds indicated percentage");
            }
        }
        else {
          if (LOG.isTraceEnabled()) LOG.trace("delete - performing memoryPercentage " + memoryPercentage + ", generating memory usage exceeds indicated percentage");
          mue = new MemoryUsageException("delete memory usage exceeds " + memoryUsageThreshold + " percent, trxId is " + transactionId);
        }
    }
    else
    {
      try {
          checkBlockNonPhase2(transactionId); // throws IOException
          delete = ProtobufUtil.toDelete(proto); 
      } catch (Throwable e) {
        if (LOG.isWarnEnabled()) LOG.warn("delete - txId " + transactionId
             + ", Caught exception ", e);
        t = e;
      }

      // Process in local memory
     if ((delete != null) && (t == null))
     {
          try {
            delete(transactionId, savepointId, pSavepointId, startId, delete, implicitSavepoint, query, keep_old_row);
          } catch (Throwable e) {
            if (!isLockException(e)) {
                if (LOG.isWarnEnabled()) LOG.warn("delete - txId " + transactionId
                     + ", regionName " + m_regionName + ", Caught exception after internal delete - ", e);
            }
            t = e;
          }

          if (LOG.isTraceEnabled()) LOG.trace("delete - txId "  + transactionId + " savepointId " + savepointId + ", region " + m_regionDetails + ", type " + type + ", row " + Bytes.toStringBinary(proto.getRow().toByteArray()) + ", row in hex " + Hex.encodeHexString(proto.getRow().toByteArray()));
        }
    }

    deleteTransactionalResponseBuilder.setHasException(false);

    if (t != null)
    {
      deleteTransactionalResponseBuilder.setHasException(true);
      deleteTransactionalResponseBuilder.setException(t.toString());
    }

    if (mue != null)
    {
      if (LOG.isTraceEnabled()) LOG.trace("delete - performing memoryPercentage " + memoryPercentage + ", posting memory usage exceeds indicated percentage");
      deleteTransactionalResponseBuilder.setHasException(true);
      deleteTransactionalResponseBuilder.setException(mue.toString());
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, false);
      long timeCost = System.currentTimeMillis();
      deleteTransactionalResponseBuilder.setCoproSTime(startTime);
      deleteTransactionalResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[18] += timeCost;
      callCount[18]++;
      costStats.callCountPlus(19L);
      costStats.sumCostPlus(19L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " delete txID " + transactionId + " CC " + callCount[18] + " ATC " + (costSum[18] / callCount[18]) + " TC " + timeCost);
          }
    }

    DeleteTransactionalResponse dresponse = deleteTransactionalResponseBuilder.build();
    done.run(dresponse);
  }

  @Override
  public void get(RpcController controller,
                  GetTransactionalRequest request,
                  RpcCallback<GetTransactionalResponse> done) {
// The default response seems redundant
//    GetTransactionalResponse response = GetTransactionalResponse.getDefaultInstance();
    long preTime = 0, tmpTime = 0, startTime = System.currentTimeMillis();

    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get proto = request.getGet();
    Get get = null;
    RegionScanner scanner = null;
    Throwable t = null;
    Exception ge = null;
    IOException gioe = null;
    MemoryUsageException mue = null;
    org.apache.hadoop.hbase.client.Result result2 = null;
    long transactionId = request.getTransactionId();
    long startId = request.getStartId();
    boolean exceptionThrown = false;
    long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
    long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
    boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
    boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());

    boolean skipScanConflict = request.getSkipScanConflict();
    TrxTransactionState state = null;
    int isolationLevel = request.getIsolationLevel();
    int lockMode = request.getLockMode();
    int error = INIT_SVPT_ERROR;
    boolean waitOnSelectForUpdate = request.getWaitOnSelectForUpdate();
    ByteArrayKey rowInHex = null; 
    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.GetTransactionalResponse.Builder getResponseBuilder = GetTransactionalResponse.newBuilder();
    String query = Bytes.toString(request.getQueryContext().toByteArray());

    if (LOG.isTraceEnabled()) LOG.trace("GetTransactionalRequest - txId "
            + transactionId +
            ", savepointId " + savepointId + " implicit savepoint " + implicitSavepoint +
            ", region " + m_regionDetails + " skipScanConflict is " + skipScanConflict);
    if (false == m_regionName.equals(request.getRegionName().toStringUtf8())) {
      if (LOG.isWarnEnabled()) {
          LOG.warn("get - Regions' name mismatch. Input name is: "
             + request.getRegionName().toStringUtf8() + " and actual name is: " +  m_regionName);
      }

      getResponseBuilder.setHasException(true);
      getResponseBuilder.setException(REGION_NAME_MISMATCH_EXCEPTION);
      done.run(getResponseBuilder.build());
      return;
    }

    long time1 =0, time2 = 0, time3 = 0, time4 = 0, time5 = 0;
    long time2_1 =0, time2_2 = 0, time2_3 = 0, time2_4 = 0;
      if (memoryThrottle == true) {
        if(memoryUsageWarnOnly == true)  
          if (LOG.isWarnEnabled()) {
              LOG.warn("GetTransactionalRequest - performing memoryPercentage " + memoryPercentage + ", warning memory usage exceeds indicated percentage");
          }
        else {
          if (LOG.isTraceEnabled()) LOG.trace("GetTransactionalRequest - performing memoryPercentage " + memoryPercentage + ", generating memory usage exceeds indicated percentage exception");
          mue = new MemoryUsageException("get memory usage exceeds " + memoryUsageThreshold + " percent, trxId is " + transactionId);
          exceptionThrown = true;
        }
      }
      else
      {
        try {
          checkBlockNonPhase2(transactionId); // throws IOException
          get = ProtobufUtil.toGet(proto);
        } catch (Throwable e) {
          if (LOG.isWarnEnabled()) LOG.warn("GetTransactionalRequest - txId " + transactionId + " (loc 0) in region " + m_regionDetails
                + ", Caught exception " + e.getMessage() + " " + stackTraceToString(e));
          t = e;
          exceptionThrown = true;
        }

        if (exceptionThrown == false) 
        {
            Scan scan = new Scan(get);
            scan.setSmall(true);
            List<Cell> results = new ArrayList<Cell>();

            try {

   //check the write lock for ta23
   int total_lock_time = forUpdLockTimeOut ;  
   boolean waitHere = true;
   int waitCounter = 0;
   byte[] getrow1 = get.getRow();
   rowInHex = new ByteArrayKey(getrow1);
   EndpointCostStats costStats = getEndpointCostStats(transactionId, false);
   while(enableTmpWriterLock == true && waitHere == true && waitCounter < total_lock_time + 1) {
      synchronized(tmpWriteLockHashmap){
         if(!tmpWriteLockHashmap.containsKey(rowInHex)) {
            if(enableTmpReadWriterLock==true && skipScanConflict == false) {
               long currentts = TrxEnvironmentEdgeManager.currentTime();
               trafLockInfo tli = new trafLockInfo(transactionId, currentts);
               tli.setIsRead();
               tmpWriteLockHashmap.put(rowInHex,tli);
            }
            waitHere = false; break;
         }
         else {
            trafLockInfo tfi = tmpWriteLockHashmap.get(rowInHex);
            if(transactionId == tfi.getTid() || tfi.isRead()) {
               waitHere = false; break;
            }
            else {
               Thread.sleep(1);
               waitCounter++;
            }
         }
      }
      if(waitCounter == total_lock_time ) //TIMEOUT
      {
         getResponseBuilder.setHasException(true);
         getResponseBuilder.setException("get for update lock timeout " );

         GetTransactionalResponse gresponse = getResponseBuilder.build();
         if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
           costStats.lockTimeCostPlus (waitCounter);
         done.run(gresponse);
         return;
      }
   }
   if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
     costStats.lockTimeCostPlus (waitCounter);
     preTime = System.currentTimeMillis();
     time1 = preTime - startTime;
   }
   if(waitOnSelectForUpdate == true)
   {
      waitCounter = 0;
      while(waitHere == true && waitCounter < total_lock_time + 1) { //by default, only wait for 3 ms
        synchronized(selectForUpdateLockHashmap){
          if(!selectForUpdateLockHashmap.containsKey(rowInHex))
          {
             if(selectForUpdateLockWaitQueue.containsKey(rowInHex) && enableUseWaitQueue == true) //the wait queue 
             {
               List<Long> waitTrxList = selectForUpdateLockWaitQueue.get(rowInHex);
               Long theTid = waitTrxList.get(0);
               if (theTid == transactionId ) //I am the first in the queue
               {
                 selectForUpdateLockHashmap.put(rowInHex,transactionId); //lock it
                 waitHere = false;
                 waitTrxList.remove(theTid); //I get it so remove from the queue
                 if(waitTrxList.size() == 0) //the queue is empty, remove it
                   selectForUpdateLockWaitQueue.remove(rowInHex);
                 break;
               }
             } 
             else //wait queue is empty
             {
               selectForUpdateLockHashmap.put(rowInHex,transactionId); //lock it
             
               waitHere = false; break;
             }
          }
          else {
            long tid = selectForUpdateLockHashmap.get(rowInHex);
            if(tid == transactionId)  //I get this lock
            { waitHere = false; break; }
            if(enableUseWaitQueue == true) {
              if(selectForUpdateLockWaitQueue.containsKey(rowInHex) ) //the wait queue
              {
               List<Long> waitTrxList = selectForUpdateLockWaitQueue.get(rowInHex);
               boolean inQueue = false;
               for(int i=0; i < waitTrxList.size(); i++)
               {
                 if( waitTrxList.get(i) == transactionId ) 
                 { inQueue = true; break; }
               }
               if(inQueue == false) //not in wait queue, enqueue at the end
               {
                 Long theTid = transactionId;
                 waitTrxList.add(theTid); //next : wait
                }
              }
              else //wait queue is empty, create it
               {
               List<Long> waitTrxList = new LinkedList<Long>();
               Long theTid = transactionId;
               waitTrxList.add(theTid);
               selectForUpdateLockWaitQueue.put(rowInHex, waitTrxList);
               } //if(selectForUpdateLockWaitQueue.containsKey(rowInHex) ) 
             } //if(enableUseWaitQueue == true) 
          }
        }

        if(waitHere == true) {
            Thread.sleep(1);          
            waitCounter++;
        }

        if(waitCounter == total_lock_time ) //TIMEOUT  wait for 10 times , default is 30 ms
        {

          getResponseBuilder.setHasException(true);
          getResponseBuilder.setException("get for update lock timeout " + lockTimeOut );

          GetTransactionalResponse gresponse = getResponseBuilder.build();
          if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
            costStats.lockTimeCostPlus (waitCounter);

          done.run(gresponse);
          return;
        } //        if(waitCounter == lockTimeOut ) //TIMEOUT
      } //while
      if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
        costStats.lockTimeCostPlus (waitCounter);
    } //if
              if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                tmpTime  = System.currentTimeMillis();
                time2 = tmpTime - preTime;
                preTime = tmpTime;
              }

              if (LOG.isDebugEnabled())  {
                byte[] row = proto.getRow().toByteArray();
                byte[] getrow = get.getRow();

                LOG.debug("GetTransactionalRequest - txId " + transactionId + " (loc 1) skipScanConflict " + skipScanConflict +
                          ", lockMode " + lockMode + ", Calling getScanner for region " + m_regionDetails +
                          ", row = " + Bytes.toStringBinary(row) + ", row in hex " + Hex.encodeHexString(row) +
                          ", getrow = " + Bytes.toStringBinary(getrow) + ", getrow in hex " + Hex.encodeHexString(getrow));
              }
              
              // Savepoint Checkin  
             if (savepointId > 0) {
	     	    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                      tmpTime  = System.currentTimeMillis();
	     	      time2_1 = tmpTime - preTime;
                    }
                    state= this.beginTransIfNotExist(transactionId, startId);
	     	    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                      tmpTime  = System.currentTimeMillis();
	     	      time2_2 = tmpTime - preTime;
                    }
                    if (!state.getStatus().equals(Status.PENDING)) { // Active
                         LOG.error("getScanner late checkin for transaction " + transactionId + " current state " + state.getStatus() + " in region " + m_regionDetails);
                         throw new IOException("getScanner late checkin for transaction " + transactionId + " current state " + state.getStatus() + " in region " + m_regionDetails);
                    }        
                    error = state.savepointCheckin(savepointId, SavepointOp.DML_SVPT_OP);
	     	    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                      tmpTime  = System.currentTimeMillis();
	     	      time2_3 = tmpTime - preTime;
                    }
                    if (error < 0) {
                         throw new IOException("Savepoint checkin error " + error + " on tid " + transactionId + " svpt " + savepointId + 
                             " op get " + SavepointOp.DML_SVPT_OP + " in region " + m_regionDetails);
                    }
              }    
              
              Object[] checkResult = checkLockedInGetScanner(scan, isolationLevel, lockMode);
              scanner = getScanner(transactionId, startId, skipScanConflict, scan, savepointId, pSavepointId, isolationLevel, lockMode, false, implicitSavepoint, checkResult, query);
	      if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                tmpTime  = System.currentTimeMillis();
	        time2_4 = tmpTime - preTime;
              }
              if(waitOnSelectForUpdate == true)
              {
                Long key = getTransactionalUniqueId(transactionId);
                TrxTransactionState state1 = transactionsById.get(key);
                state1.addSelForUpdLock(rowInHex);
              }

              if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                tmpTime = System.currentTimeMillis();
                time3 = tmpTime - preTime;
                preTime = tmpTime;
              }
              if (scanner != null)
                scanner.next(results);

              if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                tmpTime = System.currentTimeMillis();
                time4 = tmpTime - preTime;
                preTime = tmpTime;
              }
              result2 = Result.create(results);
              if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                tmpTime = System.currentTimeMillis();
                time5 = tmpTime - preTime;
                preTime = tmpTime;
              }
              if (LOG.isTraceEnabled()) LOG.trace("GetTransactionalRequest - txId " + transactionId + " (loc 2) in region " + m_regionDetails + ", getScanner result2 isEmpty is "
		   + result2.isEmpty() 
		   + ", row " 
		   + Bytes.toStringBinary(result2.getRow())
		   + " result length: "
		   + result2.size()); 

              if (result2.isEmpty() && lockMode == LockMode.LOCK_U) {
                  boolean ok_locked = ((Boolean)checkResult[2]).booleanValue();
                  if (!ok_locked) {
                      int isoLevel = transformIsolationLevel(isolationLevel);
                      unLock(transactionId, savepointId, scan.getStartRow(), lockMapping[isoLevel][SEL_UPD_ROW_LOCK]);
                  }
              }
            } catch(Throwable e) {
              if (!isLockException(e)) {
                  if (LOG.isWarnEnabled()) LOG.warn("GetTransactionalRequest - txId " + transactionId + " (loc 3) in region " + m_regionDetails + ", Caught exception "
                           + e.getMessage() + " " + stackTraceToString(e));
              }
              t = e;
              if(waitOnSelectForUpdate == true) { //if any exception, release the lock
                synchronized(selectForUpdateLockHashmap){ 
                  selectForUpdateLockHashmap.remove(rowInHex);
                  if(selectForUpdateLockWaitQueue.containsKey(rowInHex) && enableUseWaitQueue == true )
                  {
                    List<Long> waitTrxList = selectForUpdateLockWaitQueue.get(rowInHex);
                    if(waitTrxList.size() == 0) 
                      selectForUpdateLockWaitQueue.remove(rowInHex);
                  }
                }
              }
            }
            finally {
                //Savepoint Checkout
                if ((savepointId > 0) && (error == OK_SVPT_ERROR)) {
                     state.savepointCheckout(savepointId, SavepointOp.DML_SVPT_OP);
                     if (LOG.isTraceEnabled()) LOG.trace("GetTransactionalRequest -- EXIT txId: " + transactionId
                           + " savepointId " + savepointId);
                }       
                if (scanner != null) {
                    try {
                        scanner.close();
                     } catch(Exception e) {
                     if (LOG.isWarnEnabled()) LOG.warn("GetTransactionalRequest - txId " + transactionId + " (loc 4) in region " + m_regionDetails
                             + ", Caught exception closing scanner ", e);
                     ge = e;
                }
              }
            }
         } // ExceptionThrown
      } // End of MemoryUsageCheck

   if (result2 != null)
   {
     getResponseBuilder.setResult(ProtobufUtil.toResult(result2));
   }
   else
   {
     if (t == null && ge == null)
       gioe = new IOException("get - result2 was null");
     if (LOG.isTraceEnabled()) LOG.trace("get - txId " + transactionId + " (loc 5) in region " + m_regionDetails + ", result2 was null ");
   }
      
   getResponseBuilder.setHasException(false);

   if (t != null)
   {
     getResponseBuilder.setHasException(true);
     getResponseBuilder.setException(t.toString());
   }
   
   if (ge != null)
   {
     getResponseBuilder.setHasException(true);
     getResponseBuilder.setException(ge.toString());
   }
      
   if (gioe != null)
   {
     getResponseBuilder.setHasException(true);
     getResponseBuilder.setException(gioe.toString());
   }

   if (mue != null)
   {
     if (LOG.isTraceEnabled()) LOG.trace("get - performing memoryPercentage " + memoryPercentage + ", posting memory usage exceeds indicated percentage exception");
     getResponseBuilder.setHasException(true);
     getResponseBuilder.setException(mue.toString());
   }

   if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, false);
      long timeCost = System.currentTimeMillis();
      long time6 = timeCost - preTime;
      getResponseBuilder.setCoproSTime(startTime);
      getResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[19] += timeCost;
      callCount[19]++;
      costStats.callCountPlus(20L);
      costStats.sumCostPlus(20L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " get txID " + transactionId + " CC " + callCount[19] + " ATC " + (costSum[19] / callCount[19]) + " TC " + timeCost + " time1 " + time1
                + " time2 " + time2 + " time3 " + time3 + " time4 " + time4 + " time5 " + time5 + " time6 " + time6 
		        + " time2 [" + time2_1 + ", " + time2_2 + ", " + time2_3 + ", " + time2_4 + "]");
	      }
   }

   GetTransactionalResponse gresponse = getResponseBuilder.build();
   done.run(gresponse);
  }

  @Override
  public void getMultiple(RpcController controller,
                  GetMultipleTransactionalRequest request,
                  RpcCallback<GetMultipleTransactionalResponse> done) {

   java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get> protoList;
   List<Result> results = new ArrayList<Result>();
   org.apache.hadoop.hbase.client.Result result = null;
   List<Cell> cellResults = new ArrayList<Cell>();
   RegionScanner scanner = null;
   Exception ge = null;

   protoList = request.getGetList();
   Get get = null;
   Throwable t = null;
   MemoryUsageException mue = null;
   TrxTransactionState state = null;
   long transactionId = request.getTransactionId();
   long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
   long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
   boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
   boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());

   long startId = request.getStartId();
   boolean skipScanConflict = request.getSkipScanConflict();
   boolean exceptionThrown = false;
   int isolationLevel = request.getIsolationLevel();
   int lockMode = request.getLockMode();
   int error = INIT_SVPT_ERROR;
   boolean waitOnSelectForUpdate = request.getWaitOnSelectForUpdate();
   ByteArrayKey rowInHex = null;
   long preTime = 0, tmpTime = 0, startTime = System.currentTimeMillis();
   long time1 = 0, time2 = 0, time3 = 0, time4 = 0;
   String query = Bytes.toString(request.getQueryContext().toByteArray());

   if (LOG.isTraceEnabled()) LOG.trace("getMultiple - transactionId " + transactionId +
            ", savepointId " + savepointId + " implicit savepoint " + implicitSavepoint +
            ", region " + m_regionDetails);

   org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.GetMultipleTransactionalResponse.Builder getMultipleTransactionalResponseBuilder = GetMultipleTransactionalResponse.newBuilder();
   if (false == m_regionName.equals(request.getRegionName().toStringUtf8())) {
      getMultipleTransactionalResponseBuilder.setHasException(true);
      getMultipleTransactionalResponseBuilder.setException(t.toString());
      done.run(getMultipleTransactionalResponseBuilder.build());
      return;
   }
   getMultipleTransactionalResponseBuilder.setHasException(false);

   if (memoryThrottle == true) {
     if(memoryUsageWarnOnly == true)  {
         if (LOG.isWarnEnabled()) {
             LOG.warn("getMultiple - performing memoryPercentage " + memoryPercentage + ", warning memory usage exceeds indicated percentage");
         }
     }
     else {
       if (LOG.isTraceEnabled()) LOG.trace("getMultiple - performing memoryPercentage " + memoryPercentage + ", generating memory usage exceeds indicated percentage");
       mue = new MemoryUsageException("getMultiple memory usage exceeds " + memoryUsageThreshold + " percent, trxId is " + transactionId);
     }
   }
   else
   {
      try {
         // Savepoint Checkin
         if (savepointId > 0) {
            state = this.beginTransIfNotExist(transactionId, startId);
            if (!state.getStatus().equals(Status.PENDING)) { // Active
               LOG.error("getMultiple late checkin for transaction " + transactionId + " in region " + m_regionDetails);
               throw new IOException("getMultiple late checkin for transaction " + transactionId + " in region " + m_regionDetails);
            }
            error = state.savepointCheckin(savepointId, SavepointOp.DML_SVPT_OP);
            if (error < 0) {
               throw new IOException("Savepoint checkin error " + error + " on tid " + transactionId + " svpt " + savepointId +
                   " op getMultiple " + SavepointOp.DML_SVPT_OP + " in region " + m_regionDetails);
            }
         }

         if (waitOnSelectForUpdate){
            // Avoid deadlock on concurrent multiple lock requests
            if (LOG.isErrorEnabled()) LOG.error("getMultiple incompatible waitOnSelectForUpdate directive for tid " + transactionId + " in region " +  m_regionDetails);
            getMultipleTransactionalResponseBuilder.setHasException(true);
            getMultipleTransactionalResponseBuilder.setException("getMultiple incompatible waitOnSelectForUpdate directive for tid " + transactionId + " in region " +  m_regionDetails);
            GetMultipleTransactionalResponse gresponse = getMultipleTransactionalResponseBuilder.build();

            done.run(gresponse);
            return;
         }

         if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
           preTime = System.currentTimeMillis();
           time1 = preTime - startTime;
         }
         ArrayList<Get> getList = new ArrayList<Get>();

         int i = -1;
         for (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get proto : protoList){
            i++;
            get = null;
            if (proto != null){
               get = ProtobufUtil.toGet(proto);

               if (get != null) {
                  Scan scan = new Scan(get);

                  try {
                     byte[] getrow = get.getRow();
                     rowInHex = new ByteArrayKey(getrow);
                     skipScanConflict = request.getSkipScanConflict();
                     boolean waitHere = true;
                     int waitCounter = 0;
                     EndpointCostStats costStats = getEndpointCostStats(transactionId, false);

                     //check the write lock for ta23 
                     int total_lock_time = forUpdLockTimeOut ;
                     while(enableTmpWriterLock == true && waitHere == true && waitCounter < total_lock_time + 1) {
                        synchronized(tmpWriteLockHashmap){
                           if(!tmpWriteLockHashmap.containsKey(rowInHex)) { //not locked by some other writer
                              long currentts = TrxEnvironmentEdgeManager.currentTime();
                              trafLockInfo tli = new trafLockInfo(transactionId, currentts);
                              tli.setIsRead();
                              if(skipScanConflict == false && enableTmpReadWriterLock==true )
                                tmpWriteLockHashmap.put(rowInHex,tli);
                              waitHere = false; break;
                           }
                           else {
                              trafLockInfo tfi = tmpWriteLockHashmap.get(rowInHex);
                              if(transactionId == tfi.getTid() || tfi.isRead()) {
                                 waitHere = false; break;
                              }
                              else {
                                 Thread.sleep(1);
                                 waitCounter++;
                              }
                           }
                        }
                        if(waitCounter == total_lock_time ) //TIMEOUT 
                        {
                           getMultipleTransactionalResponseBuilder.setHasException(true);
                           getMultipleTransactionalResponseBuilder.setException("get for update lock timeout " + " writer conflict ");
                           done.run(getMultipleTransactionalResponseBuilder.build());
                           if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
                             costStats.lockTimeCostPlus (waitCounter);
                           return;
                        }
                     }
                     if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
                       costStats.lockTimeCostPlus (waitCounter);

                     if (LOG.isDebugEnabled())  {
                        byte[] row = proto.getRow().toByteArray();

                        LOG.debug("getMultiple - txId " + transactionId + " skipScanConflict " + skipScanConflict +
                              ", Calling getScanner iteration " + i + " for region " + m_regionDetails +
                              ", row = " + Bytes.toStringBinary(row) + ", row in hex " + Hex.encodeHexString(row) +
                              ", getrow = " + Bytes.toStringBinary(getrow) + ", getrow in hex " + Hex.encodeHexString(getrow));
                     }
                     if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                       tmpTime = System.currentTimeMillis();
                       time2 += (tmpTime - preTime);
                       preTime = tmpTime;
                     }

                     scanner = getScanner(transactionId, startId, skipScanConflict, scan, savepointId, pSavepointId, isolationLevel, lockMode, false, implicitSavepoint, query);
                     if (scanner != null){
                        checkMemeoryUsage(transactionId);
                        scanner.next(cellResults);
                     }
                     if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                       tmpTime = System.currentTimeMillis();
                       time3 += (tmpTime - preTime);
                       preTime = tmpTime;
                     }
                     result = Result.create(cellResults);
                     if (!result.isEmpty()) {
                        results.add(result);
                     }
                     cellResults.clear();
                     results.add(result);
                     if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                       tmpTime = System.currentTimeMillis();
                       time4 += (tmpTime - preTime);
                       preTime = tmpTime;
                     }
                     if (LOG.isTraceEnabled()) LOG.trace("getMultiple - txId " + transactionId + " in region " + m_regionDetails
                                    + ", getScanner result isEmpty is "
                                    + result.isEmpty()
                                    + ", row "
                                    + Bytes.toStringBinary(result.getRow())
                                    + " result length: "
                                    + result.size()
                                    + " results length: "
                                    + results.size());

                     if (scanner != null) {
                        try {
                           scanner.close();
                        } catch(Exception e) {
                           if (LOG.isWarnEnabled()) LOG.warn("get - txId " + transactionId + " (loc 6) in region " + m_regionDetails
                                 + ", Caught exception closing scanner ", e);
                           ge = e;
                           exceptionThrown = true;
                        }
                     }

                     if (LOG.isTraceEnabled()) LOG.trace("getMultiple - txId " + transactionId + " adding result: " + result);
                     getMultipleTransactionalResponseBuilder.addResult(ProtobufUtil.toResult(result));

                  } catch(Throwable e) {
                     if (!isLockException(e)) {
                         if (LOG.isWarnEnabled()) LOG.warn("getMultiple - txId " + transactionId + " loc 2 in region " + m_regionDetails + ", Caught exception "
                              + e.getMessage() + " " + stackTraceToString(e));
                     }
                     t = e;
                     exceptionThrown = true;
                  }
                  if (t != null)
                  {
                     getMultipleTransactionalResponseBuilder.setHasException(true);
                     getMultipleTransactionalResponseBuilder.setException(t.toString());
                  }
                  else if (mue != null)
                  {
                     if (LOG.isTraceEnabled()) LOG.trace("putMultiple - performing memoryPercentage " + memoryPercentage + ", posting memory usage exceeds indicated percentage");
                     getMultipleTransactionalResponseBuilder.setHasException(true);
                     getMultipleTransactionalResponseBuilder.setException(mue.toString());
                  }
               } // if (get != null)
            } // if (proto != null)
         } // End for

         if (LOG.isTraceEnabled()) LOG.trace("getMultiple - txId " + transactionId + " in region " + m_regionDetails
                                    + ", count is " + i
                                    + ", results size " + results.size());

         getMultipleTransactionalResponseBuilder.setCount(i + 1);

      } catch(Throwable e) {
         if (LOG.isWarnEnabled()) LOG.warn("getMultiple - txId " + transactionId + " loc 3 in region " + m_regionDetails + ", Caught exception "
                 + e.getMessage() + " " + stackTraceToString(e));
         t = e;
         exceptionThrown = true;
      } finally {
         //Savepoint Checkout
         if ((savepointId > 0) && (error == OK_SVPT_ERROR)) {
            state.savepointCheckout(savepointId, SavepointOp.DML_SVPT_OP);
            if (LOG.isTraceEnabled()) LOG.trace("get -- EXIT txId: " + transactionId
                      + " savepointId " + savepointId);
         }
         if (scanner != null) {
            try {
               scanner.close();
            } catch(Exception e) {
               if (LOG.isWarnEnabled()) LOG.warn("get - txId " + transactionId + " (loc 6) in region " + m_regionDetails
                          + ", Caught exception closing scanner ", e);
               ge = e;
               exceptionThrown = true;
            }
         }
      }
   }

   if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, false);
      long timeCost = System.currentTimeMillis();
      getMultipleTransactionalResponseBuilder.setCoproSTime(startTime);
      getMultipleTransactionalResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[20] += timeCost;
      callCount[20]++;
      costStats.callCountPlus(21L);
      costStats.sumCostPlus(21L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " getMultiple txID " + transactionId + " CC " + callCount[20] + " ATC " + (costSum[20] / callCount[20]) + " TC " + timeCost + " time1 " + time1 + " time2 " + time2 + " time3 " + time3 + " time4 " + time4);
          }
   }

   GetMultipleTransactionalResponse gmresponse = getMultipleTransactionalResponseBuilder.build();
   done.run(gmresponse);
 }

  public void openScanner(RpcController controller,
                          OpenScannerRequest request,
                          RpcCallback<OpenScannerResponse> done) {
    RegionScanner scanner = null;
    Throwable t = null;
    MemoryUsageException mue = null;
    boolean exceptionThrown = false;
    NullPointerException npe = null;        
    IOException ioe = null;                 
    LeaseStillHeldException lse = null;                 
    Scan scan = null;
    long scannerId = -1L;
    long transId = request.getTransactionId();
    long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
    long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
    boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
    boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());

    long startId = request.getStartId();
    boolean skipScanConflict = request.getSkipScanConflict();
    int isolationLevel = request.getIsolationLevel();
    int lockMode = request.getLockMode();
    long startTime = System.currentTimeMillis(), time1 = 0, time2 = 0;
    String query = Bytes.toString(request.getQueryContext().toByteArray());

    if (LOG.isDebugEnabled()) LOG.debug("openScanner - ENTER txId " + transId
            + ", savepointId " + savepointId + " implicit savepoint " + implicitSavepoint
            + " skipScanConflict " + skipScanConflict + " in region " + m_regionDetails);

    {
    
      if (memoryThrottle == true) {
        if(memoryUsageWarnOnly == true)  {
            if (LOG.isWarnEnabled()) {
                LOG.warn("openScanner - performing memoryPercentage " + memoryPercentage + ", warning memory usage exceeds indicated percentage");
            }
        }
        else {
          if (LOG.isTraceEnabled()) LOG.trace("openScanner - performing memoryPercentage " + memoryPercentage + ", generating memory usage exceeds indicated percentage");
          exceptionThrown = true;
          mue = new MemoryUsageException("openScanner memory usage exceeds " + memoryUsageThreshold + " percent, trxId is " + transId);
        }
      }
      else
      {
        try {
            scan = ProtobufUtil.toScan(request.getScan());
          if (scan == null)
            if (LOG.isTraceEnabled()) LOG.trace("openScanner - txId " + transId + ", scan was null");
        } catch (Throwable e) {
          if (LOG.isWarnEnabled()) LOG.warn("openScanner - txId " + transId
             + ", Caught exception ", e);
          t = e;
          exceptionThrown = true;
        }

        if (!exceptionThrown) {
          if (scan == null) {
            if (LOG.isTraceEnabled()) LOG.trace("openScanner - txId " + transId + ", scan is null");
            npe = new NullPointerException("openScanner - txId " + transId + ", scan is null ");
            ioe =  new IOException("Invalid arguments to openScanner", npe);
            exceptionThrown = true;
          }
          else
          {
            try {
//              scan.getAttribute(Scan.SCAN_ATTRIBUTES_METRICS_ENABLE);
              scan.setScanMetricsEnabled(true);
              prepareScanner(scan);
            } catch (Throwable e) {
              if (LOG.isWarnEnabled()) LOG.warn("openScanner - txId " + transId
                  + ", scan Caught exception ", e);
              t = e;
              exceptionThrown = true;
            }
          }
        }
        if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
          time1 = System.currentTimeMillis();

        if (!exceptionThrown) {
          try {
            Object[] checkResult = checkLockedInGetScanner(scan, isolationLevel, lockMode);
            scanner = getScanner(transId, startId, skipScanConflict, scan, savepointId, pSavepointId, isolationLevel, lockMode, false, implicitSavepoint, checkResult, query);

            if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
              time2 = System.currentTimeMillis();
            if (scanner != null) {
              if (LOG.isTraceEnabled()) LOG.trace("openScanner - txId " + transId + ", called getScanner, scanner is " + scanner);
              // Add the scanner to the map
              scannerId = addScanner(transId, scanner, this.m_Region, checkResult);
              if (LOG.isTraceEnabled()) LOG.trace("openScanner - txId " + transId + ", called addScanner, scanner id " + scannerId + ", skipScanConflict " + skipScanConflict + ", region " + m_regionDetails);
            }
            else
              if (LOG.isTraceEnabled()) LOG.trace("openScanner - txId " + transId + ", getScanner returned null, scanner id " + scannerId + ", region " + m_regionDetails);
       
          } catch (LeaseStillHeldException llse) {
/*
            try {
                scannerLeases.cancelLease(getScannerLeaseId(scannerId));
              } catch (LeaseException le) {
                  if (LOG.isTraceEnabled()) LOG.trace("getScanner failed to get a lease " + scannerId);
              }
*/
            LOG.error("openScanner - txId " + transId + ", getScanner Error opening scanner, ", llse);
            exceptionThrown = true;
            lse = llse;
          } catch (IOException e) {
            if (!isLockException(e)) {
                LOG.error("openScanner - txId " + transId + ", regionName " + m_regionName + ", getScanner Error opening scanner, ", e);
            }
            exceptionThrown = true;
            ioe = e;
          }
        }

        if (LOG.isTraceEnabled()) LOG.trace("openScanner - txId " + transId + ", scanner id " + scannerId + ", region " + m_regionDetails);
      }
    }

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.OpenScannerResponse.Builder openResponseBuilder = OpenScannerResponse.newBuilder();

    openResponseBuilder.setScannerId(scannerId);
    openResponseBuilder.setHasException(false);

    if (t != null)
    {
      openResponseBuilder.setHasException(true);
      openResponseBuilder.setException(t.toString());
    }

    if (ioe != null)
    {
      openResponseBuilder.setHasException(true);
      openResponseBuilder.setException(ioe.toString());
    }

    if (lse != null)
    {
      openResponseBuilder.setHasException(true);
      openResponseBuilder.setException(lse.toString());
    }

    if (mue != null)
    {
      if (LOG.isTraceEnabled()) LOG.trace("openScanner - performing memoryPercentage " + memoryPercentage + ", posting memory usage exceeds indicated percentage");
      openResponseBuilder.setHasException(true);
      openResponseBuilder.setException(mue.toString());
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transId, false);
      long timeCost = System.currentTimeMillis();
      openResponseBuilder.setCoproSTime(startTime);
      openResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[21] += timeCost;
      callCount[21]++;
      costStats.callCountPlus(22L);
      costStats.sumCostPlus(22L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " openScanner txID " + transId + " CC " + callCount[21] + " ATC " + (costSum[21] / callCount[21]) + " TC " + timeCost + " time1 " + (time1 - startTime) + " time2 " + (time2 - time1));
          }
    }

    OpenScannerResponse oresponse = openResponseBuilder.build();
    done.run(oresponse);
  }
  
    public  boolean checkWriteLock(long tid, byte[] s, byte[] e ) {
        boolean fulltablescan = false;
        boolean waitLockIsFree = false;
	Long tk = tid;
        long lockts = 0L;

          if( tmpRangeLockTime.containsKey(tk) )
	  {
            Long trid = tmpRangeLockTime.get(tk);
            if(!transactionsById.containsKey(trid))
              waitLockIsFree = true;
	  }

          if(waitLockIsFree) {
            long currentts = TrxEnvironmentEdgeManager.currentTime();
            if(currentts - maxWriteLockFreeTs > 200 && maxWriteLockFreeTs != 0L) //for 0.2 seconds I still cannot get lock , it means starve
            {
              if (LOG.isWarnEnabled()) {
                  LOG.warn("LOCKDBG: give up to get write lock due to starvation for tid " + tid);
              }
              tmpRangeLockTime.remove(tk);
              return false;
            }
          }

	  if(( Bytes.equals(s,HConstants.EMPTY_START_ROW) || Bytes.equals(e,HConstants.EMPTY_END_ROW )) && tmpWriteLockHashmap.size() > 0 )
          {
             fulltablescan = true;
          }

	  Iterator iter = tmpWriteLockHashmap.entrySet().iterator();  
	  while(iter.hasNext())
	  {
	      Map.Entry<ByteArrayKey, trafLockInfo> entry = (Map.Entry<ByteArrayKey, trafLockInfo>) iter.next();  
		  ByteArrayKey k = entry.getKey();
                  trafLockInfo ti = entry.getValue();
		  if( (((Bytes.compareTo(s, k.getBytesArray()) < 0) && Bytes.compareTo(e,k.getBytesArray()) >0) ||
		       Bytes.equals(s,k.getBytesArray()) ||
			   Bytes.equals(e,k.getBytesArray()) ) || fulltablescan == true)
                  {
                     if(ti.getTid() != tid && !ti.isRead()) {
                           if( !tmpRangeLockTime.containsKey(tid) ) {
                             //put the tid into the tmpRangLockTime list
                             tmpRangeLockTime.put( tk, ti.getTid());
                           }	
			   return true;
			}
                  }
	  }
	  return false;
	}
	
    public static String bytesToHexString(byte[] src) {
        StringBuilder stringBuilder = new StringBuilder("");
        if (src == null || src.length <= 0) {
            return null;
        }
        for (int i = 0; i < src.length; i++) {
            int v = src[i] & 0xFF;
            stringBuilder.append("0x");

            String hv = Integer.toHexString(v);
            if (hv.length() < 2) {
                stringBuilder.append(0);
            }
            stringBuilder.append(hv);
            if (i != src.length-1) {
                stringBuilder.append(",");

            }
        }
        return stringBuilder.toString();
    }
  @Override
  public void performScan(RpcController controller,
                          PerformScanRequest request,
                          RpcCallback<PerformScanResponse> done) {

    boolean hasMore = true;
    RegionScanner scanner = null;
    Throwable t = null;
    ScannerTimeoutException ste = null;
    OutOfOrderProtocolException oop = null;
    OutOfOrderScannerNextException ooo = null;
    UnknownScannerException use = null;
    MemoryUsageException mue = null;
    LeaseStillHeldException lse = null;
    CallerDisconnectedException cde = null;
    IOException ioe = null;
    Exception ne = null;
    List<Cell> cellResults = new ArrayList<Cell>();
    List<Result> results = new ArrayList<Result>();
    org.apache.hadoop.hbase.client.Result result = null;

    long scannerId = request.getScannerId();
    long transId = request.getTransactionId();
    long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
    long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
    boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
    boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());

    long startId = request.getStartId();
    boolean skipScanConflict = request.getSkipScanConflict();
    boolean autoOpen = request.getAutoOpen();
    Scan scan = null;
    int isolationLevel = request.getIsolationLevel();
    int lockMode = request.getLockMode();

    int numberOfRows = request.getNumberOfRows();
    boolean closeScanner = request.getCloseScanner();
    boolean scannerClosed = false;
    long nextCallSeq = request.getNextCallSeq();
    long count = 0L;
    boolean shouldContinue = true;
    boolean lockViolation = false;
    TransactionalRegionScannerHolder rsh = null;

    boolean exceptionThrown = false;
    boolean regionMatched = false;
    long time1 = 0, time2 = 0, time3 = 0, time4 = 0;
    long tmpTime = 0, preTime, startTime = preTime = System.currentTimeMillis();
    String query = Bytes.toString(request.getQueryContext().toByteArray());

    if (LOG.isDebugEnabled()) LOG.debug("performScan ENTRY - txId " + transId
            + ", savepointId " + savepointId + " implicit savepoint " + implicitSavepoint
            + ", scanner id " + scannerId
            + ", requested rows " + numberOfRows + ", nextCallSeq " + nextCallSeq
            + ", closeScanner " + closeScanner + ", autoOpen " + autoOpen + ", isolationLevel " + isolationLevel + ", lockMode " + lockMode + ", region is " + m_regionDetails + ", query " + query);
    
      if (memoryThrottle == true) {
        if(memoryUsageWarnOnly == true)  {
            if (LOG.isWarnEnabled()) {
                LOG.warn("performScan - performing memoryPercentage " + memoryPercentage + ", warning memory usage exceeds indicated percentage");
            }
        }
        else {
          if (LOG.isTraceEnabled()) LOG.trace("performScan - performing memoryPercentage " + memoryPercentage + ", generating memory usage exceeds indicated percentage");
          mue = new MemoryUsageException("performScan memory usage exceeds " + memoryUsageThreshold + " percent, trxId is " + transId);
        }
      }
      else
      {
        // If nextCallSeq is zero, then this is the first performScan
        // operation for this region and we should not expect
        // an existing, open, scanner or TransactionState object.
        // Otherwise, there should be a matching key in the transactionsById map
        // associated with this transaction id.  If there is not
        // one, then we lost a request somewhere, or the initial 
        // openScanner call for the transaction id was not called.
        // This is a protocol error requiring openScanner,
        // performScan followed by a closeScanner.

        if (nextCallSeq != 0) {
           Long key = getTransactionalUniqueId(transId);
           boolean keyFound = transactionsById.containsKey(key);

           if (keyFound != true)
           {
             if (LOG.isTraceEnabled()) LOG.trace("performScan - Unknown transaction [" + transId
                 + "] in region [" + m_regionDetails
                 + "], will create an OutOfOrderProtocol exception ");
             oop = new OutOfOrderProtocolException("performScan does not have an active transaction with an open scanner, txId: " + transId);
           }
        }

        if (m_regionName.equals(request.getRegionName().toStringUtf8())) {
          regionMatched = true;
        }

        if (oop == null && regionMatched) {
            try {
                scanner = getScanner(scannerId, nextCallSeq);
                if (LOG.isTraceEnabled()) {
                    LOG.trace("performScan getScanner - txID " + transId + " scannerId " + scannerId + " nextCallSeq " + nextCallSeq + " scanner is null " + (scanner == null) + " region " + m_regionName);
                }
            } catch (Throwable e) {
                if (LOG.isWarnEnabled()) LOG.warn("performScan getScanner - txId " + transId
                    + " ,scannerId " + scannerId + " nextCallSeq " + nextCallSeq + " regoin " + m_regionName + ", Caught exception ", e);
                t = e;
                exceptionThrown = true;
            }

        // If we are supposed to automatically open the scanner and this is the first perform scan request
        // for this region, which is signified by nextCallSeq being zero, then we open the scanner.
        // Subsequent scans would have nextCallSeq <> 0 and we will skip the open and reuse the existing scanner.
        if (autoOpen && (scanner == null)){
           try {

              scan = ProtobufUtil.toScan(request.getScan());
              //check the write lock for ta23
              if(enableTmpWriterLock == true) {
                 boolean retry = false;
                 int lockRetryCount = 0;
                 do {  //simple spin lock , try up to maxForUpdateScanLockRetryTimes times , which is 60 seconds for now
                   synchronized(tmpWriteLockHashmap){
                       if(checkWriteLock(transId,scan.getStartRow(),scan.getStopRow()) == true) { // locked by some other writer
                          Thread.sleep(1);
                          lockRetryCount++;
                          retry = true;
                       }
                       else
                       {
                          Long tk  = transId;
                          tmpRangeLockTime.remove(tk); //I no need to wait on anyone else now

                          if( enableTmpReadWriterLock == true )
                          {
                              tmpLockRange(scan.getStartRow(),scan.getStopRow(),transId);
                          }
                          retry = false; break;
                       }
                   }
	        } while(retry == true && lockRetryCount < maxForUpdateScanLockRetryTimes );
                if(retry == true)
                {
                  if (LOG.isWarnEnabled()) {
                      LOG.warn("LOCKDBG: time out to get lock for a range scan, continue without lock tid " + transId);
                  }
                  lockViolation = true;
                }
                EndpointCostStats costStats = getEndpointCostStats(transId, false);
                costStats.lockTimeCostPlus (lockRetryCount);
            }
              if (scan == null){
                if (LOG.isTraceEnabled()) LOG.trace("performScan openScanner - txId " + transId + ", scan was null");
              }
           } catch (Throwable e) {
              if (LOG.isWarnEnabled()) LOG.warn("performScan openScanner - txId " + transId
                 + ", Caught exception ", e); t = e;
              exceptionThrown = true;
           } try { scan.setScanMetricsEnabled(true); prepareScanner(scan);
           } catch (Throwable e) {
              if (LOG.isWarnEnabled()) LOG.warn("performScan openScanner - txId " + transId
                  + ", scan Caught exception ", e);
              t = e;
              exceptionThrown = true;
           }

           try {
              Object[] checkResult = checkLockedInGetScanner(scan, isolationLevel, lockMode);
	      if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                preTime = System.currentTimeMillis();
	        time1 = preTime - startTime;
              }
              scanner = getScanner(transId, startId, skipScanConflict, scan, savepointId, pSavepointId, isolationLevel, lockMode, lockViolation, implicitSavepoint, checkResult, query);

	      if (LOG.isDebugEnabled())
	         LOG.debug("txID: " + transId + " isolationLevel: " + isolationLevel + " lockMode: " + lockMode + " hasLocked: " + checkResult[1]);
              if (scanner != null) {
                 if (LOG.isTraceEnabled()) LOG.trace("performScan openScanner - txId " + transId + ", called getScanner, scanner is " + scanner);
                 // Add the scanner to the map
                 scannerId = addScanner(transId, scanner, this.m_Region, checkResult);
                 if (LOG.isTraceEnabled()) LOG.trace("performScan openScanner - txId " + transId + ", called addScanner, scanner id " + scannerId + ", region " + m_regionDetails);
              }
              else {
                 if (LOG.isTraceEnabled()) LOG.trace("performScan openScanner - txId " + transId + ", getScanner returned null, scanner id " + scannerId + ", region " + m_regionDetails);
              }

           } catch (LeaseStillHeldException llse) {

              LOG.error("performScan openScanner - txId " + transId + ", getScanner Error opening scanner, ", llse);
              exceptionThrown = true;
              lse = llse;
           } catch (IOException e) {
              if (!isLockException(e)) {
                  LOG.error("performScan openScanner - txId " + transId + ", regionName " + m_regionName + ", getScanner Error opening scanner, ", e);
              }
              exceptionThrown = true;
              ioe = e;
           }
        }

        if (exceptionThrown == false) {
        
        // Should have a scanner opened now
        boolean hasLocked = false;
        boolean skipLock = false;
        boolean ok_locked = false;
        int isoLevel = 0;
        boolean updatableSelect = true;
        int scanType = -1;
        try {
          if (LockConstants.ENABLE_ROW_LEVEL_LOCK) {
              rsh = scanners.get(scannerId);
              if (rsh != null) {
                  hasLocked = rsh.hasLocked;
                  scanType = rsh.scanType;
                  ok_locked = rsh.ok_locked;
              }
              skipLock = skipLock();
              isoLevel = transformIsolationLevel(isolationLevel);
          }

          if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
            tmpTime = System.currentTimeMillis();
            time2 = tmpTime - preTime;
            preTime = tmpTime;
           }
          scanner = getScanner(scannerId, nextCallSeq);
          if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
            tmpTime = System.currentTimeMillis();
            time3 = tmpTime - preTime;
            preTime = tmpTime;
          }
          if (scanner != null)
          {
            if (LOG.isTraceEnabled()) LOG.trace("performScan - txId " + transId + ", scanner id " + scannerId + ", scanner is not null" + " LockConstants.ENABLE_ROW_LEVEL_LOCK " + LockConstants.ENABLE_ROW_LEVEL_LOCK);
            // whether it is for update or update or delete statement
            int scanLockMode = LockMode.LOCK_NO;
            int scanCacheLockMode = LockMode.LOCK_NO;
            if (LockConstants.ENABLE_ROW_LEVEL_LOCK && !skipLock) {
                checkAndCreateLockManager();
                if (lockMode != LockMode.LOCK_U) {
                    updatableSelect = false;
                }
                if (!hasLocked && (!updatableSelect) && (isoLevel == READCOMMITTED)) {
                    this.lockManager.disableEsca(transId);
                }
                if (updatableSelect) {
                    scanLockMode = lockMapping[isoLevel][SEL_UPD_ROW_LOCK];
                } else {
                    scanLockMode = lockMapping[isoLevel][SEL_ROW_LOCK];
                }
                if (scanType == FULL_TABLE_SCAN && LockConstants.ENABLE_TABLELOCK_FOR_FULL_SCAN) {
                    if (updatableSelect) {
                        scanCacheLockMode = lockMapping[isoLevel][SEL_UPD_TAB_LOCK];
                    } else {
                        scanCacheLockMode = lockMapping[isoLevel][SEL_TAB_LOCK];
                    }
                } else {
                    scanCacheLockMode = LockMode.LOCK_RS;
                }
            }
            RetCode retCode = null;
            boolean skipCurrentRow = false;
            while (shouldContinue) {
              skipCurrentRow = false;
              if (LockConstants.ENABLE_ROW_LEVEL_LOCK && !skipLock && !hasLocked && rsh.failedRow != null) {
                  result = rsh.failedRow;
                  try {
                      retCode = tryLock(transId, savepointId, pSavepointId, result.getRow(), scanLockMode, implicitSavepoint, query);
                  } catch (IOException e) {
                      throw e;
                  }

                  rsh.failedRow = null;
                  // check current row delete or update by other transaction
                  if (retCode == RetCode.OK_WITHRETRY) {
                      checkAndGetRow(transId, savepointId, result.getRow(), cellResults);
                      if (cellResults.isEmpty()) {
                          skipCurrentRow = true;
                      } else {
                          result = Result.create(cellResults);
                          cellResults.clear();
                      }
                  }
                  if ((isoLevel == READCOMMITTED && !updatableSelect) || skipCurrentRow) {
                      if (retCode != RetCode.OK_LOCKED) {
                          unLock(transId, savepointId, result.getRow(), scanLockMode);
                      }
                  }
                 
                  if (!skipCurrentRow) {
                      results.add(result);
                      count++;
                  } else if (LOG.isTraceEnabled()) {
                      LOG.trace("performScan txId " + transId + " savepointId " + savepointId + " row " + getRowidFromRowKey(result.getRow()) + " was skipped (loc 1)");
                  }
                  skipCurrentRow = false;
              }
              if (LockConstants.ENABLE_ROW_LEVEL_LOCK && !skipLock && !hasLocked && (count == numberOfRows - 1)) {
                  try {
                      checkMemeoryUsage(transId);
                      retCode = lock(transId, scanCacheLockMode, query);
                      hasMore = scanner.next(cellResults);
                  } catch (Exception e) {
                      if (scanCacheLockMode == LockMode.LOCK_RS) {
                          LOG.error("failed to get LOCK_RS(loc 1) " + transId + " " + m_regionName);
                      } else {
                          LOG.error("failed to get LOCK(loc 1) " + scanCacheLockMode + " " + transId + " " + m_regionName);
                      }
                      throw e;
                  } finally {
                      if (retCode == RetCode.OK || retCode == RetCode.OK_WITHRETRY) {
                          unLock(transId, scanCacheLockMode);
                      }
                  }
              } else {
                  checkMemeoryUsage(transId);
                  hasMore = scanner.next(cellResults);
              }
              result = Result.create(cellResults);
              cellResults.clear();

              if (!result.isEmpty()) {
                //try lock
                if (LockConstants.ENABLE_ROW_LEVEL_LOCK && !skipLock && !hasLocked) {
                    try {
                        retCode = tryLock(transId, savepointId, pSavepointId, result.getRow(), scanLockMode, implicitSavepoint, query);
                    } catch (IOException e) {
                        hasMore = true;//do rescan for this row
                        rsh.failedRow = result;
                        throw e;
                    }
                    // check current row delete or update by other transaction
                    if (retCode == RetCode.OK_WITHRETRY) {
                        checkAndGetRow(transId, savepointId, result.getRow(), cellResults);
                        if (cellResults.isEmpty()) {
                            skipCurrentRow = true;
                        } else {
                            result = Result.create(cellResults);
                            cellResults.clear();
                        }
                    }
                    if ((isoLevel == READCOMMITTED && !updatableSelect) || skipCurrentRow) {
                        if (retCode != RetCode.OK_LOCKED) {
                            unLock(transId, savepointId, result.getRow(), scanLockMode);
                        }
                    }
                }
                if (!skipCurrentRow) {
                    results.add(result);
                    count++;
                } else if (LOG.isTraceEnabled()) {
                    LOG.trace("performScan txId " + transId + " savepointId " + savepointId + " row " + getRowidFromRowKey(result.getRow()) + " was skipped (loc 2)");
                }
              }

              if (count == numberOfRows || !hasMore)
                shouldContinue = false;
            }
            if (RSConstants.RECORD_SCAN_ROW_THRESHOLD >=0 ) {
                if (LOG.isInfoEnabled()) {
                    LOG.info("record scan rows performScan - txId " + transId + ", scanner id " + scannerId + ", row count is " + count
                    + ", hasMore is " + hasMore + ", result " + result.isEmpty() + " region " + m_regionName);
                }
            }
            if (LOG.isTraceEnabled()) LOG.trace("performScan - txId " + transId + ", scanner id " + scannerId + ", row count is " + count
                    + ", hasMore is " + hasMore + ", result " + result.isEmpty() + " region " + m_regionDetails);
          }
          else
          {
            if (LOG.isTraceEnabled()) LOG.trace("performScan - txId " + transId + ", scanner id " + scannerId + transId + ", scanner is null");
          }
       } catch(OutOfOrderScannerNextException ooone) {
         LOG.error("performScan - txId " + transId + ", scanner id " + scannerId + " Caught OutOfOrderScannerNextException  ", ooone);
         ooo = ooone;
         exceptionThrown = true;
       } catch(ScannerTimeoutException cste) {
         LOG.error("performScan - txId " + transId + ", scanner id " + scannerId + " Caught ScannerTimeoutException  ", cste);
         ste = cste;
         exceptionThrown = true;
       } catch(CallerDisconnectedException ccde) {
         LOG.error("performScan - txId " + transId + ", scanner id " + scannerId + " Caught CallerDisconnectedException  ", ccde);
         cde = ccde;
         exceptionThrown = true;
       } catch(Throwable e) {
         if (!isLockException(e)) {
             LOG.error("performScan - txId " + transId + ", scanner id " + scannerId + ", regionName " + m_regionName + " Caught throwable exception ", e);
         }
         t = e;
         exceptionThrown = true;
       }
       finally {
         if (LockConstants.ENABLE_ROW_LEVEL_LOCK && !hasLocked && !skipLock) {
             checkAndCreateLockManager();
             if (isoLevel == READCOMMITTED && !updatableSelect && !skipLock) {
                 this.lockManager.enableEsca(transId);
             }
         }
         if (scanner != null) {
           try {
             // If SQL cancels a scan, we will get a CallerDisconnectedException and we should close the
             // scanner to prevent an orphan scanner, which could impede a table drop.
             // executor test 106 causes this, for example
             if (cde != null || (closeScanner && (! hasMore))) {
               if (LOG.isTraceEnabled()) LOG.trace("performScan - txId " + transId + ", scanner id " + scannerId + ", close scanner was true, closing the scanner" + ", closeScanner is " + closeScanner + ", region is " + m_regionDetails);
               if (LockConstants.ENABLE_ROW_LEVEL_LOCK && !skipLock && hasLocked && scanType == FULL_TABLE_SCAN && LockConstants.ENABLE_TABLELOCK_FOR_FULL_SCAN && isoLevel == READCOMMITTED && !ok_locked && !updatableSelect) {
                   unLock(transId, savepointId, lockMapping[isoLevel][SEL_TAB_LOCK]);
                   lock(transId, savepointId, pSavepointId, lockMapping[isoLevel][SEL_META_TAB_LOCK], implicitSavepoint, query);
               }
               removeScanner(scannerId);
               scanner.close();
               scannerClosed = true;
               scannerId = -1;
/*
               try {
                 scannerLeases.cancelLease(getScannerLeaseId(scannerId));
               } catch (LeaseException le) {
                 // ignore
                 if (LOG.isTraceEnabled()) LOG.trace("performScan failed to get a lease " + scannerId);
               }
*/
             }
           } catch(Exception e) {
             LOG.error("performScan -  transaction id " + transId + ", Caught general exception " + e.getMessage() + " " + stackTraceToString(e));
             ne = e;
             exceptionThrown = true;
           }
         }
       }
       }

       if (exceptionThrown == false)
       {
           if (! scannerClosed){
           rsh = scanners.get(scannerId);

           nextCallSeq++;
 
           if (rsh == null)
           {
            if (LOG.isTraceEnabled()) LOG.trace("performScan - txId " + transId + ", performScan rsh is null, UnknownScannerException for scannerId: " + scannerId + ", nextCallSeq was " + nextCallSeq + ", for region " + m_regionDetails);
              use =  new UnknownScannerException(
                 "ScannerId: " + scannerId + ", was scanner already closed?, transaction id " + transId + ", nextCallSeq was " + nextCallSeq + ", for region " + m_regionDetails);
           }
           else
           {
             rsh.nextCallSeq = nextCallSeq;

             if (LOG.isTraceEnabled()) LOG.trace("performScan exit - txId " + transId + ", scanner id " + scannerId + " row count " + count + ", region " + m_regionDetails
                    + ", nextCallSeq " + nextCallSeq + ", rsh.nextCallSeq " + rsh.nextCallSeq + ", close scanner is " + closeScanner);

           }
         }
       }
     }
   }
   org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.PerformScanResponse.Builder performResponseBuilder = PerformScanResponse.newBuilder();
   performResponseBuilder.setHasMore(hasMore);
   performResponseBuilder.setNextCallSeq(nextCallSeq);
   performResponseBuilder.setCount(count);
   performResponseBuilder.setScannerId(scannerId);
   performResponseBuilder.setScannerIsClosed(scannerClosed);
   performResponseBuilder.setHasException(false);

    //revert this for mantis-23910
    //if (exceptionThrown == false && results != null)
    if (results != null)
    {
      if (!results.isEmpty()) {
        for (Result r: results) {
          performResponseBuilder.addResult(ProtobufUtil.toResult(r));
        }
      }
    }

    if (t != null)
    {
      performResponseBuilder.setHasMore(false);
      performResponseBuilder.setHasException(true);
      performResponseBuilder.setException(t.toString());
    }

    if (ste != null)
    {
      performResponseBuilder.setHasMore(false);
      performResponseBuilder.setHasException(true);
      performResponseBuilder.setException(ste.toString());
    }

    if (cde != null)
    {
      performResponseBuilder.setHasMore(false);
      performResponseBuilder.setHasException(true);
      performResponseBuilder.setException(cde.toString());
    }

    if (ne != null)
    {
      performResponseBuilder.setHasMore(false);
      performResponseBuilder.setHasException(true);
      performResponseBuilder.setException(ne.toString());
    }

    if (ooo != null)
    {
      performResponseBuilder.setHasMore(false);
      performResponseBuilder.setHasException(true);
      performResponseBuilder.setException(ooo.toString());
    }

    if (use != null)
    {
      performResponseBuilder.setHasMore(false);
      performResponseBuilder.setHasException(true);
      performResponseBuilder.setException(use.toString());
    }

    if (oop != null)
    {
      performResponseBuilder.setHasMore(false);
      if (TrxRegionEndpoint.suppressOutOfOrderProtocolException == false)
      {
        performResponseBuilder.setHasException(true);
        performResponseBuilder.setException(oop.toString());
        if (LOG.isWarnEnabled()) {
            LOG.warn("performScan - OutOfOrderProtocolExc, transaction was not found, txId: " + transId + ", return exception" + ", region " + m_regionDetails);
        }
      }
      else
        if (LOG.isWarnEnabled()) {
            LOG.warn("performScan - suppressing OutOfOrderProtocolExc, transaction was not found, txId: " + transId + ", region " + m_regionDetails);
        }
    }

    if (mue != null)
    {
      if (LOG.isTraceEnabled()) LOG.trace("performScan - performing memoryPercentage " + memoryPercentage + ", posting memory usage exceeds indicated percentage");
      performResponseBuilder.setHasMore(false);
      performResponseBuilder.setHasException(true);
      performResponseBuilder.setException(mue.toString());
    }

    if (ioe != null)
    {
      performResponseBuilder.setHasMore(false);
      performResponseBuilder.setHasException(true);
      performResponseBuilder.setException(ioe.toString());
    }

    if (false == regionMatched)
    {
      if (LOG.isWarnEnabled()) {
          LOG.warn("performScan - Regions' name mismatch. Input name is: "
             + request.getRegionName().toStringUtf8() + " and actual name is: " +  m_regionName);
      }
      performResponseBuilder.setHasMore(false);
      performResponseBuilder.setHasException(true);
      performResponseBuilder.setException(REGION_NAME_MISMATCH_EXCEPTION);
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transId, false);
      long timeCost = System.currentTimeMillis();
      performResponseBuilder.setCoproSTime(startTime);
      performResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[22] += timeCost;
      callCount[22]++;
      costStats.callCountPlus(23L);
      costStats.sumCostPlus(23L, timeCost);
      if (rsh == null)
        rsh = scanners.get(scannerId);
      if (rsh != null)
        rsh.scanCost += timeCost;
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " performScan txID " + transId + " CC " + callCount[22] + " ATC " + (costSum[22] / callCount[22]) + " TC " + timeCost + " time1 " + time1 + " time2 " + time2
                + " time3 " + time3 + " time4 " + time4);
          }
    }

    PerformScanResponse presponse = performResponseBuilder.build();
    done.run(presponse);
  }

  public void deleteTlogEntries(RpcController controller,
          TlogDeleteRequest request, RpcCallback<TlogDeleteResponse> done) {
    boolean hasMore = true;
    InternalScanner scanner = null;
    Throwable t = null;
    ScannerTimeoutException ste = null;
    OutOfOrderScannerNextException ooo = null;
    UnknownScannerException use = null;
    MemoryUsageException mue = null;
    Exception ne = null;
    Scan scan = null;
    List<Cell> cellResults = new ArrayList<Cell>();
    org.apache.hadoop.hbase.client.Result result = null;
    long lvAsn = request.getAuditSeqNum();
    boolean lvAgeCommitted = request.getAgeCommitted();
    long startTime = System.currentTimeMillis();

    try{
       scan = ProtobufUtil.toScan(request.getScan());
       // use an internal scanner to perform scanning.
       scanner = m_Region.getScanner(scan);
    }
    catch (Exception e){
       if (LOG.isErrorEnabled()) LOG.error("deleteTlogEntries Exception in region: "
          + m_regionDetails + " getting scanner ", e );
    }

    long count = 0L;
    boolean shouldContinue = true;

    long time1 = System.currentTimeMillis();
    if (LOG.isTraceEnabled()) LOG.trace("deleteTlogEntries ENTRY.  Records older than " + lvAsn
        + " will be deleted in region: " + m_regionDetails);

    try {
       if (scanner != null){
          if (LOG.isTraceEnabled()) LOG.trace("deleteTlogEntries - scanner is not null");
          while (shouldContinue) {
             hasMore = scanner.next(cellResults);
             result = Result.create(cellResults);
             if (!result.isEmpty()) {
                for (Cell cell : result.rawCells()) {
                   String valueString = new String(CellUtil.cloneValue(cell));
                   StringTokenizer st = new StringTokenizer(valueString, ",");
                   if (st.hasMoreElements()) {
                      String asnToken = st.nextElement().toString();
                      String transidToken = st.nextElement().toString();
                      String stateToken = st.nextElement().toString();
                      if (LOG.isTraceEnabled()) LOG.trace("deleteTlogEntries transidToken: "
                                   + transidToken + " asnToken: " + asnToken);
                      if (Long.parseLong(asnToken) < lvAsn) {
                         if ( (stateToken.contains(TransState.STATE_FORGOTTEN.toString())) ||
                              (stateToken.equals(TransState.STATE_COMMITTED.toString()) && (lvAgeCommitted)) ||
                              (stateToken.equals(TransState.STATE_ABORTED.toString()) && (lvAgeCommitted))) {

                            if (LOG.isTraceEnabled()) LOG.trace("Deleting transid: " + transidToken
                                  + " from region: " + m_regionDetails + " with state: " + stateToken);
                            try {
                               Delete d = new Delete(result.getRow());
                               d.setDurability(Durability.SKIP_WAL);
                               m_Region.delete(d);
                            }
                            catch (Exception e) {
                               if (LOG.isWarnEnabled()) {
                                   LOG.warn("deleteTlogEntries -"
                                   + " txId " + transidToken + ", Executing delete caught an exception ", e);
                               }
                               throw new IOException("deleteTlogEntries -"
                                   + " txId " + transidToken + ", Executing delete caught an exception " + e.toString());
                            }
                            count++;
                         }
                      } else {
                         if (LOG.isTraceEnabled()) LOG.trace("deleteTlogEntries Ending scan at asn: " + asnToken
                                    + ", transid: " + transidToken +
                                    " because it is not less than the comparator: " + lvAsn +
                                    " in region: " + m_regionDetails);
                         shouldContinue = false;
                         break;
                      }
                   } // if (st.hasMoreElements()
                } // for (Cell cell : result.rawCells()
             } // if (!result.isEmpty()
             cellResults.clear();

             if (!hasMore){
                shouldContinue = false;
             }
          } // while (shouldContinue)
          if (LOG.isTraceEnabled()) LOG.trace("deleteTlogEntries - count is " + count + ", hasMore is " + hasMore
                    + ", result " + result.isEmpty());
       }
       else {
          if (LOG.isTraceEnabled()) LOG.trace("deleteTlogEntries - scanner is null");
       }
    } catch(OutOfOrderScannerNextException ooone) {
       if (LOG.isWarnEnabled()) {
           LOG.warn("deleteTlogEntries - Caught OutOfOrderScannerNextException ", ooone);
       }
       ooo = ooone;
    } catch(ScannerTimeoutException cste) {
       if (LOG.isWarnEnabled()) {
           LOG.warn("deleteTlogEntries - Caught ScannerTimeoutException ", cste);
       }
       ste = cste;
    } catch(Throwable e) {
       if (LOG.isWarnEnabled()) {
           LOG.warn("deleteTlogEntries - Caught throwable exception ", e);
       }
       t = e;
    } finally {
       if (LOG.isTraceEnabled()) LOG.trace("deleteTlogEntries - closing the scanner, region is " + m_regionDetails);
       try{
          scanner.close();
       }
       catch(IOException ioe){
          if (LOG.isWarnEnabled()) {
              LOG.warn("deleteTlogEntries - exception closing the scanner ", ioe);
          }
       }
    }

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TlogDeleteResponse.Builder deleteResponseBuilder = TlogDeleteResponse.newBuilder();
    deleteResponseBuilder.setCount(count);
    deleteResponseBuilder.setHasException(false);

    if (t != null){
       deleteResponseBuilder.setHasException(true);
       deleteResponseBuilder.setException(t.toString());
    }

    if (ste != null){
       deleteResponseBuilder.setHasException(true);
       deleteResponseBuilder.setException(ste.toString());
    }

    if (ne != null){
       deleteResponseBuilder.setHasException(true);
       deleteResponseBuilder.setException(ne.toString());
    }

    if (ooo != null){
       deleteResponseBuilder.setHasException(true);
       deleteResponseBuilder.setException(ooo.toString());
    }

    if (use != null){
       deleteResponseBuilder.setHasException(true);
       deleteResponseBuilder.setException(use.toString());
    }

    if (mue != null){
       if (LOG.isTraceEnabled()) LOG.trace("deleteTlogEntries - performing memoryPercentage "
           + memoryPercentage + ", posting memory usage exceeds indicated percentage");
       deleteResponseBuilder.setHasException(true);
       deleteResponseBuilder.setException(mue.toString());
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      long timeCost = System.currentTimeMillis();
      deleteResponseBuilder.setCoproSTime(startTime);
      deleteResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[23] += timeCost;
      callCount[23]++;
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " deleteTlogEntries CC " + callCount[23] + " ATC " + (costSum[23] / callCount[23]) + " TC " + timeCost + " time1 " + (time1 - startTime));
          }
    }

    TlogDeleteResponse TlogDel_response = deleteResponseBuilder.build();
    done.run(TlogDel_response);
 }

  public void setStoragePolicy(RpcController controller,
                                             TrafSetStoragePolicyRequest request,
                                             RpcCallback<TrafSetStoragePolicyResponse> done) {
    String path = request.getPath();
    String policy = request.getPolicy();
    if (LOG.isTraceEnabled()) LOG.trace("setStoragePolicy ENTRY. path " +  path + " policy " + policy );
    long startTime = System.currentTimeMillis();

    IOException t=null;
    try {
      invokeSetStoragePolicy(fs, path, policy);
    }
    catch (IOException e) {
      t = e; 
    }
  
    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TrafSetStoragePolicyResponse.Builder setStoragePolicyResponseBuilder =
      org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TrafSetStoragePolicyResponse.newBuilder();

    if(t != null)
    {
      LOG.error("setStoragePolicy error : " + t.toString() );
      setStoragePolicyResponseBuilder.setStatus(false);
      setStoragePolicyResponseBuilder.setException(t.toString());
    }
    else
    {
      setStoragePolicyResponseBuilder.setStatus(true);
      setStoragePolicyResponseBuilder.setException("");
    }
   
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      long timeCost = System.currentTimeMillis();
      setStoragePolicyResponseBuilder.setCoproSTime(startTime);
      setStoragePolicyResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[24] += timeCost;
      callCount[24]++;
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " setStoragePolicy CC " + callCount[24] + " ATC " + (costSum[24] / callCount[24]) + " TC " + timeCost);
          }
    }

    TrafSetStoragePolicyResponse resp = setStoragePolicyResponseBuilder.build();
    done.run(resp);
  }

  private static void invokeSetStoragePolicy(final FileSystem fs, final String pathstr,
      final String storagePolicy)
       throws IOException {
        Path path = new Path(pathstr);
        if(hdfsSetStoragePolicyMethod == null)
             throw new IOException(hdfsSetStoragePolicyReflectErrorMsg);
        if (hdfsSetStoragePolicyMethod != null) {
          try {
            hdfsSetStoragePolicyMethod.invoke(fs, path, storagePolicy);
            if (LOG.isDebugEnabled()) {
              LOG.debug("Set storagePolicy=" + storagePolicy + " for path=" + path);
            }
          } catch (Exception e) {
               LOG.error("invoke set storage policy error : " , e);
               throw new IOException(e);
          }
        }
    }


  public void getTransactionStatesPriorToAsn(RpcController controller,
                                             TlogTransactionStatesFromIntervalRequest request,
                                             RpcCallback<TlogTransactionStatesFromIntervalResponse> done) {

     boolean hasMore = true;
     InternalScanner scanner = null;
     Throwable t = null;
     ScannerTimeoutException ste = null;
     OutOfOrderScannerNextException ooo = null;
     UnknownScannerException use = null;
     MemoryUsageException mue = null;
     Exception ne = null;
     Scan scan = null;
     List<Cell> cellResults = new ArrayList<Cell>();
     List<Result> results = new ArrayList<Result>();
     org.apache.hadoop.hbase.client.Result result = null;
     long lvAsn = request.getAuditSeqNum();
     long count = 0L;
     boolean shouldContinue = true;
     long startTime = System.currentTimeMillis();
     if (LOG.isTraceEnabled()) LOG.trace("getTransactionStatesPriorToAsn entries older than " + lvAsn + " will be returned, region is " + m_regionDetails);
     try{
        scan = ProtobufUtil.toScan(request.getScan());
        // use an internal scanner to perform scanning.
        scanner = m_Region.getScanner(scan);
     }
     catch (Exception e){
        if (LOG.isErrorEnabled()) LOG.error("getTransactionStatesPriorToAsn Exception in region: "
           + m_regionDetails + " getting scanner ", e );
     }
     long time1 = System.currentTimeMillis();

     try {
        if (scanner != null){
           if (LOG.isTraceEnabled()) LOG.trace("getTransactionStatesPriorToAsn - scanner is not null");
           while (shouldContinue) {
              hasMore = scanner.next(cellResults);
              result = Result.create(cellResults);
              if (!result.isEmpty()) {
                 for (Cell cell : result.rawCells()) {
                    String valueString = new String(CellUtil.cloneValue(cell));
                    StringTokenizer st = new StringTokenizer(valueString, ",");
                    if (st.hasMoreElements()) {
                       String asnToken = st.nextElement().toString() ;
                       String transidToken = st.nextElement().toString() ;
                       String stateToken = st.nextElement().toString() ;
                       if (LOG.isTraceEnabled()) LOG.trace("getTransactionStatesPriorToAsn Transid: " + transidToken + " has state: " + stateToken + " and ASN " + asnToken);
                       if (Long.parseLong(asnToken) < lvAsn) {
                          if (LOG.isTraceEnabled()) LOG.trace("adding transid: " + transidToken + " to result list");
                          results.add(result);
                          count++;
                       }
                    } // if (st.hasMoreElements()
                 } // for (Cell cell : result.rawCells()
              } // if (!result.isEmpty()
              cellResults.clear();

              if (!hasMore){
                 shouldContinue = false;
              }
           } // while (shouldContinue)
           if (LOG.isTraceEnabled()) LOG.trace("getTransactionStatesPriorToAsn - count is " + count + ", hasMore is " + hasMore
                      + ", result " + result.isEmpty());
        }
        else {
           if (LOG.isTraceEnabled()) LOG.trace("getTransactionStatesPriorToAsn - scanner is null");
        }
     } catch(OutOfOrderScannerNextException ooone) {
        if (LOG.isTraceEnabled()) LOG.trace("getTransactionStatesPriorToAsn - Caught OutOfOrderScannerNextException "
                    + ooone.getMessage() + " " + stackTraceToString(ooone));
        ooo = ooone;
     } catch(ScannerTimeoutException cste) {
        if (LOG.isTraceEnabled()) LOG.trace("getTransactionStatesPriorToAsn - Caught ScannerTimeoutException "
                    + cste.getMessage() + " " + stackTraceToString(cste));
        ste = cste;
     } catch(Throwable e) {
        if (LOG.isTraceEnabled()) LOG.trace("getTransactionStatesPriorToAsn - Caught throwable exception "
                    + e.getMessage() + " " + stackTraceToString(e));
        t = e;
     }
     finally {
        if (scanner != null) {
           try {
              if (LOG.isTraceEnabled()) LOG.trace("getTransactionStatesPriorToAsn - close scanner in region " + m_regionDetails);
              scanner.close();
           } catch(Exception e) {
              if (LOG.isTraceEnabled()) LOG.trace("getTransactionStatesPriorToAsn - Caught general exception " + e.getMessage() + " " + stackTraceToString(e));
              ne = e;
           }
        }
     }

     org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TlogTransactionStatesFromIntervalResponse.Builder statesFromIntervalResponseBuilder = TlogTransactionStatesFromIntervalResponse.newBuilder();
     statesFromIntervalResponseBuilder.setCount(count);
     statesFromIntervalResponseBuilder.setHasException(false);

     if (results != null){
        if (!results.isEmpty()) {
           for (Result r: results) {
              statesFromIntervalResponseBuilder.addResult(ProtobufUtil.toResult(r));
           }
        }
     }

     if (t != null){
        statesFromIntervalResponseBuilder.setHasException(true);
        statesFromIntervalResponseBuilder.setException(t.toString());
     }

     if (ste != null){
        statesFromIntervalResponseBuilder.setHasException(true);
        statesFromIntervalResponseBuilder.setException(ste.toString());
     }

     if (ne != null){
        statesFromIntervalResponseBuilder.setHasException(true);
        statesFromIntervalResponseBuilder.setException(ne.toString());
     }

     if (ooo != null){
        statesFromIntervalResponseBuilder.setHasException(true);
        statesFromIntervalResponseBuilder.setException(ooo.toString());
     }

     if (use != null){
        statesFromIntervalResponseBuilder.setHasException(true);
        statesFromIntervalResponseBuilder.setException(use.toString());
     }

     if (mue != null){
        if (LOG.isTraceEnabled()) LOG.trace("getTransactionStatesPriorToAsn - performing memoryPercentage " + memoryPercentage + ", posting memory usage exceeds indicated percentage");
        statesFromIntervalResponseBuilder.setHasException(true);
        statesFromIntervalResponseBuilder.setException(mue.toString());
     }

     if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      long timeCost = System.currentTimeMillis();
      statesFromIntervalResponseBuilder.setCoproSTime(startTime);
      statesFromIntervalResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[25] += timeCost;
      callCount[25]++;
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " getTransactionStatesPriorToAsn CC " + callCount[25] + " ATC " + (costSum[25] / callCount[25]) + " TC " + timeCost + " time1 " + (time1 - startTime));
          }
     }

     TlogTransactionStatesFromIntervalResponse sfi_response = statesFromIntervalResponseBuilder.build();
     done.run(sfi_response);
  }

  public void putTlog(RpcController controller, TlogWriteRequest request, RpcCallback<TlogWriteResponse> done) {
// The default response seems redundant
//     TlogWriteResponse response = TlogWriteResponse.getDefaultInstance();
     if (LOG.isTraceEnabled()) LOG.trace("putTlog - ENTRY");
     MutationProto proto = request.getPut();
     MutationType type = proto.getMutateType();
     Put put = null;
     Throwable t = null;
     long transactionId = request.getTransactionId();
     boolean forced = request.getForced();
     boolean result = false;
     long startTime = System.currentTimeMillis();

     try {
        put = ProtobufUtil.toPut(proto);
     } catch (Throwable e) {
        if (LOG.isWarnEnabled()) LOG.warn("putTlog - txId " + transactionId + ", Caught exception ", e);
        t = e;
     }

     // Process in local memory
     if (put != null){
        if (t == null) {
           if (! forced){
              put.setDurability(Durability.ASYNC_WAL);
           }
           try {
              if (LOG.isTraceEnabled()) LOG.trace("putTlog - putting row " + put);
              result = putTlog(transactionId, put);
           }catch (Throwable e) {
               if (LOG.isWarnEnabled()) LOG.warn("putTlog - txId " + transactionId
                         + ", Caught exception ", e);
               t = e;
           }
           if (LOG.isTraceEnabled())
               LOG.trace("putTlog - txId "  + transactionId
                       + ", region " + m_regionDetails + ", result " + result + ", type " + type + ", row "
                       + Bytes.toStringBinary(proto.getRow().toByteArray()) + ", row in hex "
                       + Hex.encodeHexString(proto.getRow().toByteArray()));

        }
     }
     
     org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TlogWriteResponse.Builder TlogWriteResponseBuilder = TlogWriteResponse.newBuilder();
     TlogWriteResponseBuilder.setHasException(false);

     if (t != null)
     {
        TlogWriteResponseBuilder.setHasException(true);
        TlogWriteResponseBuilder.setException(t.toString());
     }

     if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, false);
      long timeCost = System.currentTimeMillis();
      TlogWriteResponseBuilder.setCoproSTime(startTime);
      TlogWriteResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[26] += timeCost;
      callCount[26]++;
      costStats.callCountPlus(32L);
      costStats.sumCostPlus(32L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " putTlog txID " + transactionId + " CC " + callCount[26] + " ATC " + (costSum[26] / callCount[26]) + " TC " + timeCost);
          }
     }

     TlogWriteResponse tlwresponse = TlogWriteResponseBuilder.build();
     done.run(tlwresponse);
  }

  /**
   * Processes a transactional putTlog
   * @param long transactionId
   * @param Put put
   * @return boolean
   * @throws IOException
   */
  public boolean putTlog(final long transactionId, Put put) throws IOException {

    if (LOG.isTraceEnabled()) LOG.trace("Enter TrxRegionEndpoint putTlog, txid: "
                + transactionId + ", on HRegion " + this);
    boolean result = false;

    try {
       if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint putTlog putting " + put.getRow().toString());
       m_Region.put(put);
       result = true;
    } catch (Exception e) {
      if (LOG.isWarnEnabled()) LOG.warn("TrxRegionEndpoint putTlog - txid " + transactionId + ", Caught internal exception " + e.toString() + ", returning false");
      throw new IOException("TrxRegionEndpoint putTlog - ", e);
    }
    if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint putTlog EXIT - returns " + result + ", transId " + transactionId);
    return result;
  }

  @Override
  public void put(RpcController controller,
                  PutTransactionalRequest request,
      RpcCallback<PutTransactionalResponse> done) {
// The default response seems redundant
//    PutTransactionalResponse response = PutTransactionalResponse.getDefaultInstance();
    long startTime = System.currentTimeMillis();

    MutationProto proto = request.getPut();
    MutationType type = proto.getMutateType();
    Put put = null;
    Throwable t = null;
    MemoryUsageException mue = null;
    long transactionId = request.getTransactionId();
    long startId = request.getStartId();
    long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
    long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
    boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
    boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());
    String query = Bytes.toString(request.getQueryContext().toByteArray());
    boolean keep_old_row = request.getKeepOldRow();

    noConflictCheckForIndex = request.getNoConflictCheckForIndex();

    if (LOG.isTraceEnabled()) LOG.trace("put - transactionId " + transactionId +
        ", savepointId " + savepointId + " implicit savepoint " + implicitSavepoint +
        ", region " + m_regionDetails);

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.PutTransactionalResponse.Builder putTransactionalResponseBuilder = PutTransactionalResponse.newBuilder();
    if (false == m_regionName.equals(request.getRegionName().toStringUtf8())) {
      if (LOG.isWarnEnabled()) {
          LOG.warn("put - Regions' name mismatch. Input name is: "
             + request.getRegionName().toStringUtf8() + " and actual name is: " +  m_regionName);
      }

      putTransactionalResponseBuilder.setHasException(true);
      putTransactionalResponseBuilder.setException(REGION_NAME_MISMATCH_EXCEPTION);
      done.run(putTransactionalResponseBuilder.build());
      return;
    }

      if (memoryThrottle == true) {
        if(memoryUsageWarnOnly == true)  {
            if (LOG.isWarnEnabled()) {
                LOG.warn("put - performing memoryPercentage " + memoryPercentage + ", warning memory usage exceeds indicated percentage");
            }
        }
        else {
          if (LOG.isTraceEnabled()) LOG.trace("put - performing memoryPercentage " + memoryPercentage + ", generating memory usage exceeds indicated percentage exception");
          mue = new MemoryUsageException("put memory usage exceeds " + memoryUsageThreshold + " percent, trxId is " + transactionId);
        }
      }
      else
      {
        try {
            checkMemeoryUsage(transactionId);
            put = ProtobufUtil.toPut(proto);
        } catch (Throwable e) {
          if (LOG.isWarnEnabled()) LOG.warn("put - txId " + transactionId
              + ", Caught exception " , e);
          t = e;
        }

      if ((mue == null && type == MutationType.PUT && proto.hasRow()) && (put != null))
      {
        // Process in local memory
        try {
		  //add writer lock for ta23
		  //do not need to check if another transaction hold this lock
		  //because we assume the for-update lock protect all concurrent writing
		  //this is only for ta23
                  boolean lockViolated = false;
		  
		  if(enableTmpWriterLock == true) {
		    boolean waitHere = true;
                    int waitCounter = 0;
                    EndpointCostStats costStats = getEndpointCostStats(transactionId, false);
		    int total_lock_time = maxForUpdateScanLockRetryTimes ;
			while(waitHere == true && waitCounter < total_lock_time + 1 ) {
			  synchronized(tmpWriteLockHashmap){
			    ByteArrayKey rowInHex = new ByteArrayKey(put.getRow());
                                boolean writelocked = tmpWriteLockHashmap.containsKey(rowInHex);
                                boolean rangelocked = checkRangeLock(rowInHex, transactionId);
                if (LOG.isInfoEnabled()) {
                    LOG.info("LOCKDBG: put operation, writelocked " + writelocked + " rangelocked " + rangelocked);
                }
                                if(writelocked && !rangelocked)
				{
                                   trafLockInfo tfi = tmpWriteLockHashmap.get(rowInHex);
                                   if(tfi.getTid() == transactionId) //I get it
                                   { tfi.setIsWrite();  waitHere = false; break; } 
				   waitCounter++;
				   try {
						Thread.sleep(1);    
					} catch(InterruptedException ex) {
					}		
				}
                                else if( !writelocked && rangelocked) {
				   waitCounter++;
				   try {
						Thread.sleep(1);    
					} catch(InterruptedException ex) {
					}		
                                }
                                else if( writelocked && rangelocked) {
                                   trafLockInfo tfi = tmpWriteLockHashmap.get(rowInHex);
                                   if(tfi.getTid() == transactionId) //I get it
                                     tfi.setIsWrite(); 
				   waitCounter++;
				   try {
						Thread.sleep(1);    
					} catch(InterruptedException ex) {
					}		
                                }
				else {
					if(tmpWriteLockHashmap.size() < maxTmpWriterLockSize ) {
						long currentts = TrxEnvironmentEdgeManager.currentTime();
						trafLockInfo tli = new trafLockInfo(transactionId, currentts);
						tmpWriteLockHashmap.put(rowInHex,tli);
						waitHere = false; break;
					}
				}
				if(waitCounter == total_lock_time ) //TIMEOUT 
				{
/*
				  putTransactionalResponseBuilder.setHasException(true);
				  putTransactionalResponseBuilder.setException("get for update lock timeout put");
				  done.run(putTransactionalResponseBuilder.build());
				  return; 
*/
                                  waitHere = false;
                                  lockViolated = true;
                                  break;
				}
			  }
			}//while waitHere
                        costStats.lockTimeCostPlus(waitCounter);
		  }//if enableTmpWriterLock
		  
          put(transactionId, savepointId, pSavepointId, startId, put, lockViolated, implicitSavepoint, query, keep_old_row);
        } catch (Throwable e) {
          if (!isLockException(e)) {
              if (LOG.isWarnEnabled()) LOG.warn("put - txId " + transactionId
                   + ", regionName: " + m_regionName + ", Caught exception ", e);
          }
          t = e;
        }

        if (LOG.isTraceEnabled()) LOG.trace("put - txId "  + transactionId + ", regionName " + m_regionDetails + ", type " + type + ", row " + Bytes.toStringBinary(proto.getRow().toByteArray()) + ", row in hex " + Hex.encodeHexString(proto.getRow().toByteArray()));
      }
      else
      {
        if (LOG.isTraceEnabled()) LOG.trace("put - txId "  + transactionId + ", regionName " + m_regionDetails + "- no valid PUT type or does not contain a row");
      }
    }

    putTransactionalResponseBuilder.setHasException(false);

    if (t != null)
    {
      putTransactionalResponseBuilder.setHasException(true);
      putTransactionalResponseBuilder.setException(t.toString());
    }

    if (mue != null)
    {
      if (LOG.isTraceEnabled()) LOG.trace("put - performing memoryPercentage " + memoryPercentage + ", posting memory usage exceeds indicated percentage exception");
      putTransactionalResponseBuilder.setHasException(true);
      putTransactionalResponseBuilder.setException(mue.toString());
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, false);
      long timeCost = System.currentTimeMillis();
      putTransactionalResponseBuilder.setCoproSTime(startTime);
      putTransactionalResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[27] += timeCost;
      callCount[27]++;
      costStats.callCountPlus(25L);
      costStats.sumCostPlus(25L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " put txID " + transactionId + " CC " + callCount[27] + " ATC " + (costSum[27] / callCount[27]) + " TC " + timeCost);
          }
    }

    PutTransactionalResponse presponse = putTransactionalResponseBuilder.build();
    done.run(presponse);
  }

  @Override
  public void putMultiple(RpcController controller,
                          PutMultipleTransactionalRequest request,
                          RpcCallback<PutMultipleTransactionalResponse> done) {
// The default response seems redundant
//    PutMultipleTransactionalResponse response = PutMultipleTransactionalResponse.getDefaultInstance();

   java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto> results;
   results = request.getPutList();
   Put put = null;
   MutationType type;
   Throwable t = null;
   MemoryUsageException mue = null;
   long transactionId = request.getTransactionId();
   long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
   long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
   boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
   boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());
   String query = Bytes.toString(request.getQueryContext().toByteArray());
   boolean keep_old_row = request.getKeepOldRow();

   long startId = request.getStartId();
   long startTime = System.currentTimeMillis();
   noConflictCheckForIndex = request.getNoConflictCheckForIndex();
   if (LOG.isTraceEnabled()) LOG.trace("putMultiple - transactionId " + transactionId +
       ", savepointId " + savepointId + " implicit savepoint " + implicitSavepoint +
       ", region " + m_regionDetails);

   org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.PutMultipleTransactionalResponse.Builder putMultipleTransactionalResponseBuilder = PutMultipleTransactionalResponse.newBuilder();
   if (false == m_regionName.equals(request.getRegionName().toStringUtf8())) {
      if (LOG.isWarnEnabled()) {
          LOG.warn("putMultiple - Regions' name mismatch. Input name is: "
             + request.getRegionName().toStringUtf8() + " and actual name is: " +  m_regionName);
      }

      putMultipleTransactionalResponseBuilder.setHasException(true);
      putMultipleTransactionalResponseBuilder.setException(REGION_NAME_MISMATCH_EXCEPTION);
      done.run(putMultipleTransactionalResponseBuilder.build());
      return;
    }

   {
      if (memoryThrottle == true) {
        if(memoryUsageWarnOnly == true)  {
            if (LOG.isWarnEnabled()) {
                LOG.warn("putMultiple - performing memoryPercentage " + memoryPercentage + ", warning memory usage exceeds indicated percentage");
            }
        }
        else { 
          if (LOG.isTraceEnabled()) LOG.trace("putMultiple - performing memoryPercentage " + memoryPercentage + ", generating memory usage exceeds indicated percentage");
          mue = new MemoryUsageException("putMultiple memory usage exceeds " + memoryUsageThreshold + " percent, trxId is " + transactionId);
        }
      }
      else
      {
         for (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto proto : results){
           put = null;

           if (proto != null){
             type = proto.getMutateType();

             if (type == MutationType.PUT && proto.hasRow()){
               try {
                   checkMemeoryUsage(transactionId);
                   put = ProtobufUtil.toPut(proto);
               } catch (Throwable e) {
                 if (LOG.isWarnEnabled()) LOG.warn("putMultiple - txId " + transactionId
                      + ", Caught exception ", e);
                 t = e;
               }

               // Process in local memory
               if (put != null){
                 try {
                   //add writer lock for ta23
                   //do not need to check if another transaction hold this lock
                   //because we assume the for-update lock protect all concurrent writing
                   //this is only for ta23
                   //not finish yet for this part
					  
                   if(enableTmpWriterLock == true) {
                      synchronized(tmpWriteLockHashmap){
                         if(tmpWriteLockHashmap.size() < maxTmpWriterLockSize ) {
                            long currentts = TrxEnvironmentEdgeManager.currentTime();
                            trafLockInfo tli = new trafLockInfo(transactionId, currentts);
                            ByteArrayKey rowInHex = new ByteArrayKey(put.getRow());
                            tmpWriteLockHashmap.put(rowInHex,tli);
                         }
                      }
                   }
				 
                   put(transactionId, savepointId, pSavepointId, startId, put, false, implicitSavepoint, query, keep_old_row);
                 } catch (Throwable e) {
                   if (!isLockException(e)) {
                       if (LOG.isWarnEnabled()) LOG.warn("putMultiple - txId " + transactionId
                           + ", regionName " + m_regionName + ", Caught exception after internal put - ", e);
                   }
                   t = e;

                   // Return first error rather than keep trying because this batch will fail.
                   break;
                 }

                 if (LOG.isTraceEnabled()) LOG.trace("putMultiple - txId "  + transactionId + ", region " + m_regionDetails + ", type " + type + ", row " + Bytes.toStringBinary(proto.getRow().toByteArray()) + ", row in hex " + Hex.encodeHexString(proto.getRow().toByteArray()));
               }
             }
           }
           else
             if (LOG.isTraceEnabled()) LOG.trace("putMultiple - txId "  + transactionId + ", region " + m_regionDetails + ", put proto was null");
          }
       }
    }
      
    putMultipleTransactionalResponseBuilder.setHasException(false);

    if (t != null)
    {
      putMultipleTransactionalResponseBuilder.setHasException(true);
      putMultipleTransactionalResponseBuilder.setException(t.toString());
    }

    if (mue != null)
    {
      if (LOG.isTraceEnabled()) LOG.trace("putMultiple - performing memoryPercentage " + memoryPercentage + ", posting memory usage exceeds indicated percentage");
      putMultipleTransactionalResponseBuilder.setHasException(true);
      putMultipleTransactionalResponseBuilder.setException(mue.toString());
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, false);
      long timeCost = System.currentTimeMillis();
      putMultipleTransactionalResponseBuilder.setCoproSTime(startTime);
      putMultipleTransactionalResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[28] += timeCost;
      callCount[28]++;
      costStats.callCountPlus(26L);
      costStats.sumCostPlus(26L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " putMultiple tid: " + transactionId + " CC " + callCount[28] + " ATC " + (costSum[28] / callCount[28]) + " TC " + timeCost);
          }
    }

    PutMultipleTransactionalResponse pmresponse = putMultipleTransactionalResponseBuilder.build();
    done.run(pmresponse);
  }
  
    @Override
  public void putMultipleNonTxn(RpcController controller,
                          PutMultipleNonTransactionalRequest request,
                          RpcCallback<PutMultipleNonTransactionalResponse> done) {
// The default response seems redundant
//    PutMultipleTransactionalResponse response = PutMultipleTransactionalResponse.getDefaultInstance();

   TrxTransactionState state;
   java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto> results;
   results = request.getPutList();
   Put put = null;
   MutationType type;
   long txid = 0;
   Throwable t = null;
   MemoryUsageException mue = null;
   
   #ifdef CDH5.7 APACHE1.2 CDH5.16
    MultiVersionConcurrencyControl.WriteEntry writeEntry = null;
    long mvccNum = 0;
#endif

   long tmpTime = 0, preTime, startTime = preTime = System.currentTimeMillis();
   long time1 = 0, time2 = 0, time3 = 0, time4 = 0, time5 = 0, time6 = 0, time7 = 0, time8 = 0;
   long nonTransactionId = request.getNonTransactionId();
   long cid = request.getCommitId();
   long flags = request.getFlags();
   int totalNum = request.getTotalNum();
   if (LOG.isTraceEnabled()) LOG.trace("putMultipleNonTxn - nonTransactionId " + nonTransactionId + " cid " + cid + ", region " + m_regionDetails);
   
   org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.PutMultipleNonTransactionalResponse.Builder putMultipleNonTransactionalResponseBuilder = PutMultipleNonTransactionalResponse.newBuilder();
   if (false == m_regionName.equals(request.getRegionName().toStringUtf8())) {
      if (LOG.isWarnEnabled()) {
          LOG.warn("putMultipleNonTxn - Regions' name mismatch. Input name is: "
             + request.getRegionName().toStringUtf8() + " and actual name is: " +  m_regionName);
      }

      putMultipleNonTransactionalResponseBuilder.setHasException(true);
      putMultipleNonTransactionalResponseBuilder.setException(REGION_NAME_MISMATCH_EXCEPTION);
      done.run(putMultipleNonTransactionalResponseBuilder.build());
      return;
   }

   {
      if (memoryThrottle == true) {
        if(memoryUsageWarnOnly == true)  {
            if (LOG.isWarnEnabled()) {
                LOG.warn("putMultipleNonTxn - performing memoryPercentage " + memoryPercentage + ", warning memory usage exceeds indicated percentage");
            }
        }
        else { 
          if (LOG.isTraceEnabled()) LOG.trace("putMultipleNonTxn - performing memoryPercentage " + memoryPercentage + ", generating memory usage exceeds indicated percentage");
          mue = new MemoryUsageException("putMultipleNonTxn - memory usage exceeds " + memoryUsageThreshold + " percent, nonTransactionId is " + nonTransactionId);
        }
      }
      else
      {
          // step 1 - create a temp ts object for holding mutations (no adding into any list for transaction processing
         if (LOG.isTraceEnabled()) LOG.trace("putMultipleNonTxn - Step 1: create transaction state - nonTransactionId "
                               + nonTransactionId + ", region " + m_regionDetails);
         state = new TrxTransactionState(nonTransactionId, nextLogSequenceId.getAndIncrement(),
                                      nextLogSequenceId, m_Region.getRegionInfo(), m_Region.getTableDesc(), tHLog, 
#ifdef CDH5.7 APACHE1.2 CDH5.16
                                      configuredEarlyLogging, this.t_Region,
#else                                     
                                      configuredEarlyLogging,
#endif                                                                                                        
                                      flags /* startId*/ , false /*regionTransaction*/ , true /* incremental BR */, m_regionName);          // temporary mutation holders
         state.setMutationClient(MUTATION_CLIENT_IBR); // set Incremental BR as mutation client
         state.setCommitId(cid);
//         state.setCommitId(TrxEnvironmentEdgeManager.currentTime());
         
          // step 2 - add all put into ts through a new addWrite proc with new putMultiple NonTxn commit tag (~ region txn)
         if (LOG.isTraceEnabled()) LOG.trace("putMultipleNonTxn - Step 2: call addWrite2 for all the put - nonTransactionId "
                               + nonTransactionId + " cid " + state.getCommitId() + ", region " + m_regionDetails);
         for (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto proto : results) {
             put = null;
             if (proto != null) {
                type = proto.getMutateType();
                if (type == MutationType.PUT && proto.hasRow()){
                  try {
                      checkMemeoryUsage(nonTransactionId);
                      put = ProtobufUtil.toPut(proto);
                  } catch (Throwable e) {
                     if (LOG.isWarnEnabled()) LOG.warn("putMultipleNonTxn - nonTransactionId " + nonTransactionId + " cid " + state.getCommitId() + ", Caught exception ", e);
                     t = e;
                  }
                  if (put != null) {
                      try { // add the put into temp ts object
                          state.addWrite2(put); // new addWrite2 proc for IBR operation to add put into ts waction + WAL edit generation
                      } catch (Throwable e) {
                          if (LOG.isWarnEnabled()) LOG.warn("putMultipleNonTxn - nonTransactionId " + nonTransactionId + " cid " + state.getCommitId() + ", Caught exception after internal put - ", e);
                          t = e;
                      }
                      if (LOG.isTraceEnabled()) LOG.trace("putMultipleNonTxn - nonTransactionId " + nonTransactionId + " cid " + state.getCommitId() + ", region " + m_regionDetails + ", type " + type + ", row " + Bytes.toStringBinary(proto.getRow().toByteArray()) + ", row in hex " + Hex.encodeHexString(proto.getRow().toByteArray()));
                  }
                }
             }
             else
                if (LOG.isTraceEnabled()) LOG.trace("putMultipleNonTxn - nonTransactionId " + nonTransactionId + " cid " + state.getCommitId() + ", region " + m_regionDetails + ", put proto was null");
         } // for all mutation put
         
         if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
           preTime = System.currentTimeMillis();
           time1 = preTime - startTime;
         }
         // step 3 - write nonTxn put multiple commit WALEdit  into HLOG 
         //              - this is for durability only, so the txn is committed and will be replayed during preWALRestore if RS fails
         //              - this operation is non-transactional, so ACI is NOT guaranteed, only  Durability is ensured if HLOG op succeeds

         if (LOG.isTraceEnabled()) LOG.trace("putMultipleNonTxn - Step 3: write TS_IBR_COMMIT HLOG WAL edit - nonTransactionId "
                               + nonTransactionId + ", region " + m_regionDetails);
         if (state.hasWrite()) {
                      if (LOG.isTraceEnabled()) LOG.trace("putMultipleNonTxn - write IBR commit edit to HLOG");
               try {

#ifdef CDH5.7 APACHE1.2 CDH5.16 
                WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(), 
                                             this.regionInfo.getTable(), 
                                             WALKey.NO_SEQUENCE_ID,
                                             TrxEnvironmentEdgeManager.currentTime(),
                                             WALKey.EMPTY_UUIDS,
                                             HConstants.NO_NONCE,
                                             HConstants.NO_NONCE,
                                             this.t_Region.getMVCC());                                       
#else
                final WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(),
                                          this.regionInfo.getTable(),
                                          TrxEnvironmentEdgeManager.currentTime());

#endif
      
                state.resetEdit();
                WALEdit e2 = state.getPreparedEdit();
                if (LOG.isTraceEnabled()) LOG.trace("putMultipleNonTxn - IBR commit WAL edit from ts, WALEdit size = " + e2.size());            
                  
		if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                  tmpTime = System.currentTimeMillis();
		  time2 = tmpTime - preTime;
		  preTime = tmpTime;
                }
#ifdef CDH5.7 APACHE1.2 CDH5.16
                txid = this.tHLog.append(this.m_Region.getTableDesc(), this.regionInfo, wk, e2, false);
                writeEntry = wk.getWriteEntry();
                mvccNum = writeEntry.getWriteNumber();
        
                if (LOG.isInfoEnabled()) LOG.info("putMultipleNonTxn - IBR Commit " + m_regionDetails + " txId: " + nonTransactionId  );
#else
                AtomicLong lv_seqid = this.m_Region.getSequenceId();
                txid = this.tHLog.append(this.m_Region.getTableDesc(),
                                         this.regionInfo,  wk,  e2,  lv_seqid,  false,  null);
                                         
                 if (LOG.isInfoEnabled()) LOG.info("putMultipleNonTxn - IBR Commit " + m_regionDetails + " txId: " + nonTransactionId  );
                  
#endif

                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                  tmpTime = System.currentTimeMillis();
                  time3 = tmpTime - preTime;
                  preTime = tmpTime;
                }
                WALSync(tHLog, nonTransactionId, txid);
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                  tmpTime = System.currentTimeMillis();
                  time4 = tmpTime - preTime;
                  preTime = tmpTime;
                }

#ifdef CDH5.7 APACHE1.2 CDH5.16 
               if (writeEntry != null) {
                     this.t_Region.getMVCC().completeAndWait(writeEntry);
                     writeEntry = null;
               }
#endif
        
               if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                 tmpTime = System.currentTimeMillis();
                 time5 = tmpTime - preTime;
                 preTime = tmpTime;
               }
               } catch (IOException exp) {
                                   exp.fillInStackTrace();
                                   LOG.error("putMultipleNonTxn - IBR commit - " + nonTransactionId + " HLog seq " + txid + " Caught IOException in HLOG operations", exp );
                                   t = exp; // throw exp;
                }
 
#ifdef CDH5.7 APACHE1.2 CDH5.16    
               finally {
                       if (writeEntry != null) {
                              this.t_Region.getMVCC().completeAndWait(writeEntry);
                              writeEntry = null;
                       }          
                } // finally
#endif      

         } // has write, need HLOG op
         
         // step 4 - for all the put in ts, perform region.put and construct related mutation proto if Incremental BR is ON
         if (LOG.isTraceEnabled()) LOG.trace("putMultipleNonTxn - Step 4: peform region.put - nonTransactionId "
                               + nonTransactionId + ", region " + m_regionDetails);
         ListIterator<WriteAction> writeOrderIter = null;
         if (state.hasWrite()) {
              try {
                      int writeOrderIndex = 0;
                      List<Mutation> mutations = (putBatchMutateNum > 0 ? new ArrayList<Mutation>() : null);
                      for (writeOrderIter = state.getWriteOrderingIter();  writeOrderIter.hasNext();) {
                             WriteAction action =(WriteAction) writeOrderIter.next();
                             Put pput = action.getPut();
                             if (putBatchMutateNum > 0 && pput != null)
                                 mutations.add(pput);

                             if (putBatchMutateNum > 0 && (mutations.size() >= putBatchMutateNum
                                                        || mutations.size() > 0 && writeOrderIter.hasNext() == false)) {
                                 OperationStatus[] result = m_Region.batchMutate(mutations.toArray(new Mutation[0]),
                                                                 HConstants.NO_NONCE, HConstants.NO_NONCE);
                                 mutations.clear();
                                 for (int i = 0; i < result.length; i++) {
                                     if (result[i].getOperationStatusCode() != OperationStatusCode.SUCCESS)
                                         throw new IOException("putMultipleNonTxn - batch commit txId " + nonTransactionId + " with  region: " + m_regionDetails
                                          + " exception " + result[i].getExceptionMsg());
                                 }
                             } else if (putBatchMutateNum <= 0 && null != pput) {        // Process Put

                                       pput.setDurability(Durability.ASYNC_WAL);
                                       if (LOG.isTraceEnabled()) LOG.trace("putMultipleNonTxn - IBR commit txId "
                                              + nonTransactionId + ", Executing put writeOrderIndex " + writeOrderIndex + " durability "
                                              + put.getDurability().toString() + " directly to region "  + m_regionDetails  );
                                       try {
                                             m_Region.put(pput);
                                       }
                                      catch (Exception e) {
                                                LOG.error("putMultipleNonTxn - IBR commit " + " txId " + nonTransactionId + ", Executing put caught an exception ",e);
                                                t = e; // throw new IOException("IBR commit -" + " txId " + nonTransactionId + ", Executing put caught an exception " + e);
                                       }
                             }

                            writeOrderIndex++;
                      } // for every put
                      if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                        tmpTime = System.currentTimeMillis();
                        time6 = tmpTime - preTime;
                        preTime = tmpTime;
                      }
                      if (LOG.isTraceEnabled()) LOG.trace("putMultipleNonTxn - Step 5: IBR CDC operation - nonTransactionId "
                               + nonTransactionId + " cid " + state.getCommitId() + ", region " + m_regionDetails);
                      // IBR op will do CDC by default
                      if (useMC2) {
                          if (mutationCapture2 == null) {
                              mutationCapture2 = MutationCapture2.MC2_getInstance(this.config, 
                              this.fs,
                              context,
                              regionInfo,
                              0, 1);
                          }
                          mutationCapture2.setNonTrxRecordBinlog(true);
                          state.setTotalNum( (short)totalNum );
                          mutationCapture2.MC2_doMutationAppend(state, regionInfo.getTable().getNameAsString());
                          mutationCapture2.setNonTrxRecordBinlog(false);

                          if (LOG.isTraceEnabled()) LOG.trace("putMultipleNonTxn - MC2_doMutationAppend finished");
                      }
                      else {
                          mutationCapture.txnMutationBuilder(state, 5000, 15000); 
                      }
                      if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                        tmpTime = System.currentTimeMillis();
                        time7 = tmpTime - preTime;
                        preTime = tmpTime;
                      }
              } catch(IOException e) {
                     LOG.error("putMultipleNonTxn - IBR CDC Unable to write mutation capture ", e);
                     t = new IOException("Trafodion CDC Exception NonTxnMultiplePut ", e);  // throw new RuntimeException(e);
              }
         } // size > 0
         
       } // else  - no memory issue
    }

    if (LOG.isTraceEnabled()) LOG.trace("putMultipleNonTxn - Step 6: nonTransactionId "
                + nonTransactionId + " cid " + cid + ", region " + m_regionDetails + ((t == null) ? " no exception " : " exception caught " + t));
      
    putMultipleNonTransactionalResponseBuilder.setHasException(false);

    if (t != null)
    {
      putMultipleNonTransactionalResponseBuilder.setHasException(true);
      putMultipleNonTransactionalResponseBuilder.setException(t.toString());
    }

    if (mue != null)
    {
      if (LOG.isTraceEnabled()) LOG.trace("putMultipleNonTxn - performing memoryPercentage " + memoryPercentage + ", posting memory usage exceeds indicated percentage");
      putMultipleNonTransactionalResponseBuilder.setHasException(true);
      putMultipleNonTransactionalResponseBuilder.setException(mue.toString());
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(nonTransactionId, false);
      long timeCost = System.currentTimeMillis();
      putMultipleNonTransactionalResponseBuilder.setCoproSTime(startTime);
      putMultipleNonTransactionalResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[29] += timeCost;
      callCount[29]++;
      costStats.callCountPlus(27L);
      costStats.sumCostPlus(27L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " putMultipleNonTxn txID " + nonTransactionId + " CC " + callCount[29] + " ATC " + (costSum[29] / callCount[29]) + " TC " + timeCost + " time1 " + time1
                 + " time2 " + time2 + " time3 " + time3 + " time4 " + time4 + " time5 " + time5 + " time6 " + time6 + " time7 " + time7);
          }
    }

    PutMultipleNonTransactionalResponse pmresponse = putMultipleNonTransactionalResponseBuilder.build();
    done.run(pmresponse);
  }

  @Override
  public void recoveryRequest(RpcController controller,
                              RecoveryRequestRequest request,
                              RpcCallback<RecoveryRequestResponse> done) {
      int tmId = request.getTmId();
      long transactionId = request.getTransactionId();

      if (reconstructIndoubts == 0) {
         if (LOG.isTraceEnabled()) LOG.trace("recoveryRequest - txId " + transactionId + ", RECOV");
         constructIndoubtTransactions();
      }

      // Placeholder for real work when recovery is added
      if (LOG.isInfoEnabled()) LOG.info("recoveryRequest - txId "  + transactionId + ", region " + m_regionDetails + ", tmId " + tmId);

      org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.RecoveryRequestResponse.Builder recoveryResponseBuilder = RecoveryRequestResponse.newBuilder();
      try {
         pSTRConfig = STRConfig.getInstance(this.config);
      } catch (Exception xe) {
         LOG.error("An ERROR occurred while getting the STR Configuration");
      }

      List<Long> indoubtTransactions = new ArrayList<Long>();
      String leaseKey = null;
      if (LOG.isTraceEnabled()) LOG.trace("recoveryRequest Trafodion Recovery: region " + regionInfo.getEncodedName() + " receives recovery request from TM " + tmId  +
                            " with region state " + regionState.intValue());
      switch(regionState.intValue()) {
              case REGION_STATE_REPLAY:
                    if (LOG.isInfoEnabled()) LOG.info("TRAF RCOV:recoveryRequest in region replay " + regionInfo.getEncodedName());
                    break;
              case REGION_STATE_RECOVERING: // RECOVERING, already create a list of in-doubt txn, but still in the state of resolving them,
                           // retrieve all in-doubt txn from rmid and return them into a long a
                    if (LOG.isInfoEnabled()) LOG.info("TRAF RCOV:recoveryRequest in region starting " + regionInfo.getEncodedName() + " has in-doubt transaction " + indoubtTransactionsById.size());
                    synchronized(indoubtTransactionsById) {                    
                    for (Entry<Long, List<WALEdit>> entry : indoubtTransactionsById.entrySet()) {
                          long tid = entry.getKey();
                          int clusterid = (int) TransactionState.getClusterId(tid);
                          int nodeid = (int) TransactionState.getNodeId(tid);

                          boolean add = false;
                          if ( (   ((clusterid == 1) && (pSTRConfig.getConfiguredPeerCount() == 0))
                                        || (clusterid == pSTRConfig.getTrafClusterIdInt())  )          && nodeid == tmId) add = true; // match local TM
                          else if ( ((clusterid != pSTRConfig.getTrafClusterIdInt()) ) && tmId == -2) add = true; // for any peer
                        
                          if (add) {
                              indoubtTransactions.add(tid);
                              if (LOG.isInfoEnabled()) LOG.info("recoveryRequest - txId " + transactionId + ", Trafodion Recovery: region " + m_regionName
                                 + " in-doubt transaction " + tid
                                 + " has been added into the recovery reply to Cluster " + clusterid + " Node " + nodeid
                                 + " TM " + tmId + " during recovery ");
                          }
                     } // for
                     } // synchronization
                     if (LOG.isTraceEnabled()) LOG.trace("recoveryRequest " + indoubtTransactions.size());
                     if (indoubtTransactions.size() == 0) {
                       try {
                           if (LOG.isTraceEnabled()) LOG.trace("recoveryRequest - Trafodion Recovery: delete recovery zNode TM "
                                      + tmId + " region encoded name " + regionInfo.getEncodedName() + " for 0 in-doubt transaction");
                           if (indoubtTransactionsById.size() == 0) {
                               regionState.set(REGION_STATE_START);
                               if (LOG.isInfoEnabled()) {
                                   LOG.info("recoveryRequest - Trafodion Recovery: region " + m_regionDetails + " is STARTED.");
                               }
                           }
                           deleteRecoveryzNode(tmId, regionInfo.getEncodedName());
                       } catch (IOException e) {
                          LOG.error("recoveryRequest - Trafodion Recovery: delete recovery zNode failed ", e);
                       }
                     }
                     break;
              case REGION_STATE_START: // START
                     List<TrxTransactionState> commitPendingCopy = new ArrayList<TrxTransactionState>(commitPendingTransactions);
                     if (LOG.isInfoEnabled()) LOG.info("TRAF RCOV:recoveryRequest in region started" + regionInfo.getEncodedName()
                                   + " has in-doubt transaction " + commitPendingCopy.size());
                     for (TrxTransactionState commitPendingTS : commitPendingCopy) {
                         long tid = commitPendingTS.getTransactionId();
                         int clusterid = (int) commitPendingTS.getClusterId();
                         int nodeid = (int) commitPendingTS.getNodeId();

                         boolean add = false;

                         if ( (   ((clusterid == 1) && (pSTRConfig.getConfiguredPeerCount() == 0))
                                        || (clusterid == pSTRConfig.getTrafClusterIdInt())  )          && nodeid == tmId) add = true; // match local TM
                          else if ( ((clusterid != pSTRConfig.getTrafClusterIdInt()) ) && tmId == -2) add = true; // for any peer
                        
                         if (add) {
                             indoubtTransactions.add(tid);
                             if (LOG.isInfoEnabled()) LOG.info("recoveryRequest - Trafodion Recovery: region " + m_regionName
                                + " in-doubt transaction " + tid + " write " + commitPendingTS.getWriteOrdering().size()
                                + " has been added into the recovery reply to TM " + tmId + " for started region ");
                         }
                     }
                     // now pick up any long running active transactions with lease expired and renewed
		     
		     synchronized (longRunningTransactions) {
		     if (longRunningTransactions.size() > 0)
		         if (LOG.isInfoEnabled()) {
		             LOG.info("There are long running transactions with leases expired, size " + longRunningTransactions.size());
		         }
                     for (Long txid:longRunningTransactions) {
		         long tid = txid.longValue();
			 try {
                             int clusterid = (int) TransactionState.getClusterId(tid);
                             int nodeid = (int) TransactionState.getNodeId(tid);
                             boolean add = false;

                             if ( (   ((clusterid == 1) && (pSTRConfig.getConfiguredPeerCount() == 0))
                                        || (clusterid == pSTRConfig.getTrafClusterIdInt())  )          && nodeid == tmId) add = true; // match local TM
                          else if ( ((clusterid != pSTRConfig.getTrafClusterIdInt()) ) && tmId == -2) add = true; // for any peer
                                  
                             if (add) {
                                 indoubtTransactions.add(tid);
                                 if (LOG.isInfoEnabled()) LOG.info("recoveryRequest - Trafodion Recovery: region " + regionInfo.getEncodedName() + " long running transaction " + tid + " has been added into the recovery reply to TM " + tmId + " for started region ");
                             }			       
                             try {	   
			         leaseKey = getTransactionalLeaseId(tid);
			         if (LOG.isInfoEnabled()) {
			             LOG.info("TRAF RCOV: re-create transaction lease for long running txn " + tid);
                     }
                                 transactionLeases.createLease(leaseKey, transactionLeaseTimeout, new TransactionLeaseListener(tid));
                             } catch (LeaseStillHeldException e) {
		                  if (LOG.isInfoEnabled()) {
		                      LOG.info("TRAF RCOV: renew transaction lease for long running txn " + tid + " after recreate fails ");
		                  }
		                 transactionLeases.renewLease(leaseKey);
                             }			                        
		         } catch (Exception e) {
                            //throw new RuntimeException(e);
			    if (LOG.isInfoEnabled()) {
			        LOG.info("TRAF RCOV: transaction lease create or renewal fails in recovery request for tid " + tid);
		        }
		         }
		     } // loop
                     longRunningTransactions.clear();
		     } //sync longRunningTransactions
                     
                     // now remove the ZK node after TM has initiated the recovery request   
                    try {
                       if (LOG.isTraceEnabled()) LOG.trace("recoveryRequest - Trafodion Recovery: delete recovery zNode TM "
                              + tmId + " region encoded name " + regionInfo.getEncodedName() + " for 0 in-doubt transaction");
                       deleteRecoveryzNode(tmId, regionInfo.getEncodedName());
                    } catch (IOException e) {
                       LOG.error("recoveryRequest - Trafodion Recovery: delete recovery zNode failed ", e);
                    }
                    break;
                default:
                    LOG.error("Trafodion Recovery: encounter incorrect region state " + regionState.intValue());
                    break;
      }

      // Placeholder response forced to zero for now
      for (Long transactionInDoubtId:indoubtTransactions) {
         recoveryResponseBuilder.addResult(transactionInDoubtId);
      }
      // Placeholder response forced to zero for now

      recoveryResponseBuilder.setHasException(false);

      RecoveryRequestResponse rresponse = recoveryResponseBuilder.build();
      done.run(rresponse);
  }

  /**
   * Gives the maximum for a given combination of column qualifier and column
   * family, in the given row range as defined in the Scan object. In its
   * current implementation, it takes one column family and one column qualifier
   * (if provided). In case of null column qualifier, maximum value for the
   * entire column family will be returned.
   */
  @Override
  public void getMax(RpcController controller, TransactionalAggregateRequest request,
    RpcCallback<TransactionalAggregateResponse> done) {
    RegionScanner scanner = null;
    TransactionalAggregateResponse response = null;
    long transactionId = request.getTransactionId();
    long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
    long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
    boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
    boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());
    long startId = request.getStartId();
    T max = null;
    int nameCount = request.getRegionNameCount();
    int iterate = 0;
    String query = Bytes.toString(request.getQueryContext().toByteArray());

    for (iterate = 0; iterate < nameCount; iterate++) {
      if (m_regionEncodedName.equals(request.getRegionName(iterate).toStringUtf8()))
       break;
    }
    if (iterate >= nameCount) {
      if (LOG.isWarnEnabled()) {
          LOG.warn("getMax - Regions' name mismatch. Region's name is: " +  m_regionName);
      }

      response = TransactionalAggregateResponse.newBuilder().addFirstPart(
          ByteString.copyFrom(REGION_NAME_MISMATCH_EXCEPTION.getBytes())).setHasException(true).build();
      done.run(response);
      return;
    }

    try {
      checkBlockNonPhase2(transactionId); // throws IOException
      ColumnInterpreter<T, S, P, Q, R> ci = constructColumnInterpreterFromRequest(request);
      T temp;
      Scan scan = ProtobufUtil.toScan(request.getScan());
      scanner = getScanner(transactionId, startId, scan, savepointId, pSavepointId, implicitSavepoint, query);
      List<Cell> results = new ArrayList<Cell>();
      byte[] colFamily = scan.getFamilies()[0];
      NavigableSet<byte[]> qualifiers = scan.getFamilyMap().get(colFamily);
      byte[] qualifier = null;
      if (qualifiers != null && !qualifiers.isEmpty()) {
        qualifier = qualifiers.pollFirst();
      }
      // qualifier can be null.
      boolean hasMoreRows = false;
      do {
        checkMemeoryUsage(transactionId);
        hasMoreRows = scanner.next(results);
        for (Cell kv : results) {
          temp = ci.getValue(colFamily, qualifier, kv);
          max = (max == null || (temp != null && ci.compare(temp, max) > 0)) ? temp : max;
        }
        results.clear();
      } while (hasMoreRows);
      if (max != null) {
        TransactionalAggregateResponse.Builder builder = TransactionalAggregateResponse.newBuilder();
        builder.addFirstPart(ci.getProtoForCellType(max).toByteString());
        response = builder.build();
      }
    } catch (IOException e) {
      ResponseConverter.setControllerException(controller, e);
    } finally {
      if (scanner != null) {
        try {
          scanner.close();
        } catch (IOException ignored) {}
      }
    }
    if (LOG.isTraceEnabled()) LOG.trace("getMax - txId " + transactionId + ", Maximum from this region is "
        + m_regionDetails + ": " + max);
    done.run(response);
  }

  /**
   * Gives the minimum for a given combination of column qualifier and column
   * family, in the given row range as defined in the Scan object. In its
   * current implementation, it takes one column family and one column qualifier
   * (if provided). In case of null column qualifier, minimum value for the
   * entire column family will be returned.
   */
  @Override
  public void getMin(RpcController controller, TransactionalAggregateRequest request,
      RpcCallback<TransactionalAggregateResponse> done) {
    TransactionalAggregateResponse response = null;
    RegionScanner scanner = null;
    long transactionId = request.getTransactionId();
    long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
    long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
    boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
    boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());
    long startId = request.getStartId();
    T min = null;
    int nameCount = request.getRegionNameCount();
    int iterate = 0;
    String query = Bytes.toString(request.getQueryContext().toByteArray());

    for (iterate = 0; iterate < nameCount; iterate++) {
      if (m_regionEncodedName.equals(request.getRegionName(iterate).toStringUtf8()))
       break;
    }
    if (iterate >= nameCount) {
      if (LOG.isWarnEnabled()) {
          LOG.warn("getMin - Regions' name mismatch. Region's name is: " +  m_regionName);
      }

      response = TransactionalAggregateResponse.newBuilder().addFirstPart(
          ByteString.copyFrom(REGION_NAME_MISMATCH_EXCEPTION.getBytes())).setHasException(true).build();
      done.run(response);
      return;
    }

    try {
      checkBlockNonPhase2(transactionId); // throws IOException
      ColumnInterpreter<T, S, P, Q, R> ci = constructColumnInterpreterFromRequest(request);
      T temp;
      Scan scan = ProtobufUtil.toScan(request.getScan());
      scanner = getScanner(transactionId, startId, scan, savepointId, pSavepointId, implicitSavepoint, query);
      List<Cell> results = new ArrayList<Cell>();
      byte[] colFamily = scan.getFamilies()[0];
      NavigableSet<byte[]> qualifiers = scan.getFamilyMap().get(colFamily);
      byte[] qualifier = null;
      if (qualifiers != null && !qualifiers.isEmpty()) {
        qualifier = qualifiers.pollFirst();
      }
      boolean hasMoreRows = false;
      do {
        checkMemeoryUsage(transactionId);
        hasMoreRows = scanner.next(results);
        for (Cell kv : results) {
          temp = ci.getValue(colFamily, qualifier, kv);
          min = (min == null || (temp != null && ci.compare(temp, min) < 0)) ? temp : min;
        }
        results.clear();
      } while (hasMoreRows);
      if (min != null) {
        response = TransactionalAggregateResponse.newBuilder().addFirstPart( 
          ci.getProtoForCellType(min).toByteString()).build();
      }
    } catch (IOException e) {
      ResponseConverter.setControllerException(controller, e);
    } finally {
      if (scanner != null) {
        try {
          scanner.close();
        } catch (IOException ignored) {}
      }
    }
    if (LOG.isTraceEnabled()) LOG.trace("getMin - txId " + transactionId + ", Minimum from this region is "
        + m_regionDetails + ": " + min);
    done.run(response);
  }

  /**
   * Gives the sum for a given combination of column qualifier and column
   * family, in the given row range as defined in the Scan object. In its
   * current implementation, it takes one column family and one column qualifier
   * (if provided). In case of null column qualifier, sum for the entire column
   * family will be returned.
   */
  @Override
  public void getSum(RpcController controller, TransactionalAggregateRequest request,
      RpcCallback<TransactionalAggregateResponse> done) {
    TransactionalAggregateResponse response = null;
    RegionScanner scanner = null;
    long sum = 0l;
    long transactionId = request.getTransactionId();
    long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
    long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
    boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
    boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());
    long startId = request.getStartId();
    int nameCount = request.getRegionNameCount();
    int iterate = 0;
    String query = Bytes.toString(request.getQueryContext().toByteArray());

    for (iterate = 0; iterate < nameCount; iterate++) {
      if (m_regionEncodedName.equals(request.getRegionName(iterate).toStringUtf8()))
       break;
    }
    if (iterate >= nameCount) {
      if (LOG.isWarnEnabled()) {
          LOG.warn("getSum - Regions' name mismatch. Region's name is: " +  m_regionName);
      }

      response = TransactionalAggregateResponse.newBuilder().addFirstPart(
          ByteString.copyFrom(REGION_NAME_MISMATCH_EXCEPTION.getBytes())).setHasException(true).build();
      done.run(response);
      return;
    }

    try {
      checkBlockNonPhase2(transactionId); // throws IOException
      ColumnInterpreter<T, S, P, Q, R> ci = constructColumnInterpreterFromRequest(request);
      S sumVal = null;
      T temp;
      Scan scan = ProtobufUtil.toScan(request.getScan());
      scanner = getScanner(transactionId, startId, scan, savepointId, pSavepointId, implicitSavepoint, query);
      byte[] colFamily = scan.getFamilies()[0];
      NavigableSet<byte[]> qualifiers = scan.getFamilyMap().get(colFamily);
      byte[] qualifier = null;
      if (qualifiers != null && !qualifiers.isEmpty()) {
        qualifier = qualifiers.pollFirst();
      }
      List<Cell> results = new ArrayList<Cell>();
      boolean hasMoreRows = false;
      do {
        checkMemeoryUsage(transactionId);
        hasMoreRows = scanner.next(results);
        for (Cell kv : results) {
          temp = ci.getValue(colFamily, qualifier, kv);
          if (temp != null)
            sumVal = ci.add(sumVal, ci.castToReturnType(temp));
        }
        results.clear();
      } while (hasMoreRows);
      if (sumVal != null) {
        response = TransactionalAggregateResponse.newBuilder().addFirstPart( 
          ci.getProtoForPromotedType(sumVal).toByteString()).build();
      }
    } catch (IOException e) {
      ResponseConverter.setControllerException(controller, e);
    } finally {
      if (scanner != null) {
        try {
          scanner.close();
        } catch (IOException ignored) {}
      }
    }
    if (LOG.isTraceEnabled()) LOG.trace("getSum - txId " + transactionId + ", Sum from this region is "
        + m_regionDetails + ": " + sum);
    done.run(response);
  }

  /**
   * Gives the row count for the given column family and column qualifier, in
   * the given row range as defined in the Scan object.
   * @throws IOException
   */
  @Override
  public void getRowNum(RpcController controller, TransactionalAggregateRequest request,
      RpcCallback<TransactionalAggregateResponse> done) {
    TransactionalAggregateResponse.Builder responseBuilder = TransactionalAggregateResponse.newBuilder();
    long counter = 0L;
    List<Cell> results = new ArrayList<Cell>();
    RegionScanner scanner = null;
    long transactionId = 0L;
    long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
    long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
    boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
    boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());
    long startId = 0L;
    int isolationLevel = LockConstants.READ_COMMITTED_ACCESS_;
    int nameCount = request.getRegionNameCount();
    int lockMode = request.getLockMode();
    int iterate = 0;
    long startTime = System.currentTimeMillis();
    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TransactionalAggregateResponse.Builder mybuilder = TransactionalAggregateResponse.newBuilder();
    String query = Bytes.toString(request.getQueryContext().toByteArray());

    for (iterate = 0; iterate < nameCount; iterate++) {
      if (m_regionEncodedName.equals(request.getRegionName(iterate).toStringUtf8()))
       break;
    }
    if (iterate >= nameCount) {
      if (LOG.isWarnEnabled()) {
          LOG.warn("getRowNum - Regions' name mismatch. Region's name is: " +  m_regionName);
      }

      responseBuilder.setHasException(true);
      responseBuilder.setException(REGION_NAME_MISMATCH_EXCEPTION); 
      done.run(responseBuilder.build());
      return;
    }

    int isoLevel = READCOMMITTED;
    Object[] checkResult = null;
    boolean skipLock = false;
    boolean hasLocked = false;
    boolean ok_locked = false;
    int scanType = -1;
    try {
      checkBlockNonPhase2(transactionId); // throws IOException
      Scan scan = ProtobufUtil.toScan(request.getScan());
      byte[][] colFamilies = scan.getFamilies();
      byte[] colFamily = colFamilies != null ? colFamilies[0] : null;
      NavigableSet<byte[]> qualifiers = colFamilies != null ?
          scan.getFamilyMap().get(colFamily) : null;
      byte[] qualifier = null;
      if (qualifiers != null && !qualifiers.isEmpty()) {
        qualifier = qualifiers.pollFirst();
      }
      if (scan.getFilter() == null && qualifier == null)
        scan.setFilter(new FirstKeyOnlyFilter());
      transactionId = request.getTransactionId();
      startId = request.getStartId();
      isolationLevel = request.getIsolationLevel();
      checkResult = checkLockedInGetScanner(scan, isolationLevel, lockMode);
      scanner = getScanner(transactionId, startId, scan, savepointId, pSavepointId, implicitSavepoint, checkResult, query, isolationLevel, lockMode);
      boolean hasMoreRows = false;
      int scanLockMode = LockMode.LOCK_NO;
      skipLock = skipLock();

      boolean updatableSelect = false;
      if (LockConstants.ENABLE_ROW_LEVEL_LOCK && !skipLock) {
          scanType = ((Integer)checkResult[0]).intValue();
          hasLocked = ((Boolean)checkResult[1]).booleanValue();
          ok_locked = ((Boolean)checkResult[2]).booleanValue();
          isoLevel = transformIsolationLevel(isolationLevel);

          checkAndCreateLockManager();
          if (lockMode == LockMode.LOCK_U) {
              updatableSelect = true;
          }
          if (!hasLocked && (!updatableSelect) && (isoLevel == READCOMMITTED)) {
              this.lockManager.disableEsca(transactionId);
          }
          if (LockConstants.ENABLE_TABLELOCK_FOR_FULL_SCAN && scanType == FULL_TABLE_SCAN) {
              if (updatableSelect) {
                  scanLockMode = lockMapping[isoLevel][SEL_UPD_TAB_LOCK];
              } else {
                  scanLockMode = lockMapping[isoLevel][SEL_TAB_LOCK];
              }
          } else {
              if (updatableSelect) {
                  scanLockMode = lockMapping[isoLevel][SEL_UPD_ROW_LOCK];
              } else {
                  scanLockMode = lockMapping[isoLevel][SEL_ROW_LOCK];
              }
          }
      }

      org.apache.hadoop.hbase.client.Result result = null;
      RetCode retCode = null;

      if (LockConstants.ENABLE_ROW_LEVEL_LOCK && !skipLock && !hasLocked && (LockConstants.ENABLE_TABLELOCK_FOR_FULL_SCAN &&
              scanType == FULL_TABLE_SCAN)) {
          try {
              retCode = lock(transactionId, savepointId, pSavepointId, scanLockMode, implicitSavepoint, query);
              hasLocked = (retCode == RetCode.OK || retCode == RetCode.OK_WITHRETRY);
          } catch (IOException e) {
              throw e;
          }
      }
      boolean skipCurrentRow = false;
      do {
        skipCurrentRow = false;
        checkMemeoryUsage(transactionId);
        hasMoreRows = scanner.next(results);
        if (results.size() > 0) {
          if (LockConstants.ENABLE_ROW_LEVEL_LOCK && !skipLock && !hasLocked) {
             result = Result.create(results);
             results.clear(); 
             try {
                 retCode = tryLock(transactionId, savepointId, pSavepointId, result.getRow(), scanLockMode, implicitSavepoint, query);
             } catch (IOException e) {
                 throw e;
             }
             // check current row delete or update by other transaction
             if (retCode == RetCode.OK_WITHRETRY) {
                 checkAndGetRow(transactionId, savepointId, result.getRow(), results);
                 if (results.isEmpty()) {
                     skipCurrentRow = true;
                 }
                 results.clear();
             }
             if (isoLevel == READCOMMITTED && !updatableSelect && retCode != RetCode.OK_LOCKED) {
                 unLock(transactionId, savepointId, result.getRow(), scanLockMode);
             }
          }
          if (!skipCurrentRow) {
              counter++;
          }
        }
        results.clear();
      } while (hasMoreRows);
      if (LockConstants.ENABLE_ROW_LEVEL_LOCK && !skipLock) {
          if (hasLocked && scanType == FULL_TABLE_SCAN && !ok_locked && isoLevel == READCOMMITTED) {
              unLock(transactionId, savepointId, lockMapping[isoLevel][SEL_TAB_LOCK]);
              lock(transactionId, savepointId, pSavepointId, lockMapping[isoLevel][SEL_META_TAB_LOCK], implicitSavepoint, query);
          }
      }
      ByteBuffer bb = ByteBuffer.allocate(8).putLong(counter);
      bb.rewind();
      
     responseBuilder.addFirstPart(ByteString.copyFrom(bb));
    } catch (IOException e) {
       if (isLockException(e) || isFinalLockException(e)) {
         responseBuilder.setHasException(true);
         responseBuilder.setException(e.toString());
       } else {
         ResponseConverter.setControllerException(controller, e);
       }
    } finally {
      if (LockConstants.ENABLE_ROW_LEVEL_LOCK && !hasLocked && !skipLock && isoLevel == READCOMMITTED) {
          this.lockManager.enableEsca(transactionId);
      }
      if (scanner != null) {
        try {
          scanner.close();
        } catch (IOException ignored) {}
      }
    }

    if (LOG.isInfoEnabled()) LOG.info(String.format("Row counter for txId %d from this region: %s is %d, startKey is [%s], endKey is [%s]",
        transactionId, m_regionDetails, counter,
        regionInfo.getStartKey() == null ? "null" : Bytes.toStringBinary(regionInfo.getStartKey()),
        regionInfo.getEndKey() == null ? "null" : Bytes.toStringBinary(regionInfo.getEndKey())));

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transactionId, false);
      long timeCost = System.currentTimeMillis();
      mybuilder.setCoproSTime(startTime);
      mybuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[30] += timeCost;
      callCount[30]++;
      costStats.callCountPlus(29L);
      costStats.sumCostPlus(29L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " getRowNum txID " + transactionId + " CC " + callCount[30] + " ATC " + (costSum[30] / callCount[30]) + " TC " + timeCost);
          }
    }

    done.run(responseBuilder.build());
  }

  /**
   * Gives a Pair with first object as Sum and second object as row count,
   * computed for a given combination of column qualifier and column family in
   * the given row range as defined in the Scan object. In its current
   * implementation, it takes one column family and one column qualifier (if
   * provided). In case of null column qualifier, an aggregate sum over all the
   * entire column family will be returned.
   * <p>
   * The average is computed in
   * AggregationClient#avg(byte[], ColumnInterpreter, Scan) by
   * processing results from all regions, so its "ok" to pass sum and a Long
   * type.
   */
  @Override
  public void getAvg(RpcController controller, TransactionalAggregateRequest request,
      RpcCallback<TransactionalAggregateResponse> done) {
    TransactionalAggregateResponse response = null;
    RegionScanner scanner = null;
    int nameCount = request.getRegionNameCount();
    int iterate = 0;

    for (iterate = 0; iterate < nameCount; iterate++) {
      if (m_regionEncodedName.equals(request.getRegionName(iterate).toStringUtf8()))
       break;
    }
    if (iterate >= nameCount) {
      if (LOG.isWarnEnabled()) {
          LOG.warn("getAvg - Regions' name mismatch. Region's name is: " +  m_regionName);
      }

      response = TransactionalAggregateResponse.newBuilder().addFirstPart(
          ByteString.copyFrom(REGION_NAME_MISMATCH_EXCEPTION.getBytes())).setHasException(true).build();
      done.run(response);
      return;
    }
    String query = Bytes.toString(request.getQueryContext().toByteArray());

    try {
      ColumnInterpreter<T, S, P, Q, R> ci = constructColumnInterpreterFromRequest(request);
      S sumVal = null;
      Long rowCountVal = 0l;
      Scan scan = ProtobufUtil.toScan(request.getScan());
      long transactionId = request.getTransactionId();
      long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
      long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
      boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
      boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());
      long startId = request.getStartId();
      scanner = getScanner(transactionId, startId, scan, savepointId, pSavepointId, implicitSavepoint, query);
      byte[] colFamily = scan.getFamilies()[0];
      NavigableSet<byte[]> qualifiers = scan.getFamilyMap().get(colFamily);
      byte[] qualifier = null;
      if (qualifiers != null && !qualifiers.isEmpty()) {
        qualifier = qualifiers.pollFirst();
      }
      List<Cell> results = new ArrayList<Cell>();
      boolean hasMoreRows = false;
    
      do {
        results.clear();
        checkMemeoryUsage(transactionId);
        hasMoreRows = scanner.next(results);
        for (Cell kv : results) {
          sumVal = ci.add(sumVal, ci.castToReturnType(ci.getValue(colFamily,
              qualifier, kv)));
        }
        rowCountVal++;
      } while (hasMoreRows);
      if (sumVal != null) {
        ByteString first = ci.getProtoForPromotedType(sumVal).toByteString();
        TransactionalAggregateResponse.Builder pair = TransactionalAggregateResponse.newBuilder();
        pair.addFirstPart(first);
        ByteBuffer bb = ByteBuffer.allocate(8).putLong(rowCountVal);
        bb.rewind();
        pair.setSecondPart(ByteString.copyFrom(bb));
        response = pair.build();
      }
    } catch (IOException e) {
      ResponseConverter.setControllerException(controller, e);
    } finally {
      if (scanner != null) {
        try {
          scanner.close();
        } catch (IOException ignored) {}
      }
    }
    done.run(response);
  }

  /**
   * Gives a Pair with first object a List containing Sum and sum of squares,
   * and the second object as row count. It is computed for a given combination of
   * column qualifier and column family in the given row range as defined in the
   * Scan object. In its current implementation, it takes one column family and
   * one column qualifier (if provided). The idea is get the value of variance first:
   * the average of the squares less the square of the average a standard
   * deviation is square root of variance.
   */
  @Override
  public void getStd(RpcController controller, TransactionalAggregateRequest request,
      RpcCallback<TransactionalAggregateResponse> done) {
    RegionScanner scanner = null;
    TransactionalAggregateResponse response = null;
    try {
      ColumnInterpreter<T, S, P, Q, R> ci = constructColumnInterpreterFromRequest(request);
      S sumVal = null, sumSqVal = null, tempVal = null;
      long rowCountVal = 0l;
      Scan scan = ProtobufUtil.toScan(request.getScan());
      long transactionId = request.getTransactionId();
      long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
      long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
      boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
      boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());
      long startId = request.getStartId();
      String query = Bytes.toString(request.getQueryContext().toByteArray());
      scanner = getScanner(transactionId, startId, scan, savepointId, pSavepointId, implicitSavepoint, query);
      byte[] colFamily = scan.getFamilies()[0];
      NavigableSet<byte[]> qualifiers = scan.getFamilyMap().get(colFamily);
      byte[] qualifier = null;
      int nameCount = request.getRegionNameCount();
      int iterate = 0;

      for (iterate = 0; iterate < nameCount; iterate++) {
        if (m_regionEncodedName.equals(request.getRegionName(iterate).toStringUtf8()))
         break;
      }
      if (iterate >= nameCount) {
        if (LOG.isWarnEnabled()) {
            LOG.warn("getStd - Regions' name mismatch. Region's name is: " +  m_regionName);
        }

        response = TransactionalAggregateResponse.newBuilder().addFirstPart(
            ByteString.copyFrom(REGION_NAME_MISMATCH_EXCEPTION.getBytes())).setHasException(true).build();
        done.run(response);
        return;
      }

      if (qualifiers != null && !qualifiers.isEmpty()) {
        qualifier = qualifiers.pollFirst();
      }
      List<Cell> results = new ArrayList<Cell>();

      boolean hasMoreRows = false;
    
      do {
        tempVal = null;
        checkMemeoryUsage(transactionId);
        hasMoreRows = scanner.next(results);
        for (Cell kv : results) {
          tempVal = ci.add(tempVal, ci.castToReturnType(ci.getValue(colFamily,
              qualifier, kv)));
        }
        results.clear();
        sumVal = ci.add(sumVal, tempVal);
        sumSqVal = ci.add(sumSqVal, ci.multiply(tempVal, tempVal));
        rowCountVal++;
      } while (hasMoreRows);
      if (sumVal != null) {
        ByteString first_sumVal = ci.getProtoForPromotedType(sumVal).toByteString();
        ByteString first_sumSqVal = ci.getProtoForPromotedType(sumSqVal).toByteString();
        TransactionalAggregateResponse.Builder pair = TransactionalAggregateResponse.newBuilder();
        pair.addFirstPart(first_sumVal);
        pair.addFirstPart(first_sumSqVal);
        ByteBuffer bb = ByteBuffer.allocate(8).putLong(rowCountVal);
        bb.rewind();
        pair.setSecondPart(ByteString.copyFrom(bb));
        response = pair.build();
      }
    } catch (IOException e) {
      ResponseConverter.setControllerException(controller, e);
    } finally {
      if (scanner != null) {
        try {
          scanner.close();
        } catch (IOException ignored) {}
      }
    }
    done.run(response);
  }

  /**
   * Gives a List containing sum of values and sum of weights.
   * It is computed for the combination of column
   * family and column qualifier(s) in the given row range as defined in the
   * Scan object. In its current implementation, it takes one column family and
   * two column qualifiers. The first qualifier is for values column and 
   * the second qualifier (optional) is for weight column.
   */
  @Override
  public void getMedian(RpcController controller, TransactionalAggregateRequest request,
      RpcCallback<TransactionalAggregateResponse> done) {
    TransactionalAggregateResponse response = null;
    RegionScanner scanner = null;
    int nameCount = request.getRegionNameCount();
    int iterate = 0;

    for (iterate = 0; iterate < nameCount; iterate++) {
      if (m_regionEncodedName.equals(request.getRegionName(iterate).toStringUtf8()))
       break;
    }
    if (iterate >= nameCount) {
      if (LOG.isWarnEnabled()) {
          LOG.warn("getMedian - Regions' name mismatch. Region's name is: " +  m_regionName);
      }

      response = TransactionalAggregateResponse.newBuilder().addFirstPart(
          ByteString.copyFrom(REGION_NAME_MISMATCH_EXCEPTION.getBytes())).setHasException(true).build();
      done.run(response);
      return;
    }

    try {
      ColumnInterpreter<T, S, P, Q, R> ci = constructColumnInterpreterFromRequest(request);
      S sumVal = null, sumWeights = null, tempVal = null, tempWeight = null;
      Scan scan = ProtobufUtil.toScan(request.getScan());
      long transactionId = request.getTransactionId();
      long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
      long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
      boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
      boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());
      long startId = request.getStartId();
      String query = Bytes.toString(request.getQueryContext().toByteArray());
      scanner = getScanner(transactionId, startId, scan, savepointId, pSavepointId, implicitSavepoint, query);
      byte[] colFamily = scan.getFamilies()[0];
      NavigableSet<byte[]> qualifiers = scan.getFamilyMap().get(colFamily);
      byte[] valQualifier = null, weightQualifier = null;
      if (qualifiers != null && !qualifiers.isEmpty()) {
        valQualifier = qualifiers.pollFirst();
        // if weighted median is requested, get qualifier for the weight column
        weightQualifier = qualifiers.pollLast();
      }
      List<Cell> results = new ArrayList<Cell>();

      boolean hasMoreRows = false;
    
      do {
        tempVal = null;
        tempWeight = null;
        checkMemeoryUsage(transactionId);
        hasMoreRows = scanner.next(results);
        for (Cell kv : results) {
          tempVal = ci.add(tempVal, ci.castToReturnType(ci.getValue(colFamily,
              valQualifier, kv)));
          if (weightQualifier != null) {
            tempWeight = ci.add(tempWeight,
                ci.castToReturnType(ci.getValue(colFamily, weightQualifier, kv)));
          }
        }
        results.clear();
        sumVal = ci.add(sumVal, tempVal);
        sumWeights = ci.add(sumWeights, tempWeight);
      } while (hasMoreRows);
      ByteString first_sumVal = ci.getProtoForPromotedType(sumVal).toByteString();
      S s = sumWeights == null ? ci.castToReturnType(ci.getMinValue()) : sumWeights;
      ByteString first_sumWeights = ci.getProtoForPromotedType(s).toByteString();
      TransactionalAggregateResponse.Builder pair = TransactionalAggregateResponse.newBuilder();
      pair.addFirstPart(first_sumVal);
      pair.addFirstPart(first_sumWeights); 
      response = pair.build();
    } catch (IOException e) {
      ResponseConverter.setControllerException(controller, e);
    } finally {
      if (scanner != null) {
        try {
          scanner.close();
        } catch (IOException ignored) {}
      }
    }
    done.run(response);
  }

  @SuppressWarnings("unchecked")
  ColumnInterpreter<T,S,P,Q,R> constructColumnInterpreterFromRequest(
      TransactionalAggregateRequest request) throws IOException {
    String className = request.getInterpreterClassName();
    Class<?> cls;
    try {
      cls = Class.forName(className);
      ColumnInterpreter<T,S,P,Q,R> ci = (ColumnInterpreter<T, S, P, Q, R>) cls.newInstance();
      if (request.hasInterpreterSpecificBytes()) {
        ByteString b = request.getInterpreterSpecificBytes();
        P initMsg = ProtobufUtil.getParsedGenericInstance(ci.getClass(), 2, b);
        ci.initialize(initMsg);
      }
      return ci;
    } catch (ClassNotFoundException e) {
      throw new IOException(e);
    } catch (InstantiationException e) {
      throw new IOException(e);
    } catch (IllegalAccessException e) {
      throw new IOException(e);
    }
  }



  @Override
  public Service getService() {
    return this;
  }

  static public ConcurrentHashMap<String, TrxRegionEndpoint> getRegionMap() {
    return transactionsEPCPMap;
  }

  /**
   * Stores a reference to the coprocessor environment provided by the
   * {@link org.apache.hadoop.hbase.regionserver.RegionCoprocessorHost} 
   * from the region where this coprocessor is loaded.
   * Since this is a coprocessor endpoint, it always expects to be loaded
   * on a table region, so always expects this to be an instance of
   * {@link RegionCoprocessorEnvironment}.
   * @param env the environment provided by the coprocessor host
   * @throws IOException if the provided environment is not an instance of
   * {@code RegionCoprocessorEnvironment}
   */
  @Override
  public void start(CoprocessorEnvironment env) throws IOException {
    if (env instanceof RegionCoprocessorEnvironment) {
      this.env = (RegionCoprocessorEnvironment)env;
    } else {
      throw new CoprocessorException("start - Must be loaded on a table region!");
    }
    if (LOG.isTraceEnabled()) LOG.trace("start");
    RegionCoprocessorEnvironment tmp_env = 
      (RegionCoprocessorEnvironment)env;
#ifdef CDH5.7 APACHE1.2 CDH5.16
    this.m_Region = tmp_env.getRegion();
#else
    this.m_Region = (HRegion) tmp_env.getRegion();
#endif
    this.regionInfo = this.m_Region.getRegionInfo();

#ifdef CDH5.7 APACHE1.2 CDH5.16
    this.t_Region = (HRegion)tmp_env.getRegion();
#else
    this.t_Region = (TransactionalRegion) tmp_env.getRegion();
#endif

    this.config = tmp_env.getConfiguration();
    this.fs = FileSystem.get(config);
    try {
          hdfsSetStoragePolicyMethod = fs.getClass().getDeclaredMethod("setStoragePolicy",
            new Class<?>[] { Path.class, String.class });
            hdfsSetStoragePolicyMethod.setAccessible(true);
    } catch (NoSuchMethodException e) {
            hdfsSetStoragePolicyMethod = null;
            hdfsSetStoragePolicyReflectErrorMsg = "FileSystem doesn't support setStoragePolicy";
    } catch (SecurityException e) {
          hdfsSetStoragePolicyMethod = null;
          hdfsSetStoragePolicyReflectErrorMsg = "No access to setStoragePolicy on FileSystem from the SecurityManager";
    }

    regionServerStopper.inCreaseRegionNum();
    synchronized (stoppableLock) {
      try {
        TrxRegionEndpoint.transactionLeaseTimeout = config.getInt(LEASE_CONF, DEFAULT_LEASE_TIME);
        if (TrxRegionEndpoint.transactionLeaseTimeout < MINIMUM_LEASE_TIME) {
          if (LOG.isWarnEnabled()) LOG.warn("Transaction lease time: " + TrxRegionEndpoint.transactionLeaseTimeout + ", was less than the minimum lease time.  Now setting the timeout to the minimum default value: " + MINIMUM_LEASE_TIME);
          TrxRegionEndpoint.transactionLeaseTimeout = MINIMUM_LEASE_TIME;
        }

        TrxRegionEndpoint.scannerLeaseTimeoutPeriod = HBaseConfiguration.getInt(config,
								   HConstants.HBASE_CLIENT_SCANNER_TIMEOUT_PERIOD,
								   HConstants.HBASE_REGIONSERVER_LEASE_PERIOD_KEY,
								   HConstants.DEFAULT_HBASE_CLIENT_SCANNER_TIMEOUT_PERIOD);

        TrxRegionEndpoint.hbaseRpcTimeout = config.getInt("hbase.rpc.timeout", 60000);

        checkAndSetLockTimeOut(lockTimeOut);

        TrxRegionEndpoint.scannerThreadWakeFrequency = config.getInt(HConstants.THREAD_WAKE_FREQUENCY, 10 * 1000);

        this.regionTxnOptimization = config.getInt("hbase.transaction.regiontxn.optimization", 0);
        if (this.regionTxnOptimization > 0) {
           this.maxTxnPh2HLOG = (this.regionTxnOptimization) * 5;
        }

        this.txnStatisticsCollection = config.getInt("hbase.transaction.statistics", 0);

        this.cleanTimer = config.getInt(SLEEP_CONF, DEFAULT_SLEEP);
        TrxRegionEndpoint.memoryUsageThreshold = config.getInt(MEMORY_THRESHOLD, DEFAULT_MEMORY_THRESHOLD);
        TrxRegionEndpoint.memoryUsagePerformGC = config.getBoolean(MEMORY_PERFORM_GC, DEFAULT_MEMORY_PERFORM_GC);
        TrxRegionEndpoint.asyncWal = config.getInt(CONF_ASYNC_WAL, DEFAULT_ASYNC_WAL);
        TrxRegionEndpoint.skipWal = config.getBoolean(CONF_SKIP_WAL, DEFAULT_SKIP_WAL);
        TrxRegionEndpoint.fullEditInCommit = config.getBoolean(CONF_COMMIT_EDIT, DEFAULT_COMMIT_EDIT);
        
         TrxRegionEndpoint.shieldZKW = config.getBoolean(XDC_SHIELD_FROM_ZKW, DEFAULT_XDC_SHIELDZKW);
                
        TrxRegionEndpoint.useCommitIdInCells = config.getBoolean(CONF_TM_USE_COMMIT_ID_IN_CELLS, DEFAULT_TM_USE_COMMIT_ID_IN_CELLS);
        m_regionName = this.regionInfo.getRegionNameAsString();
        m_regionEncodedName = this.regionInfo.getEncodedName();
        m_isTrafodionMetadata = (m_regionName.startsWith("TRAF_RSRVD_1") && m_regionName.contains("_MD_"));
        if (m_regionName.contains("SB_HISTOGRAMS") || m_regionName.contains("SB_HISTOGRAM_INTERVALS") || m_regionName.contains("SB_PERSISTENT_SAMPLES")) {
            m_isTrafodionStatTable = true;
        }
        m_isTrafodionBRTable = (m_regionName.startsWith("TRAF_RSRVD_3") && m_regionName.contains("_BACKUP_") && !m_regionName.contains("SEABASE"));
        String tableString = new String (config.getTrimmed(DETAILED_LOGGING_STRING, ""));
        if (tableString.length() > 0 && !m_isTrafodionMetadata){
           m_detailedLogging = m_regionName.contains(tableString);
           if (LOG.isInfoEnabled()) LOG.info("Region Endpoint detailed logging: " + m_detailedLogging + " region: " + m_regionDetails);
        }
        String skey = (Bytes.equals(this.regionInfo.getStartKey(), HConstants.EMPTY_START_ROW)) ? "skey=null" : ("skey=" + Hex.encodeHexString(regionInfo.getStartKey()));
        String ekey = (Bytes.equals(this.regionInfo.getEndKey(), HConstants.EMPTY_END_ROW)) ? "ekey=null" : ("ekey=" + Hex.encodeHexString(regionInfo.getEndKey()));
	    m_regionDetails = new String(m_regionName + "," + skey + "," + ekey);
        TrxRegionEndpoint.memoryUsageWarnOnly = config.getBoolean(MEMORY_WARN_ONLY, DEFAULT_MEMORY_WARN_ONLY);
        this.memoryUsageTimer = config.getInt(MEMORY_CONF, DEFAULT_MEMORY_SLEEP);
//        this.checkRowBelongs = config.getBoolean(CHECK_ROW, true);

        TrxRegionEndpoint.suppressOutOfOrderProtocolException = config.getBoolean(SUPPRESS_OOP, DEFAULT_SUPPRESS_OOP);
	if (TrxRegionEndpoint.transactionLeases == null)  
	    TrxRegionEndpoint.transactionLeases = new Leases(LEASE_CHECK_FREQUENCY);

	//if (this.scannerLeases == null)  
	 //   this.scannerLeases = new Leases(scannerThreadWakeFrequency);

        if (LOG.isInfoEnabled()) LOG.info("Transaction lease time: "
            + TrxRegionEndpoint.transactionLeaseTimeout
            + " Scanner lease time: "
            + TrxRegionEndpoint.scannerThreadWakeFrequency
            + ", Scanner lease timeout period: "
            + TrxRegionEndpoint.scannerLeaseTimeoutPeriod
            + ", Clean timer: "
            + this.cleanTimer
            + ", MemoryUsage timer: "
            + this.memoryUsageTimer
            + ", MemoryUsageThreshold: "
            + TrxRegionEndpoint.memoryUsageThreshold
            + ", MemoryUsagePerformGC: "
            + TrxRegionEndpoint.memoryUsagePerformGC
            + ", MemoryUsageWarnOnly: "
            + TrxRegionEndpoint.memoryUsageWarnOnly
            + ", Suppress OutOfOrderProtocolExc: "
            + TrxRegionEndpoint.suppressOutOfOrderProtocolException
            + ", Transaction Statistics Collection: "
            + this.txnStatisticsCollection
            + ", Region Transaction Optimization: "
            + TrxRegionEndpoint.regionTxnOptimization
            + ", Max Ph2 commit HLOG buffer count "
            + maxTxnPh2HLOG
            + ", Shield from ZKW "
            + shieldZKW);

        // Start the clean core thread
        this.cleanOldTransactionsThread = new CleanOldTransactionsChore(this, cleanTimer, stoppable);
#ifdef HDP2.3 HDP2.4 CDH5.5 CDH5.7 APACHE1.2 CDH5.16
       txnChoreServiceThreadPoolSize = tmp_env.getConfiguration().getInt("hbase.regionserver.region.transactional.chore_service_thread_pool_size",
                DEFAULT_TXN_CHORE_SERVICE_THREAD_POOL_SIZE);        
        if (LOG.isTraceEnabled()) LOG.trace("Transactional chore thread pool size setting is " + TrxRegionEndpoint.txnChoreServiceThreadPoolSize);

        if (this.cleanOldTransactionsThread != null) {
            setupChoreService();
            s_ChoreService.scheduleChore(this.cleanOldTransactionsThread);
        }
#else
        UncaughtExceptionHandler handler = new UncaughtExceptionHandler() {

          public void uncaughtException(final Thread t, final Throwable e)
          {
            LOG.fatal("CleanOldTransactionChore uncaughtException: " + t.getName(), e);
          }
        };
 
        String n = Thread.currentThread().getName();
	
        ChoreThread = new Thread(this.cleanOldTransactionsThread);
        Threads.setDaemonThreadRunning(ChoreThread, n + ".oldTransactionCleaner", handler);
#endif

        // Start the memory usage chore thread if the threshold
        // selected is greater than the default of 100%.   

        if (memoryUsageThreshold <= DEFAULT_MEMORY_THRESHOLD &&
            memoryUsageThread == null) {
          if (LOG.isWarnEnabled()) {
              LOG.warn("start - starting memoryUsageThread");
          }

          memoryUsageThread = new MemoryUsageChore(this, memoryUsageTimer, regionServerStopper);
#ifdef HDP2.3 HDP2.4 CDH5.5 CDH5.7 APACHE1.2 CDH5.16

          if (this.memoryUsageThread != null) {
             s_ChoreService.scheduleChore(this.memoryUsageThread);
          }
        }

#else
          UncaughtExceptionHandler handler2 = new UncaughtExceptionHandler() {

            public void uncaughtException(final Thread t, final Throwable e)
            {
              LOG.fatal("MemoryUsageChore uncaughtException: " + t.getName(), e);
            }
          };

          String n2 = Thread.currentThread().getName();

          ChoreThread2 = new Thread(memoryUsageThread);
          Threads.setDaemonThreadRunning(ChoreThread2, n2 + ".memoryUsage", handler2);
        }
#endif

	if (TransactionalLeasesThread == null) {
	    if (LOG.isWarnEnabled()) {
	        LOG.warn("start - starting TransactionalLeasesThread");
	    }
	    TransactionalLeasesThread = new Thread(TrxRegionEndpoint.transactionLeases);
	    if (TransactionalLeasesThread != null) {
           Threads.setDaemonThreadRunning(TransactionalLeasesThread, "Transactional leases");
	    }
	}

/*
	if (ScannerLeasesThread == null) {
        LOG.warn("start - starting ScannerLeasesThread");
	    ScannerLeasesThread = new Thread(this.scannerLeases);
	    if (ScannerLeasesThread != null) {
           Threads.setDaemonThreadRunning(ScannerLeasesThread, "Scanner leases");
	    }
	}
*/

      } catch (Exception e) {
        throw new CoprocessorException("start - Caught exception " + e.getMessage() + " " + stackTraceToString(e));
      }
    }

#ifdef CDH5.7 APACHE1.2 CDH5.16
    this.t_Region = (HRegion)tmp_env.getRegion();
#else
    this.t_Region = (TransactionalRegion) tmp_env.getRegion();
#endif

    RegionServerServices rss = tmp_env.getRegionServerServices();
    tHLog = rss.getWAL(regionInfo);
    ServerName sn = rss.getServerName();
    lv_hostName = sn.getHostname();
    lv_port = sn.getPort();
    String lv_serverName = sn.getServerName();

    if (LOG.isTraceEnabled()) LOG.trace("hostname " + lv_hostName + " port " + lv_port);
#ifdef CDH5.7 APACHE1.2 CDH5.16
    this.t_Region = (HRegion)tmp_env.getRegion();
#else
    this.t_Region = (TransactionalRegion) tmp_env.getRegion();
#endif
    zkw1 = rss.getZooKeeper();
    rsServer = RSServer.getInstance(regionServerStopper, zkw1, config.get(HBASE_LOG_DIR, ""), lv_hostName);
    if (LockConstants.ENABLE_ROW_LEVEL_LOCK) {
        enableTmpWriterLock = false;
        enableTmpReadWriterLock = false;
        enableUseWaitQueue = false;
    }

    this.configuredEarlyLogging = tmp_env.getConfiguration().getBoolean("hbase.regionserver.region.transactional.earlylogging", false);
    if (LOG.isTraceEnabled()) LOG.trace("early logging setting is " + this.configuredEarlyLogging +
                  "\nget the reference from Region CoprocessorEnvironment ");

    this.configuredConflictReinstate = tmp_env.getConfiguration().getBoolean("hbase.regionserver.region.transactional.conflictreinstate", false);
    if (LOG.isTraceEnabled()) LOG.trace("conflict reinstate  setting is " + this.configuredConflictReinstate +
                  "\nget the reference from Region CoprocessorEnvironment ");

    this.useMC2 = tmp_env.getConfiguration().getBoolean("hbase.regionserver.region.transactional.useMC2", true);
    if (LOG.isInfoEnabled()) LOG.info("use MC2 setting is " + this.useMC2 +
                  "\nget the reference from Region TRX Endpoint CoprocessorEnvironment ");
    
    this.configuredPITRecovery = tmp_env.getConfiguration().getBoolean("hbase.regionserver.region.transactional.pit", false);
    this.configuredPITRecoveryHA = tmp_env.getConfiguration().getBoolean("hbase.regionserver.region.transactional.pit.ha", false);    
    
    this.PIT_max_txn_mutation_per_KV = tmp_env.getConfiguration().getInt("hbase.regionserver.region.transactional.pit_max_txn_per_kv", 10);
    this.PIT_max_txn_mutation_per_FILE = tmp_env.getConfiguration().getInt("hbase.regionserver.region.transactional.pit_max_txn_per_file", 10000);
    this.PIT_max_size_mutation_per_FILE = tmp_env.getConfiguration().getLong("hbase.regionserver.region.transactional.pit_max_size_per_file", 128000000);
	
    // PIT test 
    // this is used for RS PIT meta R/W ReentrantLock in mutation capture
    if (LOG.isTraceEnabled()) LOG.trace("PIT Recovery EPCP setting is " + this.configuredPITRecovery +
		  " PIT Recovery HA setting is " +  this.configuredPITRecoveryHA +
                  "\nget the reference from Region CoprocessorEnvironment ");
    
     if (LOG.isDebugEnabled()) LOG.debug("PIT EPCP Recovery mutation rollover attributes are" + 
		   " Max Txn per KV " + this.PIT_max_txn_mutation_per_KV +
		   " Max Txn per FILE " + this.PIT_max_txn_mutation_per_FILE +
     		   " Max Size per FILE " + this.PIT_max_size_mutation_per_FILE );

    if (tmp_env.getSharedData().isEmpty())
       if (LOG.isTraceEnabled()) LOG.trace("shared map is empty ");
    else
       if (LOG.isTraceEnabled()) LOG.trace("shared map is NOT empty");

    transactionsEPCPMap.put(m_regionName + trxkeyEPCPinstance, this);

    transactionsByIdTestz = TrxRegionObserver.getRefMap();

    if (transactionsByIdTestz.isEmpty()) {
       if (LOG.isTraceEnabled()) LOG.trace("reference map is empty ");
    }
    else  {
       if (LOG.isTraceEnabled()) LOG.trace("reference map is NOT empty ");
    }
    if (LOG.isTraceEnabled()) LOG.trace("Region " + m_regionDetails + " check indoubt list from reference map ");

    Map<Long, List<WALEdit>> indoubtTransactionsByIdCheck = (TreeMap<Long, List<WALEdit>>)transactionsByIdTestz.get(
            m_regionName + TrxRegionObserver.trxkeypendingTransactionsById);
    if(indoubtTransactionsByIdCheck != null) {
        this.indoubtTransactionsById = indoubtTransactionsByIdCheck;
    }
    else {
        transactionsByIdTestz.put(m_regionName + TrxRegionObserver.trxkeypendingTransactionsById,
                                  this.indoubtTransactionsById);
    }

    Map<Integer, Integer> indoubtTransactionsCountByTmidCheck = (TreeMap<Integer,Integer>)transactionsByIdTestz.get(
            m_regionName + TrxRegionObserver.trxkeyindoubtTransactionsCountByTmid);
    if(indoubtTransactionsCountByTmidCheck != null) {
        this.indoubtTransactionsCountByTmid = indoubtTransactionsCountByTmidCheck;
    }
    else {
        transactionsByIdTestz.put(m_regionName + TrxRegionObserver.trxkeyindoubtTransactionsCountByTmid,
                                  this.indoubtTransactionsCountByTmid);
    }

    Set<TrxTransactionState> commitPendingTransactionsCheck = (Set<TrxTransactionState>)transactionsByIdTestz.get(
            m_regionName + TrxRegionObserver.trxkeycommitPendingTransactions);
    if(commitPendingTransactionsCheck != null) {
        this.commitPendingTransactions = commitPendingTransactionsCheck;
    }
    else {
        transactionsByIdTestz.put(m_regionName + TrxRegionObserver.trxkeycommitPendingTransactions,
                this.commitPendingTransactions);
    }

    ConcurrentHashMap<Long, TrxTransactionState> transactionsByIdCheck = (ConcurrentHashMap<Long, TrxTransactionState>) transactionsByIdTestz.get(
            m_regionName + TrxRegionObserver.trxkeytransactionsById);
    if(transactionsByIdCheck != null) {
        this.transactionsById = transactionsByIdCheck;
    }
    else {
        transactionsByIdTestz.put(m_regionName + TrxRegionObserver.trxkeytransactionsById,
                                  this.transactionsById);
    }
    
   SortedMap<Long, TrxTransactionState> commitedTransactionsBySequenceNumberCheck = (SortedMap<Long, TrxTransactionState>)
                                                                       transactionsByIdTestz
                                                                       .get(m_regionName + TrxRegionObserver.trxkeycommitedTransactionsBySequenceNumber);
   if(commitedTransactionsBySequenceNumberCheck != null) {
       this.commitedTransactionsBySequenceNumber = commitedTransactionsBySequenceNumberCheck;
   }
   else {
       transactionsByIdTestz.put(m_regionName + TrxRegionObserver.trxkeycommitedTransactionsBySequenceNumber, this.commitedTransactionsBySequenceNumber);
   }

   AtomicBoolean onlineBalanceCheck = (AtomicBoolean)transactionsByIdTestz
                                               .get(m_regionName+TrxRegionObserver.trxkeyOnlineBalanceVar);
   if(onlineBalanceCheck != null) {
       this.onlineBalance = onlineBalanceCheck;
   }
   else {
       transactionsByIdTestz.put(m_regionName+TrxRegionObserver.trxkeyOnlineBalanceVar, this.onlineBalance);
   }

    MutationCapture mutationCap = (MutationCapture)transactionsByIdTestz
                                               .get(m_regionName + TrxRegionObserver.trxkeyMutationCapture);
    if(mutationCap != null) {
       this.mutationCapture = mutationCap;
       if (LOG.isTraceEnabled()) LOG.trace("PIT MutationCapture has been created in Observer during EPCP start ");
    }
    else {
       this.mutationCapture = new MutationCapture(this.config, 
						  this.fs,
						  context,
						  regionInfo, 
						  this.PIT_max_txn_mutation_per_KV,
						  this.PIT_max_txn_mutation_per_FILE,
						  this.PIT_max_size_mutation_per_FILE,
                                                  this.configuredPITRecoveryHA);
       transactionsByIdTestz.put(m_regionName + TrxRegionObserver.trxkeyMutationCapture, this.mutationCapture);
    }

    AtomicBoolean blockAllCheck = (AtomicBoolean)transactionsByIdTestz
            .get(m_regionName + TrxRegionObserver.trxkeyCheckBlockAllVar);
    if(blockAllCheck != null) {
        this.blockAll = blockAllCheck;
    }
    else {
        transactionsByIdTestz.put(m_regionName + TrxRegionObserver.trxkeyCheckBlockAllVar,
                                  this.blockAll);
    }
   
    AtomicBoolean blockPhase1Check = (AtomicBoolean)transactionsByIdTestz
            .get(m_regionName + TrxRegionObserver.trxkeyCheckBlockPhase1Var);
    if(blockPhase1Check != null) {
        this.blockPhase1 = blockPhase1Check;
    }
    else {
        transactionsByIdTestz.put(m_regionName + TrxRegionObserver.trxkeyCheckBlockPhase1Var,
                                  this.blockPhase1);
    }

    AtomicBoolean blockNonPhase2Check = (AtomicBoolean)transactionsByIdTestz
            .get(m_regionName + TrxRegionObserver.trxkeyCheckBlockNonPhase2Var);
    if(blockNonPhase2Check != null) {
        this.blockNonPhase2 = blockNonPhase2Check;
    }
    else {
        transactionsByIdTestz.put(m_regionName + TrxRegionObserver.trxkeyCheckBlockNonPhase2Var,
                                  this.blockNonPhase2);
    }
   
    AtomicBoolean newTransCheck = (AtomicBoolean)transactionsByIdTestz
            .get(m_regionName + TrxRegionObserver.trxkeyCheckBlockNewTransVar);
    if(newTransCheck != null) {
        this.blockNewTrans = newTransCheck;
    }
    else {
        transactionsByIdTestz.put(m_regionName + TrxRegionObserver.trxkeyCheckBlockNewTransVar,
                                  this.blockNewTrans);
    }
    
    Object commitCheckLockCheck = (Object)transactionsByIdTestz
                                               .get(m_regionName + TrxRegionObserver.trxkeyCheckCommitCheckLockVar);
   if(commitCheckLockCheck != null) {
       this.commitCheckLock = commitCheckLockCheck;
   }
   else {
       transactionsByIdTestz.put(m_regionName + TrxRegionObserver.trxkeyCheckCommitCheckLockVar, this.commitCheckLock);
   }
   
   AtomicInteger regionStateLockCheck = (AtomicInteger)transactionsByIdTestz
                                               .get(m_regionName + TrxRegionObserver.trxkeyRegionStateLockVar);
   if(regionStateLockCheck != null) {
       this.regionState = regionStateLockCheck;
   }
   else {
       transactionsByIdTestz.put(m_regionName + TrxRegionObserver.trxkeyRegionStateLockVar, this.regionState);
   }   
    
    AtomicBoolean deferRegionSplitCheck = (AtomicBoolean)transactionsByIdTestz
            .get(m_regionName + TrxRegionObserver.trxkeyDeferRegionSplitVar);
    if(deferRegionSplitCheck != null) {
        this.deferRegionSplit = deferRegionSplitCheck;
    }
    else {
        transactionsByIdTestz.put(m_regionName + TrxRegionObserver.trxkeyDeferRegionSplitVar,
                                  this.deferRegionSplit);
    }
    
    ConcurrentHashMap<Long,TransactionalRegionScannerHolder> scannersCheck =
        (ConcurrentHashMap<Long,TransactionalRegionScannerHolder>)transactionsByIdTestz
        .get(m_regionName + TrxRegionObserver.trxkeyScanners);
    if(scannersCheck != null) {
      this.scanners = scannersCheck;
    }
    else {
      transactionsByIdTestz.put(m_regionName + TrxRegionObserver.trxkeyScanners,
                              this.scanners);
    }

    // Set up the memoryBean from the ManagementFactory
    if (memoryUsageThreshold < DEFAULT_MEMORY_THRESHOLD) 
      memoryBean = ManagementFactory.getMemoryMXBean();

    if (!ATRConfig.instance().isRemote()) {
        HBaseBinlog.local_instance().initializeBinlog(this.config);
    } else {
        if (ATRConfig.instance().isDualMode()) {
            HBaseBinlog.local_instance().initializeBinlog(this.config);
            HBaseBinlog.remote_instance().initializeBinlog(this.config);
        } else {
            HBaseBinlog.remote_instance().initializeBinlog(this.config);
        }
    }

    if (LOG.isInfoEnabled()) {
        LOG.info ("TRX Endpoint coprocessor, "
		  + " regionDetails: " +  m_regionDetails
		  + ", isTrafodionMD: " + m_isTrafodionMetadata
		  + ", starting with asyncWal: " + asyncWal
		  + ", skipWal: " + skipWal
		  + ", useCommitIdInCells: " + useCommitIdInCells
		  + ", and fullEditInCommit: " + fullEditInCommit
		  + ". chore thread pool size: " + txnChoreServiceThreadPoolSize
          + ", Transaction lease time: " + TrxRegionEndpoint.transactionLeaseTimeout
          + ", Scanner lease time: " + TrxRegionEndpoint.scannerThreadWakeFrequency
          + ", Scanner lease timeout period: " + TrxRegionEndpoint.scannerLeaseTimeoutPeriod
          + ", Clean timer: " + this.cleanTimer
          + ", MemoryUsage timer: " + this.memoryUsageTimer
          + ", MemoryUsageThreshold: " + TrxRegionEndpoint.memoryUsageThreshold
          + ", MemoryUsagePerformGC: " + TrxRegionEndpoint.memoryUsagePerformGC
          + ", MemoryUsageWarnOnly: " + TrxRegionEndpoint.memoryUsageWarnOnly
          + ", Suppress OutOfOrderProtocolExc: " + TrxRegionEndpoint.suppressOutOfOrderProtocolException);
   }

    if (LOG.isTraceEnabled()) LOG.trace("start");
  }

  @Override
  public void stop(CoprocessorEnvironment env) throws IOException {
      
    //if (LOG.isTraceEnabled()) LOG.trace("Stop 1 - " + m_regionName + " - transactionsById (" + transactionsById.size()
    //                    + " ), committed Transactions (" + commitedTransactionsBySequenceNumber.size() +"), scanners (" + scanners.size() + ")");      
      
    if (LOG.isTraceEnabled()) LOG.trace("stop ");
    stoppable.stop("stop() TrxRegionEndpoint region: " + m_regionDetails);
    regionServerStopper.stop("stop() TrxRegionEndpoint region: " + m_regionDetails);
    
    // PIT: close mutation file if any

    if (LOG.isTraceEnabled()) LOG.trace("stop and close mutation file if any in PIT mode");
    // mutationCapture.mutationBufferOp(PIT_MUTATION_CLOSE_STOP, null, null, 0, 0, -1, -1, 0);
    if (useMC2) {
        if (mutationCapture2 != null) {
            mutationCapture2.MC2_doWriterOperation(PIT2_MUTATION_WRITER_CLOSE);
        }
	}
    else {
        mutationCapture.mutationBufferOp(PIT_MUTATION_CLOSE_STOP, null, null, 0, 0, -1, -1, 0);
    }

    transactionsEPCPMap.remove(m_regionName + trxkeyEPCPinstance);
  }

#ifdef CDH5.7 APACHE1.2 CDH5.16
  /**
   * Determines if the specified row is within the row range specified by the
   * specified HRegionInfo
   *
   * @param info HRegionInfo that specifies the row range
   * @param row row to be checked
   * @return true if the row is within the range specified by the HRegionInfo
   */
  public static boolean rowIsInRange(HRegionInfo info, final byte [] row) {
    return ((info.getStartKey().length == 0) ||
        (Bytes.compareTo(info.getStartKey(), row) <= 0)) &&
        ((info.getEndKey().length == 0) ||
            (Bytes.compareTo(info.getEndKey(), row) > 0));
  }
#endif

#ifdef HDP2.3 HDP2.4 CDH5.5
  private synchronized void setupChoreService() { 
      if (s_ChoreService == null) {
    s_ChoreService = new ChoreService("Cleanup ChoreService", TrxRegionEndpoint.txnChoreServiceThreadPoolSize);
      }
  }
#endif

#ifdef CDH5.7 APACHE1.2 CDH5.16
  private synchronized void setupChoreService() {
      if (s_ChoreService == null) {
    s_ChoreService = new ChoreService("Cleanup ChoreService", TrxRegionEndpoint.txnChoreServiceThreadPoolSize, true);
      }
  }
#endif

  // Internal support methods
   /**
   * Checks if the region is closing and needs to block all activity
   * @param long transactionId
   * @return String 
   * @throws IOException 
   */
  private void checkBlockAll(final long transactionId) throws IOException {
    long loops = RSConstants.MAX_BLOCK_CHECK_RETRY_TIMES;
    while (blockAll.get()) {
      if (loops-- > 0) {
        try {
           Thread.sleep(10);
        } catch(InterruptedException ex) {
             Thread.currentThread().interrupt();
        }
	continue;
      }

      // report error if delay 1 second
      if(LOG.isWarnEnabled()) LOG.warn("checkBlockAll - txId " + transactionId + ", No Transactional activity allowed.");
      throw new IOException("closing region, no more transactional activity allowed. Region: " + m_regionDetails);
    }
  }

  /**
   * Checks if the region has a snapshot pending for a backup and needs to keep the HFile static for a small duration.  This allows for a consistent snapshot
   * @param long transactionId
   * @return String 
   * @throws IOException 
   */
  private void checkBlockPhase1(final long transactionId) throws IOException {
    long loops = RSConstants.MAX_BLOCK_CHECK_RETRY_TIMES;
    while (blockPhase1.get()) {
      if (loops-- > 0) {
        try {
           Thread.sleep(10);
        } catch(InterruptedException ex) {
             Thread.currentThread().interrupt();
        }
	continue;
      }

      // report error if delay 1 second
      if(LOG.isWarnEnabled()) LOG.warn("checkBlockPhase1 - txId " + transactionId + ", No Phase1 Transactional activity allowed.");
      throw new IOException("Backup in progress for region, no more phase1 transactional activity allowed. Region: " + m_regionDetails);
    }

    // sometimes we only set the most severe in which case we always need to check the higher up levels
    checkBlockAll(transactionId);
  }

  /**
   * Checks if the region is closing and needs to block non phase 2 activity
   * @param long transactionId
   * @return String
   * @throws IOException
   */
  private void checkBlockNonPhase2(final long transactionId) throws IOException {
    long loops = (onlineBalance.get() ? 0 : RSConstants.MAX_BLOCK_CHECK_RETRY_TIMES);
    while (blockNonPhase2.get() || onlineBalance.get()) {
      if (loops-- > 0) {
        try {
           Thread.sleep(10);
        } catch(InterruptedException ex) {
             Thread.currentThread().interrupt();
        }
	continue;
      }

      // report an error if delay 1 second
      if(LOG.isWarnEnabled()) LOG.warn("checkBlockNonPhase2 - txId " + transactionId + ", No Transactional activity allowed.");

      throw new IOException("closing region, no more non phase 2 transactional activity allowed. Region: " + m_regionDetails);
    }

    TrxTransactionState state = transactionsById.get(getTransactionalUniqueId(transactionId));
    if (state != null && state.isReadFromHdfs())
        throw new IOException("region is balanced - txId " + transactionId + ", No Transactional activity allowed.");

    // sometimes we only set the most severe in which case we always need to check the higher up levels
    checkBlockAll(transactionId);
  }

  /**
   * Checks if we are blocking transactions that originate on a different cluster
   * @param long transactionId
   * @throws IOException
   */
  private void checkBlockForeignTransactions(final long transactionId) throws RegionShieldedException {
    
    if (shieldZKW) {
       try {
          pSTRConfig = STRConfig.getInstance(this.config);
          if (pSTRConfig.shieldFromRemote(pSTRConfig.getTrafClusterIdInt())) {
             if(LOG.isDebugEnabled()) LOG.debug("XDC local cluster is NOT allowed to transactional access originated from remote cluster ");
             if (TrxTransactionState.getClusterId(transactionId) != (pSTRConfig.getTrafClusterIdInt())) {
                 if(LOG.isDebugEnabled()) LOG.debug("checkBlockForeignTransactions - txId " + transactionId
                     + " was started on cluster " + TransactionState.getClusterId(transactionId)
                     + ", No Transactional activity allowed if not started on cluster " + pSTRConfig.getTrafClusterIdInt());
                 throw new RegionShieldedException("checkBlockForeignTransactions - txId " + transactionId
                     + " was started on cluster " + TransactionState.getClusterId(transactionId)
                     + ", No Transactional activity allowed if not started on cluster " + pSTRConfig.getTrafClusterIdInt()
                     + " Region: " + m_regionDetails);
             } // tid from peer       
          } // shielded from remote now
       } catch(ZooKeeperConnectionException xe) {
          if (LOG.isWarnEnabled()) {
              LOG.warn("XDC ZooKeeperConnectionException, configuration " + pSTRConfig.getTrafClusterIdInt() + " PSTRCONFIG " + pSTRConfig.toString() +
                             " tid " + TrxTransactionState.getClusterId(transactionId));
          }
          throw new RegionShieldedException("checkBlockForeignTransactions ZooKeeperConnectionException - txId " + transactionId
                     + " was started on cluster " + TransactionState.getClusterId(transactionId)
                     + ", there is XDC configuration issue, " + pSTRConfig.getTrafClusterIdInt()
                     + " Region: " + m_regionDetails);
       } catch(IOException xe) {
          if (LOG.isWarnEnabled()) {
              LOG.warn("XDC IOException, configuration " + pSTRConfig.getTrafClusterIdInt() + " PSTRCONFIG " + pSTRConfig.toString() +
                             " tid " + TrxTransactionState.getClusterId(transactionId));
          }
          throw new RegionShieldedException("checkBlockForeignTransactions IOException - txId " + transactionId
                     + " was started on cluster " + TransactionState.getClusterId(transactionId)
                     + ", there is XDC configuration issue, " + pSTRConfig.getTrafClusterIdInt()
                     + " Region: " + m_regionDetails);
       }
    } // shieldZKW
    else {
       if (readDefaultShieldFromZK) {
          try {
            pSTRConfig = STRConfig.getInstance(this.config);
            boolean lv_get_complete_status = true;
            if (pSTRConfig.getPeerStatus(pSTRConfig.getTrafClusterIdInt(), lv_get_complete_status).contains(PeerInfo.PEER_ATTRIBUTE_SHIELD))
                shieldFromRemote = true; // default is false for non-ZK case
            readDefaultShieldFromZK = false;                
          } catch (ZooKeeperConnectionException xe) {
           LOG.error("An ERROR ZooKeeperConnectionException occurred while getting the STR Configuration", xe);
          } catch (IOException xe) {
           LOG.error("An ERROR IOException occurred while getting the STR Configuration", xe);
          }                  
          if (LOG.isInfoEnabled()) LOG.info("Default shieldFromRemote value from ZK " + shieldFromRemote
             + " Region: " + m_regionDetails);
       } // readDefaultShieldFromZK
    
       if (shieldFromRemote) {
         if (TrxTransactionState.getClusterId(transactionId) != (pSTRConfig.getTrafClusterIdInt())) {
            if(LOG.isDebugEnabled()) LOG.debug("checkBlockForeignTransactions - txId " + transactionId
               + " was started on cluster " + TransactionState.getClusterId(transactionId)
               + ", No Transactional activity allowed if not started on cluster " + pSTRConfig.getTrafClusterIdInt());
            throw new RegionShieldedException("checkBlockForeignTransactions - txId " + transactionId
               + " was started on cluster " + TransactionState.getClusterId(transactionId)
               + ", No Transactional activity allowed if not started on cluster " + pSTRConfig.getTrafClusterIdInt()
               + " Region: " + m_regionDetails);
         }
       } // shieldFromRemote
    } // else
  }

  /**
   * Checks if new transactions are disabled
   * @param long transactionId
   * @return String 
   * @throws IOException 
   */
  private void checkBlockNewTrans(final long transactionId) throws RegionShieldedException, IOException {
    long loops = RSConstants.MAX_BLOCK_CHECK_RETRY_TIMES;
    while (blockNewTrans.get()) {
      if (loops-- > 0) {
        try {
           Thread.sleep(10);
        } catch(InterruptedException ex) {
             Thread.currentThread().interrupt();
        }
	continue;
      }

      if(LOG.isWarnEnabled()) LOG.warn("checkNewTrans - txId " + transactionId + ", No more new transactions allowed.");
       throw new IOException("closing region, no more new transactions allowed. Region: " + m_regionDetails);
     }

    // sometimes we only set the most sever in which case we always need to check the higher up levels
    checkBlockNonPhase2(transactionId);

//    checkBlockForeignTransactions(transactionId);

  }

  /**
   * Gets the transaction state                   
   * @param long transactionId
   * @return TrxTransactionState
   * @throws UnknownTransactionException
   */
  protected TrxTransactionState getTransactionState(final long transactionId)
   throws UnknownTransactionException {
    TrxTransactionState state = null;
    boolean throwUTE = false;

    Long key = getTransactionalUniqueId(transactionId);
    String leaseKey = getTransactionalLeaseId(transactionId);
    state = transactionsById.get(key);

    if (state == null) 
    {
      if (LOG.isTraceEnabled()) LOG.trace("getTransactionState Unknown transaction: [" + transactionId + "], throwing UnknownTransactionException");
        throwUTE = true;
    }
    else {
      if (LOG.isTraceEnabled()) LOG.trace("getTransactionState Found transaction: [" + transactionId + "]");

      try {
         transactionLeases.renewLease(leaseKey);
      } catch (LeaseException e) {
         if (LOG.isTraceEnabled()) LOG.trace("getTransactionState renewLease failed will try to createLease for transaction: [" + transactionId + "]");
         try {
            transactionLeases.createLease(leaseKey, transactionLeaseTimeout, new TransactionLeaseListener(transactionId));
         } catch (LeaseStillHeldException lshe) {
            if (LOG.isTraceEnabled()) LOG.trace("getTransactionState renewLeasefollowed by createLease failed throwing original LeaseException for transaction: [" + transactionId + "]");
            throw new RuntimeException(e);
         }
      }
    }

    if (throwUTE)
      throw new UnknownTransactionException();

    return state;
  }

  private void retireTransactionAndWriteAbortWal(final TrxTransactionState state) {
    if (state.hasWrite()) {
      Tag abortTag = state.formTransactionalContextTag(TS_ABORT, state.getStartId());
      List<Tag> tagList = new ArrayList<Tag>();
      tagList.add(abortTag);

#ifdef CDH5.7 APACHE1.2 CDH5.16
      MultiVersionConcurrencyControl.WriteEntry writeEntry = null;
      long mvccNum = 0;
#endif
      WALEdit e1 = state.editConstructFirstWriteAction();
      if (e1.getCells().size() > 0) {
        WALEdit e = new WALEdit();
        Cell c = e1.getCells().get(0);
        KeyValue kv = new KeyValue(c.getRowArray(), c.getRowOffset(), (int)c.getRowLength(),
         c.getFamilyArray(), c.getFamilyOffset(), (int)c.getFamilyLength(),
         c.getQualifierArray(), c.getQualifierOffset(), (int) c.getQualifierLength(),
         c.getTimestamp(), Type.codeToType(c.getTypeByte()), c.getValueArray(), c.getValueOffset(),
         c.getValueLength(), tagList);
      
        e.add(kv);
        try {
#ifdef CDH5.7 APACHE1.2 CDH5.16	
          WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(), 
                                 this.regionInfo.getTable(), 
                                 WALKey.NO_SEQUENCE_ID,
                                 TrxEnvironmentEdgeManager.currentTime(),
                                 WALKey.EMPTY_UUIDS,
                                 HConstants.NO_NONCE,
                                 HConstants.NO_NONCE,
                                 this.t_Region.getMVCC());

          long txid = this.tHLog.append(this.m_Region.getTableDesc(), this.regionInfo, wk, e, false);
          writeEntry = wk.getWriteEntry();
          mvccNum = writeEntry.getWriteNumber();					     
#else
          final WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(),
                                        this.regionInfo.getTable(),
                                        TrxEnvironmentEdgeManager.currentTime());

          long txid = this.tHLog.append(this.m_Region.getTableDesc(),
                                   this.regionInfo, 
                                   wk , 
                                   e,
                                   this.m_Region.getSequenceId(), 
                                   false,
                                   null);
#endif

#ifdef CDH5.7 APACHE1.2 CDH5.16 
          if (writeEntry != null) {
            this.t_Region.getMVCC().completeAndWait(writeEntry);
            writeEntry = null;
          }
#endif
        } catch (Exception exp) {
          LOG.warn("retireTransactionAndWriteAbortWal - failed to write abort wal." + exp); 
        }
      }
    }
    retireTransaction(state, true, true);
  }

  private void retireTransaction(final TrxTransactionState state, final boolean clear) {
    retireTransaction(state, clear, true);
  }

  /**
   * Retires the transaction                        
   * @param TrxTransactionState state
   */
  private void retireTransaction(final TrxTransactionState state, final boolean clear, final boolean nonPutRegionTxn) {
    long transId = state.getTransactionId();
    Long key = getTransactionalUniqueId(transId);
    String leaseKey = getTransactionalLeaseId(transId);

    if (LOG.isTraceEnabled()) LOG.trace("retireTransaction: [" + state + "]");


    if (nonPutRegionTxn) {
    try {
      transactionLeases.cancelLease(leaseKey);
    } catch (LeaseException le) {
      if (LOG.isTraceEnabled()) LOG.trace("retireTransaction: ["
               + transId + "] LeaseException");
      // Ignore
    } catch (Exception e) {
      if (LOG.isTraceEnabled()) LOG.trace("retireTransaction: ["
               + transId + "] General Lease exception" + e.getMessage() + " " + stackTraceToString(e));
      // Ignore
    }
    }

    if (LOG.isTraceEnabled()) LOG.trace("retireTransaction clearTransactionsToCheck for region: " + m_regionDetails + " from all its TrxTransactionState lists");

/* comment out after DWE fix    
    if (state.prepareEditSize != state.getEdit().getCells().size() &&
       (state.prepareEditSize != 0 ||
       (! state.getStatus().equals(Status.ABORTED)))){
       if (LOG.isWarnEnabled()) LOG.warn("retireTransaction prepareEditSize (" + state.prepareEditSize
           + ") is different from edit cells size (" + state.getEdit().getCells().size() + ") for: " + state);
    }
*/
     List<ByteArrayKey> locksToRemove = state.listOfLockedRowsSelForUpdate;
     List<ByteArrayKey> wlocksToRemove = state.listOfWLockedRows;	 
    // Clear out transaction state
    if (clear == true) {
      state.clearState();
      if (LOG.isTraceEnabled()) LOG.trace("retireTransaction clearState for region: " + m_regionDetails + " from all its TrxTransactionState lists");
    }
    else {
      state.clearTransactionsToCheck();	
      if (LOG.isTraceEnabled()) LOG.trace("retireTransaction clearTransactionsToCheck for : " + m_regionDetails);
    }

    synchronized (cleanScannersForTransactions) {
      cleanScannersForTransactions.add(transId);
    }

    if (nonPutRegionTxn) {
    synchronized (commitPendingTransactions) {
         if (commitPendingTransactions.remove(state)) {
            LOG.info("TrxRegionEndpoint coprocessor:retireTransaction: Detected and removed read only branch in commitPendingList: " + state
                        + " Region: " + m_regionDetails);
         }
    }
    }

    if (LOG.isTraceEnabled()) LOG.trace("retireTransaction calling remove entry for: " + key + " , from transactionById map " + m_regionName);
    synchronized (transactionsById) {
        transactionsById.remove(key);
    }
    if (LockConstants.ENABLE_ROW_LEVEL_LOCK && state.getIsRegionTx()) {
        rsServer.removeRegionTx(transId);
    }

    if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor:retireTransaction " + key + ", looking for retire transaction id " + transId + ", transactionsById " + transactionsById.size() + ", commitedTransactionsBySequenceNumber " + commitedTransactionsBySequenceNumber.size() + ", commitPendingTransactions " + commitPendingTransactions.size());

    if (!LockConstants.ENABLE_ROW_LEVEL_LOCK) {
      synchronized(selectForUpdateLockHashmap) {
        for(int i=0; i< locksToRemove.size(); i++)
        {
          ByteArrayKey rowInHex = locksToRemove.get(i);

          selectForUpdateLockHashmap.remove(rowInHex);
          if(selectForUpdateLockWaitQueue.containsKey(rowInHex) && enableUseWaitQueue == true)
          {
             List<Long> waitTrxList = selectForUpdateLockWaitQueue.get(rowInHex);
             if(waitTrxList.size() == 0)
               selectForUpdateLockWaitQueue.remove(rowInHex);
          }
          if (LOG.isDebugEnabled()) LOG.debug("LOCKDBG: remove lock [" + rowInHex + "] at line 5141 for trx " + transId);
        }
      }
    }
	
    if(enableTmpWriterLock == true) {
       synchronized(tmpWriteLockHashmap) {
          long nowts = TrxEnvironmentEdgeManager.currentTime();

          if(maxWriteLockFreeTs < nowts ) maxWriteLockFreeTs = nowts;
          Long tk = transId;
          tmpRangeLockTime.remove( tk );
/*
          for(int i=0; i < wlocksToRemove.size(); i++) {
	    ByteArrayKey rowInHex = wlocksToRemove.get(i);
	    tmpWriteLockHashmap.remove(rowInHex);
	   }
*/
          Iterator iter = tmpWriteLockHashmap.entrySet().iterator();
          while(iter.hasNext()) {
            Map.Entry<ByteArrayKey, trafLockInfo> entry = (Map.Entry<ByteArrayKey, trafLockInfo>) iter.next();
            trafLockInfo ti = entry.getValue();
            if(ti.getTid() == transId)
              iter.remove();
          } 
	}
        synchronized(tmpRangeLock) {
          Iterator<trafLockInfo> it = tmpRangeLock.iterator();	
          while(it.hasNext()) {
            trafLockInfo tli = it.next();
            if(tli.getTid() == transId)
              it.remove();
          }
       }
    }
  }

  public void choreThreadDetectStaleTransactionBranch() {

      synchronized(choreDetectStaleBranchLock) {

      List<Integer> staleBranchforTMId = new ArrayList<Integer>();
      List<TrxTransactionState> commitPendingCopy = new ArrayList<TrxTransactionState>(commitPendingTransactions);
      Map<Long, List<WALEdit>> indoubtTransactionsMap = null;
      synchronized(indoubtTransactionsById){
         indoubtTransactionsMap = new TreeMap<Long, List<WALEdit>>(indoubtTransactionsById);
      }
      int tmid, clusterid, tm;

      // selected printout for CP
      long currentEpoch = controlPointEpoch.get();
      if ((currentEpoch < 10) || ((currentEpoch % 20) == 1)) {
         if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor:choreThreadDetectStaleTransactionBranch: Region "
             + m_regionDetails + " ChoreThread CP Epoch " + controlPointEpoch.get());
      }

      byte [] lv_byte_region_info = regionInfo.toByteArray();
      String lv_encoded = regionInfo.getEncodedName();
      
      try {
         pSTRConfig = STRConfig.getInstance(this.config);
      } catch (Exception xe) {
         LOG.error("An ERROR occurred while getting the STR Configuration", xe);
      }

      long transactionId = 0;
      if (this.regionState.intValue() == REGION_STATE_REPLAY) {
               if (LOG.isTraceEnabled()) LOG.trace("chore thread Trafodion Recovery: region " + regionInfo.getEncodedName() +
                            " running with region state " + regionState.intValue());       
      }
      else if (this.regionState.intValue() == REGION_STATE_RECOVERING) {
         for (Entry<Long, List<WALEdit>> entry : indoubtTransactionsMap.entrySet()) {
	    try {
               transactionId = entry.getKey();
               clusterid = (int) TransactionState.getClusterId(transactionId);
               tmid = (int) TransactionState.getNodeId(transactionId);
               if (LOG.isWarnEnabled()) {
                   LOG.warn("Traf Reco Thread detect stale branch tid " + transactionId + " cluster id " + clusterid
                     + " node " + tmid + " region state " + this.regionState.intValue()
                     + " region " + m_regionName  + " PSTRConfig " + pSTRConfig);
               }

               if (  (clusterid != pSTRConfig.getTrafClusterIdInt())  ) tmid = -2; // for any peer
                       
               if (!staleBranchforTMId.contains(tmid)) {staleBranchforTMId.add(tmid);}
            } catch (Exception xe1) {
               if (LOG.isWarnEnabled()) {
                   LOG.warn("An exception when chore thread detects a stale in-doubt reinstated transaction " + transactionId + " skip ... ");
	           }
	    } // catch
         } // for loop
      }
      else if (this.regionState.intValue() == REGION_STATE_START) { // region has started
         for (TrxTransactionState commitPendingTS : commitPendingCopy) {
	    try {
              if (commitPendingTS.getCPEpoch() < (controlPointEpoch.get() - 1)) {
                 transactionId = commitPendingTS.getTransactionId();
                 if (commitPendingTS.getIsRegionTx()){
                    if (LOG.isWarnEnabled()) {
                        LOG.warn("Traf Reco Thread detect stale regionTx " + commitPendingTS+ " PSTRConfig " + pSTRConfig);
                    }
//                    synchronized(commitPendingTransactions){
//                       commitPendingTransactions.remove(transactionId);
//                    }
                 }
                 else if (commitPendingTS.dropTableRecorded()) { // this is the transaction doing the DDL drop on this table
                    if (LOG.isInfoEnabled()) {
                        LOG.info("Traf Reco Thread detect stale DDL drop txn " + commitPendingTS+ " PSTRConfig " + pSTRConfig);
                    }
                 }
                 else{
                     clusterid = (int) commitPendingTS.getClusterId();
                     tmid = (int) commitPendingTS.getNodeId();
                     if (LOG.isWarnEnabled()) {
                         LOG.warn("Traf Reco Thread detect stale branch tid " + transactionId + " cluster id " + clusterid
                                 + " node " + tmid + " region state " + this.regionState.intValue()
                                 + " region " + m_regionName  + " PSTRConfig " + pSTRConfig);
                     }
                     if (  (clusterid != pSTRConfig.getTrafClusterIdInt())  ) tmid = -2; // for any peer

                     if (!staleBranchforTMId.contains(tmid)) {staleBranchforTMId.add(tmid);}
                  }
              }
	    } catch (Exception xe1) {
               if (LOG.isWarnEnabled()) {
                   LOG.warn("An exception when chore thread detects a stale in-doubt normal transaction " + transactionId + " skip ... ");
	           }
	    } // catch
         } // loop
         synchronized(longRunningTransactions) {
         for (Long leaseExpiredTxn:longRunningTransactions) {
	    long tid = leaseExpiredTxn.longValue();
	    if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor:choreThreadDetectStaleTransactionBranch: long running branch Txn id "
                       + tid + " region info bytes " + new String(lv_byte_region_info));
            clusterid = (int) TransactionState.getClusterId(tid);
            tmid = (int) TransactionState.getNodeId(tid);
            if ((currentEpoch % 20) == 1) {
                if (LOG.isWarnEnabled()) {
                    LOG.warn("Traf Reco Thread detect long running branch tid " + tid + " cluster id " + clusterid
                                 + " node " + tmid + " region " + regionInfo.getEncodedName()  + " PSTRConfig " + pSTRConfig);
                }
            }
            if ((clusterid != pSTRConfig.getTrafClusterIdInt()) && clusterid != 0) tmid = -2; // for any peer
            if (!staleBranchforTMId.contains(tmid)) {staleBranchforTMId.add(tmid);}     
	 } // loop
	 } // sync longrunng
      }
      else {
         LOG.error("TrxRegionEndpoint coprocessor:choreThreadDetectStaleTransactionBranch: detect incorrect region state " +
                       regionState.intValue());
      }
      if (!staleBranchforTMId.isEmpty()) {
            for (int i = 0; i < staleBranchforTMId.size(); i++) {
               try {
                   tm = staleBranchforTMId.get(i);
                   if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor:choreThreadDetectStaleTransactionBranch: ZKW Create Recovery zNode TM "
                            + tm + " region encoded name " + lv_encoded + " region info bytes " + new String(lv_byte_region_info));
                   createRecoveryzNode(tm, lv_encoded, lv_byte_region_info);
                   } catch (IOException exp) {
                   LOG.error("TrxRegionEndpoint coprocessor:choreThreadDetectStaleTransactionBranch: ZKW Create recovery zNode failed ", exp);
               }
            } // for
      } // if block

      controlPointEpoch.getAndIncrement();
      commitPendingCopy.clear();
      indoubtTransactionsMap.clear();
      staleBranchforTMId.clear();
      
      } //synchronized
  }
  
  // This method is to write a special HLOG edit, mostly used in Chore to write a control point style recorded
  // The assumption is to have a pre-setup cell in current session, and the tag is used to store certain transactional context for recovery
/*  public int writeHLOGEdit() {
      
               long txid = 0;
               List<Tag> tagList = new ArrayList<Tag>();               
               Tag commitTag = null;
               WALEdit e = new WALEdit();      
               Cell c = null;
#ifdef CDH5.7 APACHE1.2 CDH5.16
               MultiVersionConcurrencyControl.WriteEntry writeEntry = null;
               long mvccNum = 0;
#endif

               try {

               if (this.regionTxnOptimization > 6) { // Buffer Ph2 commit HLOG write 
                      synchronized(bufferPh2HLOGWrite) {
                            if (txnCountPh2HLOG > 0) { // if there is leftover to flush for buffered phase 2 commits
                   
                                  if (LOG.isInfoEnabled() {
                                      LOG.info("CCC1 Flush buffered txn commit Ph2 HLOG write in Chore, txn count" + txnCountPh2HLOG);
                                  }

                                  outputPh2HLOGStream = new ByteArrayOutputStream( );
                                  byte[] tid = Bytes.toBytes (txnCountPh2HLOG);
                                  byte[] logSeqId = Bytes.toBytes(0); // TBD, to put min ph1 seq number from CPL
                                  byte[] type = Bytes.toBytes(TS_GROUP_COMMIT);
                                  byte[] version = Bytes.toBytes(1);
                                  byte[] tsId = Bytes.toBytes(txnCountPh2HLOG);
                                  byte[] mutation = Bytes.toBytes(txnCountPh2HLOG);
                                  byte[] bufferTxn = bufferCommitTxnStream.toByteArray();
                                  byte[] tagBytes = concat(version, type, tid, logSeqId, tsId, mutation);
                                  
                                  outputPh2HLOGStream.write(tagBytes);     
                                  outputPh2HLOGStream.write(bufferTxn);     
                                  c = cellPh2HLOG;                            
                                  byte [] ctag = outputPh2HLOGStream.toByteArray();
                                  byte tagType = TS_TRAFODION_TXN_TAG_TYPE; // 41                                                                                                                   
                                  commitTag = new Tag(tagType, ctag);                                  
                                  
                                  // cleanup and reset
                                  txnCountPh2HLOG = 0;
                            } // if leftover, count > 0
                      } // sync    
                      if (LOG.isInfoEnabled() {
                          LOG.info("CCC Perform txn commit Ph2 HLOG flush in Chore " + commitTag);
                      }
                      if (commitTag != null) {
                            tagList.add(commitTag);                            
                            KeyValue kv = new KeyValue(c.getRowArray(), c.getRowOffset(), (int)c.getRowLength(),
                                        c.getFamilyArray(), c.getFamilyOffset(), (int)c.getFamilyLength(),
                                        c.getQualifierArray(), c.getQualifierOffset(), (int) c.getQualifierLength(),
                                        c.getTimestamp(), Type.codeToType(c.getTypeByte()), c.getValueArray(), c.getValueOffset(),
                                        c.getValueLength(), tagList);
      
                            e.add(kv);
                            try {
                            
#ifdef CDH5.7 APACHE1.2 CDH5.16 
                                   WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(),
                                             this.regionInfo.getTable(),
                                             WALKey.NO_SEQUENCE_ID,
                                             TrxEnvironmentEdgeManager.currentTime(),
                                             WALKey.EMPTY_UUIDS,
                                             HConstants.NO_NONCE,
                                             HConstants.NO_NONCE,
                                             this.t_Region.getMVCC());
                                                                   
                                   txid = this.tHLog.append(this.m_Region.getTableDesc(), this.regionInfo, wk, e, false);
                                   writeEntry = wk.getWriteEntry();
                                   mvccNum = writeEntry.getWriteNumber();
#else
                                   final WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(),
                                          this.regionInfo.getTable(),
                                          TrxEnvironmentEdgeManager.currentTime());

                                   AtomicLong lv_seqid = this.m_Region.getSequenceId();
                                          txid = this.tHLog.append(this.m_Region.getTableDesc(),
                                                this.regionInfo, 
                                                wk , 
                                                e,
                                                lv_seqid,
                                                false,
                                                null);
#endif
                        
                            }
                           catch (IOException exp1) {
                                   LOG.error("TRAF Chore Flush commit - append to HLOG : Threw an exception ", exp1);
                                   //throw exp1;
                            }
#ifdef CDH5.7 APACHE1.2 CDH5.16   
                            finally {
                                   if (writeEntry != null) {
                                          this.t_Region.getMVCC().completeAndWait(writeEntry);
                                          writeEntry = null;
                                   }        
                            } // finally
#endif      
                      } // commitTag == null      
               } // opt = 6
               
               } catch (IOException exp2) {
                                   LOG.error("TRAF Chore Flush commit - Writing to HLOG : Threw an exception ", exp2);
               }
               
      return 0;
           
  }
*/

  public void createRecoveryzNode(int node, String encodedName, byte [] data) throws IOException {

       synchronized(zkRecoveryCheckLock) {
         // default zNodePath for recovery
         String zNodeKey = lv_hostName + "," + lv_port + "," + encodedName;

         StringBuilder sb = new StringBuilder();
         sb.append("TM");
         sb.append(node);
         String str = sb.toString();
         String zNodePathTM = zNodePath + str + zRecoveryLocal;
         String zNodePathTMKey = zNodePathTM + "/" + zNodeKey;
         if (LOG.isInfoEnabled()) LOG.info("Trafodion Recovery Region Observer CP: ZKW Post region recovery znode" + node + " zNode Path " + zNodePathTMKey);
          // create zookeeper recovery zNode, call ZK ...
         try {
                if (ZKUtil.checkExists(zkw1, zNodePathTM) == -1) {
                   // create parent nodename
                   if (LOG.isTraceEnabled()) LOG.trace("Trafodion Recovery Region Observer CP: ZKW create parent zNodes " + zNodePathTM);
                   ZKUtil.createWithParents(zkw1, zNodePathTM);
                }
                ZKUtil.createAndFailSilent(zkw1, zNodePathTMKey, data);
          } catch (KeeperException e) {
             if (LOG.isWarnEnabled()) LOG.warn("Trafodion Recovery exception creating region recovery znode"
                 + node + " zNode Path " + zNodePathTMKey + " ", e);
             throw new IOException("Trafodion Recovery Region Observer CP: ZKW Unable to create recovery zNode to TM, throw IOException " + node, e);
          }
       }
  } // end of createRecoveryzNode

  public void deleteRecoveryzNode(int node, String encodedName) throws IOException {

       synchronized(zkRecoveryCheckLock) {
         // default zNodePath
         String zNodeKey = lv_hostName + "," + lv_port + "," + encodedName;

         StringBuilder sb = new StringBuilder();
         sb.append("TM");
         sb.append(node);
         String str = sb.toString();
         String zNodePathTM = zNodePath + str + zRecoveryLocal;
         String zNodePathTMKey = zNodePathTM + "/" + zNodeKey;
         if (LOG.isInfoEnabled()) LOG.info("Trafodion Recovery Region Observer CP: ZKW Delete region recovery znode" + node + " zNode Path " + zNodePathTMKey);
          // delete zookeeper recovery zNode, call ZK ...
         try {
             ZKUtil.deleteNodeFailSilent(zkw1, zNodePathTMKey);
          } catch (KeeperException e) {
            if (LOG.isWarnEnabled()) LOG.warn("Trafodion Recovery exception deleting region recovery znode"
                 + node + " zNode Path " + zNodePathTMKey + " ", e);
            throw new IOException("Trafodion Recovery Region Observer CP: ZKW Unable to delete recovery zNode to TM " + node, e);
          }
       }
  } // end of deleteRecoveryzNode

  /**
   * Starts the region after a recovery
   */
  public void startRegionAfterRecovery() throws IOException {

    try {
          if (LOG.isTraceEnabled()) LOG.trace("Trafodion Recovery:  Flushing cache in startRegionAfterRecovery " + m_regionDetails);
#ifdef HDP2.3 HDP2.4 APACHE1.1 CDH5.7 APACHE1.2 CDH5.16
          m_Region.flush(true);
#else
          m_Region.flushcache();
#endif

     } catch (IOException e) {
     LOG.error("Trafodion Recovery: Flush failed after replay edits" + m_regionDetails + ", Caught exception ", e);
     return;
     }


    //FileSystem fileSystem = m_Region.getFilesystem();
    //Path archiveTHLog = new Path (recoveryTrxPath.getParent(),"archivethlogfile.log");
    //if (fileSystem.exists(archiveTHLog)) fileSystem.delete(archiveTHLog, true);
    //if (fileSystem.exists(recoveryTrxPath))fileSystem.rename(recoveryTrxPath,archiveTHLog);
    if (indoubtTransactionsById != null)
        if (LOG.isDebugEnabled()) LOG.debug("Trafodion Recovery: region " + recoveryTrxPath + " has " + indoubtTransactionsById.size() + " in-doubt transactions and edits are archived.");
    else
        if (LOG.isDebugEnabled()) LOG.debug("Trafodion Recovery: region " + recoveryTrxPath + " has 0 in-doubt transactions and edits are archived.");
        regionState.set(REGION_STATE_START); 
    if (LOG.isInfoEnabled()) LOG.info("Trafodion Recovery: region " + m_regionDetails + " is STARTED.");
  }

  public static void WALSync(WAL wal, long transactionId, long txid) throws IOException
  {
     try {
       if (txid == 0)
          wal.sync();
       else
          wal.sync(txid);
     } catch (IOException wale) {
        wale.fillInStackTrace();
        LOG.error("commitRequest txId: " + transactionId + " HLog seq " + txid + " Caught IOException in HLOG sync ", wale );
        try {
           Thread.sleep(1000);          ///1000 milliseconds is one second.
        } catch(InterruptedException ex) {
             Thread.currentThread().interrupt();
        }
        throw wale;
     }
  }

  /**
   * Commits the transaction
   * @param TrxTransactionState state
   * @throws IOException
   */
  private void commit(final TrxTransactionState state, short totalNum, int ddlNum) throws IOException {
    long txid = 0;
    WALEdit b = null;
    int num = 0;
    Tag commitTag = null;
    Tag binlogTag = null;
    Tag isUpsertTag = null;
    ArrayList<WALEdit> editList;
    long transactionId = state.getTransactionId();
    long commitId = state.getCommitId();
    int mClient = state.getMutationClient();
    long startId = state.getStartId();
    int size = state.writeSize();
    int myBinlogSalt = 0;
    byte[] tagArray = null;
#ifdef CDH5.7  CDH5.16 APACHE1.2
    MultiVersionConcurrencyControl.WriteEntry writeEntry = null;
    long mvccNum = 0;
#endif

     if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
         printMemoryUsage("commit() - start commit txid: " + transactionId);

     boolean generateMutation = false;
     boolean ibr = false;
     boolean pit_1 = false;     
     boolean xdc_catchup = false;     
     long tmpTime = 0, preTime = 0, startTime = System.currentTimeMillis();
     long time1 =0, time2 = 0, time3 = 0, time4 = 0, time5 = 0;
     int time6 = 0, time7 = 0, time8 = 0, time9 = 0, time10 = 0;
     long time11 = 0, time12 = 0, time13 = 0, time14 = 0, time15 = 0;
     long time16 = 0, time17 = 0, time18 = 0, time19 = 0, time20 = 0;
     long time21 = 0, time22 = 0, time23 = 0, time24 = 0;

     long currBinlogWid = -1l;

     if ((commitId > 2) && (      ((mClient & INCREMENTALBR) == INCREMENTALBR)
                                                ||  ((mClient & PIT_ALL) == PIT_ALL)
                                                ||   (((mClient & SYNCHRONIZED) == SYNCHRONIZED) &&
                                                       ((mClient & XDC_DOWN) == XDC_DOWN) )           )        ) {
          generateMutation = true;
          ibr = ((mClient & INCREMENTALBR) == INCREMENTALBR);
          pit_1 =  ((mClient & PIT_ALL) == PIT_ALL);
          xdc_catchup =  (((mClient & SYNCHRONIZED) == SYNCHRONIZED)
                                           && ((mClient & XDC_DOWN) == XDC_DOWN)  );
          if ((xdc_catchup) && ((mClient & SKIP_SDN_CDC) == SKIP_SDN_CDC)  ) {
              xdc_catchup = false;
          }
          if ((!ibr) && (!pit_1) && (!xdc_catchup)) {
              generateMutation = false;
          }
          if (LOG.isDebugEnabled()) 
		      LOG.debug("Endpoint MC2 commit mutation generation: trans id " + transactionId +
                    " table name " + regionInfo.getTable().getNameAsString() +
                    " generate mutation " + generateMutation + " CDC table attribute from TM " + mClient +
                    " ibr " + ibr + " xdc catchup " + xdc_catchup +
                    " skip SDN CDC " + ((mClient & SKIP_SDN_CDC) == SKIP_SDN_CDC) +
                    " cluster wide pit " + pit_1 );
     }
                                                      

     if (LOG.isTraceEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_LOG_MARK) > 0)
        LOG.info("TrxRegionEndpoint coprocessor:commit -" 
                 + " txId " + transactionId 
                 + " commitId " + commitId
                 + " mutation client " + mClient
                 + " startId " + startId
                 + ", region " + m_regionDetails
                 + ", transactionsById " + transactionsById.size()
                 + ", commitedTransactionsBySequenceNumber " + commitedTransactionsBySequenceNumber.size()
                 + ", commitPendingTransactions " + commitPendingTransactions.size()
                 + ", tx branch size " + size + " " + state.writeSize());
     

    if (state.isReinstated() && !this.configuredConflictReinstate) {
      if (LOG.isInfoEnabled()) {
          LOG.info("TrxRegionEndpoint commit reinstated indoubt transaction with tid:" + transactionId
        + " ;with commitId: " + commitId);
      }
      if (LOG.isDebugEnabled()) LOG.debug("commit"
					  + " Trafodion Recovery: commit reinstated indoubt transaction " + transactionId 
					  + " with commitId " + commitId
					  + " mutation client " + mClient
					  + " in region " + m_regionDetails
					  );
      synchronized (indoubtTransactionsById) {  
        editList = (ArrayList<WALEdit>) indoubtTransactionsById.get(transactionId);
      }
      num  = editList.size();
      if (LOG.isDebugEnabled()) LOG.debug("TrxRegionEndpoint coprocessor: commit -" 
					   + " txId " + transactionId
					   + " commitId " + commitId
					   + " mutation client " + mClient
					   + ", region " + m_regionDetails
					   + ", Redrive commit with number of edit kvs list size " + num
					   );
      // PIT, for this in-doubt txn w/o conflict reinstatment
      if (size > 0){
      try {
      int iPut = 0;
      int iDelete = 0;
      TransactionMutationMsg.Builder tmBuilder =  TransactionMutationMsg.newBuilder();
      tmBuilder.setTxId(transactionId);
      tmBuilder.setTableName(regionInfo.getTable().getNameAsString());
      tmBuilder.setStartId(startId);
      tmBuilder.setCommitId(commitId);
      tmBuilder.setTableCDCAttr(mClient);
      tmBuilder.setTotalNum(totalNum);
      tmBuilder.setDdlNum(ddlNum);
      tmBuilder.setSplitSeq(1);

      if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
        preTime = System.currentTimeMillis();
        time1 = (preTime - startTime);
      }
      int msgCounter = 0; 
      int splitSeq = 0;
      int msgSize = 0;
      for ( int i = 0; i < num; i++){
        if (msgCounter >= 1000 || msgSize >= MutationCapture2.MAX_MSG_PER_MUTATION_MSG) {
          tmBuilder.setIsMsgComplete(false);
          splitSeq++;
          tmBuilder.setSplitSeq(splitSeq);
          mutationCapture2.MC2_doBufferAppend(transactionId, commitId, tmBuilder, iPut, iDelete, mClient, true);
          tmBuilder =  TransactionMutationMsg.newBuilder();
          tmBuilder.setTxId(transactionId);
          tmBuilder.setTableName(regionInfo.getTable().getNameAsString());
          tmBuilder.setStartId(startId); 
          tmBuilder.setCommitId(commitId);
          tmBuilder.setTableCDCAttr(mClient);
          tmBuilder.setIsMsgComplete(false);

          //reset counter and continue loop
          iPut = 0;
          iDelete = 0;
          msgCounter = 0;
          msgSize = 0;
         }
         b = editList.get(i);
         if (LOG.isTraceEnabled()) LOG.trace("commit -"
					     + " txId" + transactionId 
                                             + " commitId " + commitId
					     + ", Writing " + b.size() + " updates for reinstated transaction"
					     );
         for (Cell kv : b.getCells()) {
           if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
             preTime = System.currentTimeMillis();
           synchronized (editReplay) {
             Put put;
             Delete del;
             if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor:commit -"
						 + " txId " + transactionId + " startId " + startId
						 + ", Trafodion Recovery: region " + m_regionDetails
						 + ", Replay commit for transaction with Op " + kv.getTypeByte()
						 );
	         tagArray = Bytes.copy(kv.getTagsArray(), kv.getTagsOffset(), kv.getTagsLength());
             if (tmBuilder.getTotalNum() == -1) {
                 binlogTag = Tag.getTag(tagArray, 0, kv.getTagsLength(), TS_TRAFODION_BINLOG_TAG_TYPE);

                 if(binlogTag != null) {
                     byte[] tagBytes = binlogTag.getValue();
                     totalNum = (short)((tagBytes[0]&0xff)<<24 | (tagBytes[1]&0xff)<<16 | (tagBytes[2]&0xff)<<8 | (tagBytes[3]&0xff));
                     myBinlogSalt = ((tagBytes[4]&0xff)<<24 | (tagBytes[5]&0xff)<<16 | (tagBytes[6]&0xff)<<8 | (tagBytes[7]&0xff));
                     tmBuilder.setTotalNum(totalNum);
                 }
             }
             if (kv.getTypeByte() == KeyValue.Type.Put.getCode()) {
                if (TrxRegionEndpoint.useCommitIdInCells == false) {
                   put = new Put(CellUtil.cloneRow(kv), kv.getTimestamp()); // kv.getRow()
                   put.addColumn(CellUtil.cloneFamily(kv),
                           CellUtil.cloneQualifier(kv),
                           kv.getTimestamp(),
                           CellUtil.cloneValue(kv));
                   isUpsertTag = Tag.getTag(tagArray, 0, kv.getTagsLength(), TS_TRAFODION_ISUPSERT_TAG_TYPE);
                   if (isUpsertTag != null) {
                     put.setAttribute("ISUPSERT", isUpsertTag.getValue());
                   }
                }
                else {
                   if (LOG.isTraceEnabled()) LOG.trace("commit - creating new put with commitId " + commitId);
                   put = new Put(CellUtil.cloneRow(kv), commitId);
                   put.addColumn(CellUtil.cloneFamily(kv),
                           CellUtil.cloneQualifier(kv),
                           commitId,
                           CellUtil.cloneValue(kv));
                }
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                  tmpTime = System.currentTimeMillis();
                  time2 += (tmpTime - preTime);
                  preTime = tmpTime;
                }
                //state.addWrite(put); // no need to add since add has been done in constructInDoubtTransactions
              try {
                 if (LOG.isTraceEnabled()) LOG.trace("commit - txId "
                     + transactionId + " with commitId " + commitId
                     + ", Trafodion Recovery executing put index " + i + " durability "
                     + put.getDurability().toString() + " directly to region "
                     + m_regionDetails);
                 m_Region.put(put);
                 if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                   tmpTime = System.currentTimeMillis();
                   time3 += (tmpTime - preTime);
                   preTime = tmpTime;
                 }
              }
              catch (Exception e) {
                 if (LOG.isWarnEnabled()) {
                     LOG.warn("commit -"
                          + " txId " + transactionId + " commitId " + commitId
                          + ", Trafodion Recovery for region: " + m_regionDetails + ", Executing put caught an exception ", e);
                 }
                 state.setCommitProgress(CommitProgress.COMMIT_FAILED);
                 throw new IOException(e.toString());
              }
              // PIT + XDC
              // note if tmTableCDCAttr is true, then commitId must be > 2, otherwise  exc eption is thrown
              // the int mutation client (PIT or XDC) will be saved in edit tag, and is used by Observer
	      //if (commitId > 2 ) { // use commitId to drive mutation capture
             if (generateMutation) { // use commitId to drive mutation capture
                  tmBuilder.addPutOrDel(true);
                  if (RSConstants.DISABLE_NEWOBJECT_FOR_ENDPOINT > 0) {
                       tmBuilder.addPut(ProtobufUtil.toMutation(MutationType.PUT, put));
                       msgSize += TrxTransactionState.getCellsMemSize(put, null, m_Region.getTableDesc());
                  } else {
                       Put newPut = new Put(put);
                       tmBuilder.addPut(ProtobufUtil.toMutation(MutationType.PUT, newPut));
                       msgSize += TrxTransactionState.getCellsMemSize(newPut, null, m_Region.getTableDesc());
                  }
	          iPut++;
	      }
              if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                tmpTime = System.currentTimeMillis();
                time4 += (tmpTime - preTime);
                preTime = tmpTime;
              }
     	     } else if (CellUtil.isDelete(kv))  {
     	        if (TrxRegionEndpoint.useCommitIdInCells == false) {
                   del = new Delete(CellUtil.cloneRow(kv), kv.getTimestamp());
                   if (CellUtil.isDeleteFamily(kv)) {
                      del.addFamily(CellUtil.cloneFamily(kv), kv.getTimestamp());
                   } else if (CellUtil.isDeleteType(kv)) {
                      del.addColumn(CellUtil.cloneFamily(kv),
                		   CellUtil.cloneQualifier(kv), kv.getTimestamp());
                   }
     	        }
     	        else {
                   if (LOG.isTraceEnabled()) LOG.trace("commit - creating new delete with commitId " + commitId);
                   del = new Delete(CellUtil.cloneRow(kv), commitId);
                   if (CellUtil.isDeleteFamily(kv)) {
                      del.addFamily(CellUtil.cloneFamily(kv), commitId);
                   } else if (CellUtil.isDeleteType(kv)) {
                      del.addColumn(CellUtil.cloneFamily(kv),
                		   CellUtil.cloneQualifier(kv), commitId);
                   }
                }
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                  tmpTime = System.currentTimeMillis();
                  time5 += (tmpTime - preTime);
                  preTime = tmpTime;
                }
                //state.addDelete(del);  // no need to add since add has been done in constructInDoubtTransactions
                try {
                   m_Region.delete(del);
                   if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                     tmpTime = System.currentTimeMillis();
                     time6 += (tmpTime - preTime);
                     preTime = tmpTime;
                   }
                }
                catch (Exception e) {
                  if (LOG.isWarnEnabled()) {
                      LOG.warn("commit -"
                           + " txId " + transactionId + " commitId " + commitId
                           + ", Trafodion Recovery: " + m_regionDetails + " Executing delete caught an exception ", e);
                  }
                  state.setCommitProgress(CommitProgress.COMMIT_FAILED);
                  throw new IOException(e.toString());
                }
                // PIT
	        //if (commitId > 2) { // use commitId to drive mutation capture
                if (generateMutation) { // use commitId to drive mutation capture
                   tmBuilder.addPutOrDel(false);
				   if (RSConstants.DISABLE_NEWOBJECT_FOR_ENDPOINT > 0)
				   	  tmBuilder.addDelete(ProtobufUtil.toMutation(MutationType.DELETE, del));
					else
					  tmBuilder.addDelete(ProtobufUtil.toMutation(MutationType.DELETE, new Delete(del)));

                   if (RSConstants.DISABLE_NEWOBJECT_FOR_ENDPOINT > 0) {
                      tmBuilder.addDelete(ProtobufUtil.toMutation(MutationType.DELETE, del));
                      msgSize += TrxTransactionState.getCellsMemSize(null, del, m_Region.getTableDesc());
                   } else {
                      Delete newDelete = new Delete(del);
                      tmBuilder.addDelete(ProtobufUtil.toMutation(MutationType.DELETE, newDelete));
                      msgSize += TrxTransactionState.getCellsMemSize(null, newDelete, m_Region.getTableDesc());
                   }
	           iDelete++;
	        }
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                  tmpTime = System.currentTimeMillis();
                  time7 += (tmpTime - preTime);
                  preTime = tmpTime;
                }
             }
          } // synchronized reply edits
        } // for WALEdit
        msgCounter++;
      } // for ediList
      if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
        preTime = System.currentTimeMillis();
      }
      // PIT for non-ts reinstated txn, here we don't have a ts re-created as configuredConflictReinstate is FALSE
      //       just directly construct the mutation buffer and append (~ replayCommittedTxn in Observer)
      //if (commitId > 2) { // use commitId to drive mutation capture
      if (generateMutation) { // use commitId to drive mutation capture
             if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
                printMemoryUsage("commit() - before generateMutation MC2_doBufferAppend 2 txid: " + transactionId);
             //mutationCapture.mutationBufferOp(PIT_MUTATION_APPEND, null, tmBuilder, true, iPut, iDelete,
             //                                          5000, 15000, state.getMutationClient()); // HA
             tmBuilder.setTotalNum(totalNum);
             tmBuilder.setDdlNum(ddlNum);
             if (useMC2) {
                 if (mutationCapture2 == null) {
                           mutationCapture2 = MutationCapture2.MC2_getInstance(this.config, 
                           this.fs,
                           context,
                           regionInfo,
                           0, 1);
                 }
                 state.setTotalNum( totalNum  );
                 state.setDdlNum( ddlNum );
                 myBinlogSalt = mutationCapture2.getBinlogSaltNum();
                 if (LOG.isInfoEnabled()) {
                     LOG.info("TrxRegionEndpoint commit reinstated transaction for transactionId: " + transactionId + "; commitId: " + commitId);
                 }
                 mutationCapture2.MC2_doBufferAppend(transactionId, commitId, tmBuilder, iPut, iDelete, state.getMutationClient(), true);
             }
             else {
                 mutationCapture.mutationBufferOp(PIT_MUTATION_APPEND, null, tmBuilder, true, iPut, iDelete,
                                                       5000, 15000, state.getMutationClient()); // HA
             }
             if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
                printMemoryUsage("commit() - after generateMutation MC2_doBufferAppend 2 txid: " + transactionId);
          } // if cid > 2
      } catch(IOException e) {
         LOG.error("commit -  CDC Exception to commit recovering branch: ", e);
         state.setCommitProgress(CommitProgress.COMMIT_FAILED);
         throw new IOException("Trafodion CDC Exception Transaction Commit Recovering Branch", e); 
      }
      if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
        tmpTime = System.currentTimeMillis();
        time8 += (tmpTime - preTime);
        preTime = tmpTime;
      }
     } // size > 0
    }  // an in-doubt reinstated transaction, but no ts constructed
    else { // either non-reinstated transaction, or reinstate transaction with conflict reinstate TRUE (write from TS write ordering)

      // If useCommitIdInCells is true, we use the commitId as the timestamp, otherwise
      // we perform write operations timestamped to right now
      // maybe we can turn off WAL here for HLOG since THLOG has contained required edits in phase 1

      ListIterator<WriteAction> writeOrderIter = null;
      if (size > 0){
    try {
      int writeOrderIndex = 0;

      List<Mutation> mutations = null;

      for (writeOrderIter = state.getWriteOrderingIter();
             writeOrderIter.hasNext();) {
         if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
           preTime = System.currentTimeMillis();
         }
         WriteAction action =(WriteAction) writeOrderIter.next();
         Put put = action.getPut();
         if (null != put) {
            // Process Put
            if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
                printMemoryUsage("commit() - before non-reinstated Process Put txid: " + transactionId);              
            if (TrxRegionEndpoint.useCommitIdInCells == true) {
               //TODO: apply memory point +1
               // We are using the startId and commitId, so update the put timestamp using the commitId
               if (state.getUpdatedSameRow()){
                  if (LOG.isInfoEnabled()) LOG.info("TrxRegionEndpoint coprocessor:commit - updating put for"
                         + " txId " + transactionId
                         + " row " + Bytes.toHex(put.getRow())
                         + " using commitId " + commitId
                         + " writeOrderIndex " + writeOrderIndex
                         + ", Trafodion region: " + m_regionDetails);
               }
               else{
                  if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor:commit - updating put for"
                         + " txId " + transactionId
                         + " row " + Bytes.toHex(put.getRow())
                         + " using commitId " + commitId
                         + " writeOrderIndex " + writeOrderIndex
                         + ", Trafodion region: " + m_regionDetails);
               }
               byte[] rowkey = put.getRow();
               Put updatedPut = new Put(rowkey, commitId);

               NavigableMap<byte[], List<Cell>> familyCellMap = put.getFamilyCellMap();
               for (Entry<byte[], List<Cell>> entry : familyCellMap.entrySet()) {
                  for (Iterator<Cell> iterator = entry.getValue().iterator(); iterator.hasNext();) {
                     Cell cell = iterator.next();
                     if (cell.getTimestamp() == (startId - 1)) {
                        // startId -1 indicates this cell has been subsequently updated in the same transaction
                        // so we do NOT want to put it into the region, otherwise the update will get lost since
                        // the region will discard a second cell with the same timestamp and MVCC version
                        if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor:commit - Skipping stale Cell found in put for"
		                       + " txId " + transactionId
                               + " using commitId " + commitId
                               + " writeOrderIndex " + writeOrderIndex
                               + ", Trafodion region: " + m_regionDetails);
                        continue;
                     }
                     // This is a cell we want to add to the put, so add the cell with the correct commitID
                     byte[] family = CellUtil.cloneFamily(cell);
                     byte[] qualifier = CellUtil.cloneQualifier(cell);
                     byte[] value = CellUtil.cloneValue(cell);
                     updatedPut.addColumn(family,qualifier,commitId,value);
                  }
               }

               put = updatedPut;
               if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                 tmpTime = System.currentTimeMillis();
                 time9 += (tmpTime - preTime);
                 preTime = tmpTime;
               }
            }
            if (TrxRegionEndpoint.skipWal){
               put.setDurability(Durability.SKIP_WAL);
            }
            else {
             if (TrxRegionEndpoint.asyncWal != 0) {
                put.setDurability(Durability.ASYNC_WAL); 
                if ((writeOrderIndex == 0) && ((TrxRegionEndpoint.asyncWal == 3) || (TrxRegionEndpoint.asyncWal == 4))) {
                   put.setDurability(Durability.SYNC_WAL); 
                }
                if ((writeOrderIndex == (size - 1)) && ((TrxRegionEndpoint.asyncWal == 2)  || (TrxRegionEndpoint.asyncWal == 4))) {
                   put.setDurability(Durability.SYNC_WAL); 
                }
             }
          }
          if (LOG.isTraceEnabled()) LOG.trace("commit - txId "
					      + transactionId + " with commitId " + commitId
					      + ", Executing put writeOrderIndex " + writeOrderIndex + " durability "
					      + put.getDurability().toString() + " directly to region "
                                              + m_regionDetails
					      );
           if (commitUseBatchMutateNum > 0)
           {
               if (mutations == null)
                   mutations = new ArrayList<Mutation>();

               mutations.add(put);
           }
           else {
             try {
               m_Region.put(put);
               if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                 tmpTime = System.currentTimeMillis();
                 time10 += (tmpTime - preTime);
                 preTime = tmpTime;
               }
             }
             catch (Exception e) {
                if (LOG.isWarnEnabled()) {
                    LOG.warn("commit -" + " txId " + transactionId + " with commitId " + commitId
		         + ", Executing put to region " + m_regionDetails + " caught an exception ",e);
                }
                state.setCommitProgress(CommitProgress.COMMIT_FAILED);
                throw new IOException("commit -" + " txId " + transactionId + " with commitId " + commitId
		         + ", Executing put caught an exception " + e);
             }
           }
           if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
               printMemoryUsage("commit() - after non-reinstated Process Put txid: " + transactionId);
         }

         // Process Delete
         Delete delete = action.getDelete();
         if (delete == null && put == null) {
             LOG.error("commit -" + " txId " + transactionId + " with commitId " + commitId
                      + " both delete and put are null in WriteAction, region: " + m_regionDetails);
         }
         if (null != delete){
            if (TrxRegionEndpoint.useCommitIdInCells == true) {
               // We are using the startId and commitId, so clone the delete
               // and use the commitId as the timestamp
               if (state.getUpdatedSameRow()){
                  if (LOG.isInfoEnabled()) LOG.info("TrxRegionEndpoint coprocessor:commit - updating delete for"
                         + " txId " + transactionId
                         + " row " + Bytes.toHex(delete.getRow())
                         + " ignoreDelete " + action.getIgnoreDelete()
                         + " using commitId " + commitId
                         + " writeOrderIndex " + writeOrderIndex
                         + ", Trafodion region: " + m_regionDetails);
               }
               else{
                  if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor:commit - updating delete for"
                         + " txId " + transactionId
                         + " row " + Bytes.toHex(delete.getRow())
                         + " ignoreDelete " + action.getIgnoreDelete()
                         + " using commitId " + commitId
                         + " writeOrderIndex " + writeOrderIndex
                         + ", Trafodion region: " + m_regionDetails);
               }

               if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor:commit - cloning delete for"
						 + " txId " + transactionId
						 + " with commitId " + commitId
						 + ", Trafodion Recovery: region " + m_regionDetails);

               byte[] deleteKey = delete.getRow();
               Delete updatedDelete = new Delete(deleteKey, commitId);
               delete = updatedDelete;
//               state.unconditionalUpdateLatestTimestamp(delete.getFamilyCellMap().values(), commitId);
               if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                 tmpTime = System.currentTimeMillis();
                 time11 += (tmpTime - preTime);
                 preTime = tmpTime;
               }
            }
            if (TrxRegionEndpoint.skipWal){
               delete.setDurability(Durability.SKIP_WAL);
            }
            else {
               if (TrxRegionEndpoint.asyncWal != 0) {
                  delete.setDurability(Durability.ASYNC_WAL);
                  if ((writeOrderIndex == 0) && ((TrxRegionEndpoint.asyncWal == 3) || (TrxRegionEndpoint.asyncWal == 4))) {
                     delete.setDurability(Durability.SYNC_WAL);
                  }
                  if ((writeOrderIndex == (size - 1)) && ((TrxRegionEndpoint.asyncWal == 2)  || (TrxRegionEndpoint.asyncWal == 4))) {
                     delete.setDurability(Durability.SYNC_WAL);
                  }
               }
            }
            if (LOG.isTraceEnabled()) LOG.trace("commit - txId "
                  + transactionId + " commitId " + commitId
                  + ", Executing delete writeOrderIndex " + writeOrderIndex + " durability "
                  + delete.getDurability().toString() + " directly to region "
                  + m_regionDetails);
            if (action.getIgnoreDelete()){
               if (LOG.isWarnEnabled()) LOG.warn("TrxRegionEndpoint coprocessor:commit - found delete to ignore for"
                      + " txId " + transactionId
                      + " row " + Bytes.toHex(delete.getRow())
                      + " ignoreDelete " + action.getIgnoreDelete()
                      + " using commitId " + commitId
                      + " writeOrderIndex " + writeOrderIndex
                      + ", Trafodion region: " + m_regionDetails);
            }
            else {
               if (commitUseBatchMutateNum > 0)
               {
                   if (mutations == null)
                       mutations = new ArrayList<Mutation>();

                   mutations.add(delete);
               }
               else {
                 try {
                    m_Region.delete(delete);
                    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
  		      tmpTime = System.currentTimeMillis();
               	      time12 += (tmpTime - preTime);
               	      preTime = tmpTime;
                    }
                 } catch (Exception e) {
                    LOG.error("commit  -" + " txId " + transactionId + " with commitId " + commitId
                            + ", Executing delete caught an exception ", e);
                    state.setCommitProgress(CommitProgress.COMMIT_FAILED);
                    throw new IOException("commit -" + " txId " + transactionId + " with commitId " + commitId
                            + ", Executing delete to region: " + m_regionDetails + " caught an exception " + e.toString());
                 }
               }
            }
         }
         writeOrderIndex++;

         // batch commit based on commitUseBatchMutateNum
         if (commitUseBatchMutateNum > 0 &&
             mutations != null &&
             mutations.size() > 0 &&
             mutations.size() % commitUseBatchMutateNum == 0)
         {
             try {
                 OperationStatus[] result = m_Region.batchMutate(mutations.toArray(new Mutation[0]),
                                                                 HConstants.NO_NONCE, HConstants.NO_NONCE);
                 mutations.clear();

                 for (int i = 0; i < result.length; i++)
                 {
                     if (result[i].getOperationStatusCode() != OperationStatusCode.SUCCESS)
                         throw new IOException("commit -" + " txId " + transactionId + " with commitId " + commitId
                             + ", Executing batchMutate to region: " + m_regionDetails
                             + " exception " + result[i].getExceptionMsg());
                 }
             }
             catch (Exception e) {
                 LOG.error("commit -" + " txId " + transactionId + " with commitId " + commitId
                           + ", Executing batchMutate caught an exception ", e);
                 state.setCommitProgress(CommitProgress.COMMIT_FAILED);
                 throw new IOException("commit batchMutate -" + " txId " + transactionId + " with commitId " + commitId
                           + ", Executing batchMutate to region: " + m_regionDetails + " caught an exception " + e.toString());
             }
         }
       }

       // commit rest mutations cannot be a full batch
       if (commitUseBatchMutateNum > 0 && mutations != null && mutations.size() > 0)
       {
           try {
               OperationStatus[] result = m_Region.batchMutate(mutations.toArray(new Mutation[0]),
                                                               HConstants.NO_NONCE, HConstants.NO_NONCE);
               mutations.clear();

               for (int i = 0; i < result.length; i++)
               {
                   if (result[i].getOperationStatusCode() != OperationStatusCode.SUCCESS)
                       throw new IOException("commit -" + " txId " + transactionId + " with commitId " + commitId
                           + ", Executing batchMutate to region: " + m_regionDetails
                           + " exception " + result[i].getExceptionMsg());
               }
           }
           catch (Exception e) {
               LOG.error("commit -" + " txId " + transactionId + " with commitId " + commitId
                       + ", Executing batchMutate caught an exception ", e);
               state.setCommitProgress(CommitProgress.COMMIT_FAILED);
               throw new IOException("commit batchMutate -" + " txId " + transactionId + " with commitId " + commitId
                       + ", Executing batchMutate to region: " + m_regionDetails + " caught an exception " + e.toString());
           }
       }
       if (writeOrderIndex <= 0) {
           LOG.error("commit  -" + " txId " + transactionId + " with commitId " + commitId
                          + ", writeOrderIndex is less equal than zero, region: " + m_regionDetails);
       }

       // PIT+XDC: this transaction has committed, so that's append the committed mutations into mutation buffer
       //         this is for normal phase 2 commit and for special reinstated txn during recovery (since we reconstruct ts)
       //if (commitId > 2) { // use commitId to drive mutation capture
       if (generateMutation) { // use commitId to drive mutation capture
           // mutationCapture.txnMutationBuilder(state, 5000, 15000);
             if (useMC2) {
                 if (mutationCapture2 == null) {
                           mutationCapture2 = MutationCapture2.MC2_getInstance(this.config, 
                           this.fs,
                           context,
                           regionInfo,
                           0, 1);
                 }
                 state.setTotalNum( totalNum );
                 state.setDdlNum( ddlNum );
                 myBinlogSalt = mutationCapture2.getBinlogSaltNum();
                 if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
                    printMemoryUsage("commit() - before MC2_doMutationAppend 3 txid: " + transactionId);
                 mutationCapture2.MC2_doMutationAppend(state, regionInfo.getTable().getNameAsString());
                 if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
                    printMemoryUsage("commit() - after MC2_doMutationAppend 3 txid: " + transactionId);
                 currBinlogWid = mutationCapture2.getCurrBinlogWid() ;
                 state.setWid(currBinlogWid);
                 binlogWidMap.put(state.getTransactionId(), currBinlogWid);
             }
             else {
                 if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
                    printMemoryUsage("commit() - before txnMutationBuilder txid: " + transactionId);
                 mutationCapture.txnMutationBuilder(state, 5000, 15000);
                 if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
                    printMemoryUsage("commit() - after txnMutationBuilder txid: " + transactionId);
             }
        } // cid > 2
        if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
          tmpTime = System.currentTimeMillis();
          time13 += (tmpTime - preTime);
          preTime = tmpTime;
        }
    } catch(IOException e) {
        LOG.error("commit - CDC Exception to commit transaction branch ", e);
        state.setCommitProgress(CommitProgress.COMMIT_FAILED);
        throw new IOException("Trafodion CDC Exception Transaction Commit", e); // throw new RuntimeException(e);
    }
       } // size > 0
    } // normal transactions

   //if (state.getIsRegionTx() && ((this.regionTxnOptimization == 1) || (this.regionTxnOptimization > 2))) {
   if ((state.getIsRegionTx() && (this.regionTxnOptimization > 1)) || (this.regionTxnOptimization > 10)) {
    
         if (LOG.isInfoEnabled()) {
             LOG.info("Skip Phase 2 HLOG write: optimization level " + regionTxnOptimization + " regionTx " + state.getIsRegionTx());
         }
    }
    
    else {
        
    if (size > 0){
        
    if (state.endEditSize != 0){
       if (LOG.isInfoEnabled()) LOG.info("commit duplicate request for: " + state);
    }
    else {
       state.endEditSize = 1;
    }
         
    if (state.getEdit().getCells().size() > 0) { // inprepare time, edits are move under preparedEdit
       if (LOG.isInfoEnabled()) LOG.info("Possible late check-in after phase : " + state);   
    }

    //TODO: apply memory point +2
    if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
        printMemoryUsage("commit() - before edit to HLOG txid: " + transactionId);
    // Now write a commit edit to HLOG
    List<Tag> tagList = new ArrayList<Tag>();
    if (state.hasWrite() || state.isReinstated()) {
        
         if (LOG.isDebugEnabled()) LOG.debug("HAX - ACID write commit transId " + transactionId + " commitId " + commitId +
                " tmflags " + mClient +              
                " with put size: " + (state.writeSize()-state.deleteSize()) + " delete size: " +  state.deleteSize() +
                " region details " + m_regionDetails);
         
         if (!state.getFullEditInCommit()) {
            if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
              preTime = System.currentTimeMillis();
            }
            WALEdit e1 = state.getPreparedEdit();
            WALEdit e = new WALEdit();
            if (e1.isEmpty() || e1.getCells().size() <= 0) {
                if (LOG.isWarnEnabled()) {
                    LOG.warn("TRAF RCOV endpoint CP: commit - txId "
                        + transactionId + " regionTx: " + state.getIsRegionTx()
                        + ", Encountered empty TS WAL Edit list during commit, HLog txid "
                        + txid + " region:" + m_regionDetails);
                }
            }
            else { // need to write Ph2 HLOG
                Cell c = null;  

                 if (state.getIsRegionTx()){
                         commitTag = state.formTransactionalContextTag(TS_REGION_TX_COMMIT, commitId);
                 }
                 else {
                         commitTag = state.formTransactionalContextTag(TS_COMMIT, commitId);
                 }
                 binlogTag = state.formBinlogContextTag( myBinlogSalt , totalNum, mutationCapture2.getCurrBinlogWid());
                 if (LOG.isDebugEnabled()) {
                     LOG.debug("HBaseBinlog: antidup, commit tag , salt " + myBinlogSalt +
                          "totalNum " + totalNum +
                          "wid " + currBinlogWid +
                          "cid " + commitId);
                 }
                 c = e1.getCells().get(0);

                 if (commitTag == null) { // skip commit HLOG write due to buffering
                     if (LOG.isInfoEnabled()) {
                         LOG.info("Skip txn commit Ph2 HLOG write for tid " + transactionId + " cid " + commitId + " region: " + m_regionDetails);
                     }
                 }
                 else {
                      //LOG.info("Perform txn commit Ph2 HLOG write for tid " + transactionId + " cid " + commitId);                     
                      tagList.add(commitTag);                            
                      tagList.add(binlogTag);
                      KeyValue kv = new KeyValue(c.getRowArray(), c.getRowOffset(), (int)c.getRowLength(),
					c.getFamilyArray(), c.getFamilyOffset(), (int)c.getFamilyLength(),
					c.getQualifierArray(), c.getQualifierOffset(), (int) c.getQualifierLength(),
					c.getTimestamp(), Type.codeToType(c.getTypeByte()), c.getValueArray(), c.getValueOffset(),
					c.getValueLength(), tagList);
      
                      e.add(kv);
                      try {
                          long now;
                          if (TrxRegionEndpoint.useCommitIdInCells == false) {
                             now = TrxEnvironmentEdgeManager.currentTime();
                          }
                          else {
                             now = commitId;
                          }

                          if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                            tmpTime = System.currentTimeMillis();
                            time14 += (tmpTime - preTime);
                            preTime = tmpTime;
                          }
#ifdef CDH5.7 APACHE1.2 CDH5.16	
		             WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(),
					     this.regionInfo.getTable(),
					     WALKey.NO_SEQUENCE_ID,
					     now,
					     WALKey.EMPTY_UUIDS,
					     HConstants.NO_NONCE,
					     HConstants.NO_NONCE,
					     this.t_Region.getMVCC());

                             //LOG.info("Perform txn commit Ph2 HLOG HLOG append for tid " + transactionId + " cid " + commitId);  

                 //TODO: apply memory point +3
                 if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0) {
                    printMemoryUsage("commit() - before HLog append 1 txid: " + transactionId);
                    LOG.info("[MEM] commit() - before HLog append 1 WALEdit.size() " + e.heapSize() + " txid: " + transactionId);
                 }
			     txid = this.tHLog.append(this.m_Region.getTableDesc(), this.regionInfo, wk, e, false);
                 if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
                    printMemoryUsage("commit() - after HLog append 1 txid: " + transactionId);
			     writeEntry = wk.getWriteEntry();
			     mvccNum = writeEntry.getWriteNumber();
#else
		             final WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(),
					  this.regionInfo.getTable(),
					  now);

                          AtomicLong lv_seqid = this.m_Region.getSequenceId();
                            txid = this.tHLog.append(this.m_Region.getTableDesc(),
                                    this.regionInfo, 
                                    wk , 
                                    e,
                                    lv_seqid,
                                    false,
                                    null);
#endif

                          if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                            tmpTime = System.currentTimeMillis();
                            time15 += (tmpTime - preTime);
                            preTime = tmpTime;
                          }
                         // force commit branch state to HLOG                   
                         if (TrxRegionEndpoint.asyncWal == 2 || TrxRegionEndpoint.asyncWal == 1)
                           WALSync(tHLog, transactionId, txid);
/*
#ifdef CDH5.7 APACHE1.2 CDH5.16
                if (writeEntry != null) {
                    this.t_Region.getMVCC().completeAndWait(writeEntry);
                    writeEntry = null;
                }
#endif
*/                	
                         if (LOG.isTraceEnabled()) LOG.trace("commit -"
							+ " txId " + transactionId + " with commitId " + commitId
                                                        + " regionTx: " + state.getIsRegionTx()
							+ ", Write commit HLOG seq " + txid);
                      }
                      catch (IOException exp1) {
                         LOG.error("TRAF RCOV endpoint CP: commit -"	+ " txId " + transactionId + " with commitId " + commitId
                               + " regionTx: " + state.getIsRegionTx() + ", Writing to HLOG : Threw an exception ", exp1);
                         state.setCommitProgress(CommitProgress.COMMIT_FAILED);
                         throw exp1;
                      }
#ifdef CDH5.7 APACHE1.2 CDH5.16   
	     	      finally {
		         if (writeEntry != null) {
			     this.t_Region.getMVCC().completeAndWait(writeEntry);
		     	writeEntry = null;
		         }	  
		     } // finally
#endif      
                     if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                       tmpTime = System.currentTimeMillis();
                       time16 += (tmpTime - preTime);
                       preTime = tmpTime;
                     }
                 } // commitTag == null
            } // e1 is not empty
         } // not full edit write in commit record during phase 2
        else { //do this for  rollover case
           if (LOG.isTraceEnabled()) LOG.trace("TRAF RCOV endpoint CP:commit -- HLOG rollover txId: " 
                     + transactionId + " regionTx: " + state.getIsRegionTx());
           commitTag = state.formTransactionalContextTag(TS_CONTROL_POINT_COMMIT, commitId);
           tagList.add(commitTag);
           WALEdit e1 = state.getPreparedEdit();
           WALEdit e = new WALEdit();

           for (Cell c : e1.getCells()) {
              KeyValue kv = new KeyValue(c.getRowArray(), c.getRowOffset(), (int)c.getRowLength(),
					c.getFamilyArray(), c.getFamilyOffset(), (int)c.getFamilyLength(),
					c.getQualifierArray(), c.getQualifierOffset(), (int) c.getQualifierLength(),
					c.getTimestamp(), Type.codeToType(c.getTypeByte()), c.getValueArray(), c.getValueOffset(),
					c.getValueLength(), tagList);
              e.add(kv);
            }
            if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
              tmpTime = System.currentTimeMillis();
              time17 += (tmpTime - preTime);
              preTime = tmpTime;
            }
            try {

                long now;
                if (TrxRegionEndpoint.useCommitIdInCells == false) {
                   now = TrxEnvironmentEdgeManager.currentTime();
                }
                else {
                   now = commitId;
                }

        if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0) {
           printMemoryUsage("commit() - before HLog append 2 txid: " + transactionId);
           LOG.info("[MEM] commit() - before HLog append 2 WALEdit.size()" + e.heapSize() + " txid: " + transactionId);
        }

#ifdef CDH5.7 APACHE1.2 CDH5.16
		WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(), 
					     this.regionInfo.getTable(), 
					     WALKey.NO_SEQUENCE_ID,
					     now,
					     WALKey.EMPTY_UUIDS,
					     HConstants.NO_NONCE,
					     HConstants.NO_NONCE,
					     this.t_Region.getMVCC());	
					     
		txid = this.tHLog.append(this.m_Region.getTableDesc(), this.regionInfo, wk, e, false);
		
		writeEntry = wk.getWriteEntry();
		mvccNum = writeEntry.getWriteNumber();
#else
		final WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(),
					  this.regionInfo.getTable(),
					  now);

           	txid = this.tHLog.append(this.m_Region.getTableDesc(),
						 this.regionInfo, 
						 wk , 
						 e,
						 this.m_Region.getSequenceId(), 
						 false, 
						 null);
#endif
                if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
                    printMemoryUsage("commit() - after HLog append 2 txid: " + transactionId);
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                  tmpTime = System.currentTimeMillis();
                  time18 += (tmpTime - preTime);
                  preTime = tmpTime;
                }
                WALSync(tHLog, transactionId, txid);
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                  tmpTime = System.currentTimeMillis();
                  time19 += (tmpTime - preTime);
                  preTime = tmpTime;
                }

#ifdef CDH5.7 APACHE1.2 CDH5.16
		if (writeEntry != null) {
		    this.t_Region.getMVCC().completeAndWait(writeEntry);
		    writeEntry = null;
		}
#endif
                if (LOG.isTraceEnabled()) LOG.trace("commit -"
						    + " txId " + transactionId + " with commitId " + commitId
                                                    + " regionTx: " + state.getIsRegionTx()
						    + ", Y11 write commit HLOG seq " + txid);
            }
            catch (IOException exp1) {
               LOG.error("TRAF RCOV endpoint CP: commit -" + " txId " + transactionId + " with commitId " + commitId
                 + " regionTx: " + state.getIsRegionTx() + ", Writing to HLOG : Threw an exception ", exp1);
               state.setCommitProgress(CommitProgress.COMMIT_FAILED);
               throw exp1;
             }
#ifdef CDH5.7 APACHE1.2 CDH5.16    
	    finally {
		if (writeEntry != null) {
                   this.t_Region.getMVCC().completeAndWait(writeEntry);
                   writeEntry = null;
		}	  
	    } // finally
#endif
            if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
              tmpTime = System.currentTimeMillis();
              time20 += (tmpTime - preTime);
              preTime = tmpTime;
            }
            if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor:commit -- EXIT"
						+ " txId: " + transactionId + " with commitId " + commitId
						+ " regionTx: " + state.getIsRegionTx()
						+ " HLog seq " + txid);
           // if (TrxRegionEndpoint.fullEditInCommit) TrxRegionEndpoint.fullEditInCommit = false;
        } // else -- full edit write in commit record during phase 2
        if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
            printMemoryUsage("commit() - after edit to HLOG txid: " + transactionId);
    } // write or reinstated
    } // size > 0

    } // region txn optimization

    state.setStatus(Status.COMMITED);
    synchronized (commitPendingTransactions) {
      if (!commitPendingTransactions.remove(state)) {
         LOG.error("commit -" + " txid: " + transactionId + "with startId " + startId
             + " regionTx: " + state.getIsRegionTx() + ", Committing a non-query transaction that is not in commitPendingTransactions");
         // synchronized statements are cleared for a throw
         throw new IOException("commit failure "+ " txid: " + transactionId + "with startId " + startId
                + " regionTx: " + state.getIsRegionTx() + " is not in commitPendingTransactions");
      }
      if (drainMC2Request) {
             drainCPL.remove(state); // remove the state from drain list, when it is empty, the wait completes
             if (LOG.isDebugEnabled()) LOG.debug("PIT CDC: remain waiting-to-drain CPL size " + drainCPL.size());
      } // only when there is a pending flush-close MC (backup or restore) req waiting on draing all the prepared branches
    }

    if (LOG.isDebugEnabled()) LOG.debug("commit(tstate) -- EXIT TrxTransactionState: " + 
					state.toString());
    
    if (state.isReinstated()) {
      try {
         pSTRConfig = STRConfig.getInstance(this.config);
      } catch (Exception xe) {
         LOG.error("An ERROR occurred while getting the STR Configuration");
      }
      synchronized(indoubtTransactionsById) {
        indoubtTransactionsById.remove(state.getTransactionId());
        int clusterid = (int) state.getClusterId();
        int tmid = (int) state.getNodeId();
        
        if (  (clusterid != pSTRConfig.getTrafClusterIdInt())  ) tmid = -2; // for any peer        

        int count = 0;
        if (indoubtTransactionsCountByTmid.containsKey(tmid)) {
          count =  (int) indoubtTransactionsCountByTmid.get(tmid) - 1;
          if (count > 0) indoubtTransactionsCountByTmid.put(tmid, count);
        }
        if (count == 0) {
          indoubtTransactionsCountByTmid.remove(tmid);
            try {
              if (LOG.isTraceEnabled()) LOG.trace("commit  -" 
						  + " txId " + transactionId + " with startId " + startId
						  + ", Trafodion Recovery: delete in commit recovery zNode TM " + tmid 
						  + " region " + m_regionDetails + " for 0 in-doubt transaction");
              if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                 preTime = System.currentTimeMillis();
              }
              deleteRecoveryzNode(tmid, regionInfo.getEncodedName());
              if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                tmpTime = System.currentTimeMillis();
                time21 += (tmpTime - preTime);
                preTime = tmpTime;
              }
            } catch (IOException e) {
            LOG.error("commit -" + " txId " + transactionId + " with startId " + startId
		      + ", Trafodion Recovery: delete recovery zNode failed. Caught exception ", e);
            }
        }

        if ((indoubtTransactionsById == null) || (indoubtTransactionsById.size() == 0)) {
          if (indoubtTransactionsById == null)
            if (LOG.isTraceEnabled()) LOG.trace("commit -" 
						+ " txId " + transactionId + " with startId " + startId
						+ ", Trafodion Recovery: start region in commit with indoubtTransactionsById null");
          else
            if (LOG.isTraceEnabled()) LOG.trace("commit -" 
						+ " txId " + transactionId + " with startId " + startId
						+ ", Trafodion Recovery: start region in commit with indoubtTransactionsById size " 
						+ indoubtTransactionsById.size());
          if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
            preTime = System.currentTimeMillis();
          }
          startRegionAfterRecovery();
          if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
            tmpTime = System.currentTimeMillis();
            time22 += (tmpTime - preTime);
            preTime = tmpTime;
           }
        }
      }
    }
                      
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      preTime = System.currentTimeMillis();
    }
    state.setCommitProgress(CommitProgress.COMMITED);
    if (LockConstants.ENABLE_ROW_LEVEL_LOCK && false == skipLock()) {
        if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
           printMemoryUsage("commit() - before retireTransaction txid: " + transactionId);
        retireTransaction(state, true);
        if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
            printMemoryUsage("commit() - after retireTransaction System.gc(); txid: " + transactionId);
        removeUnNeededCommitedTransactions(state.getSequenceNumber());
    } else {
        retireTransaction(state, false);
    }
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      tmpTime = System.currentTimeMillis();
      time23 += (tmpTime - preTime);
      tmpTime -= startTime;
      if (tmpTime >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " commit(tstate) inner txID " + transactionId + " TC " + tmpTime + (time1 > 0 ? (" time1 " + time1) : " ") + (time2 > 0 ? (" time2 " + time2) : " ") + (time3 > 0 ? (" time3 " + time3) : " ")
          + (time4 > 0 ? (" time4 " + time4) : " ") + (time5 > 0 ? (" time5 " + time5) : " ") + (time6 > 0 ? (" time6 " + time6) : " ") + (time7 > 0 ? (" time7 " + time7) : " ")
          + (time8 > 0 ? (" time8 " + time8) : " ") + (time9 > 0 ? (" time9 " + time9) : " ") + (time10 > 0 ? (" time10 " + time10) : " ") + (time11 > 0 ? (" time11 " + time11) : " ")
          + (time12 > 0 ? (" time12 " + time12) : " ") + (time13 > 0 ? (" time13 " + time13) : " ") + (time14 > 0 ? (" time14 " + time14) : " ") + (time15 > 0 ? (" time15 " + time15) : " ")
          + (time16 > 0 ? (" time16 " + time16) : " ") + (time17 > 0 ? (" time17 " + time17) : " ") + (time18 > 0 ? (" time18 " + time18) : " ") + (time19 > 0 ? (" time19 " + time19) : " ")
          + (time20 > 0 ? (" time20 " + time20) : " ") + (time21 > 0 ? (" time21 " + time21) : " ") + (time22 > 0 ? (" time22 " + time22) : " "));
         }
      }
      if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
          printMemoryUsage("commit() - end commit txid: " + transactionId);
  }
  
      // concatenate several byte[]
    byte[] concat(byte[]...arrays) {
       // Determine the length of the result byte array
       int totalLength = 0;
       for (int i = 0; i < arrays.length; i++)  {
           totalLength += arrays[i].length;
       }

       // create the result array
       byte[] result = new byte[totalLength];

       // copy the source arrays into the result array
       int currentIndex = 0;
       for (int i = 0; i < arrays.length; i++)  {
           System.arraycopy(arrays[i], 0, result, currentIndex, arrays[i].length);
           currentIndex += arrays[i].length;
       }
       return result;
    }

  /**
   * Resolves the transaction from the log
   * @param TrxTransactionState transactionState
   * @throws IOException 
   */
  private void resolveTransactionFromLog(
    final TrxTransactionState transactionState) throws IOException {
    LOG.error("Global transaction log is not Implemented. (Optimisticly) assuming transaction commit!");
    commit(transactionState, (short)1, 0);
  }

  /**
   * FormatTimestamp 
   */
  private String FormatTimestamp(long lTime){
	return new SimpleDateFormat("yyyy-MM-dd HH:mm:ss.SSS").format(new Date(lTime));
  }

  /**
   * TransactionLeaseListener
   */
  private class TransactionLeaseListener implements LeaseListener {

   //private final long transactionName;
   private final long transactionId;

   TransactionLeaseListener(final long n) {
     this.transactionId = n;
   }

   public void leaseExpired() {

   TrxTransactionState s = null;
   synchronized (transactionsById) {
     s = transactionsById.get(new Long(this.transactionId));

     LOG.error("Transaction [" + this.transactionId + "] begin nearly at " + FormatTimestamp(System.currentTimeMillis() - transactionLeaseTimeout) + " running exceeds " + (transactionLeaseTimeout/1000) + "s in region [" + m_regionName + "]");
     if (s == null) {
         if (LOG.isWarnEnabled()) {
             LOG.warn("leaseExpired Unknown transaction expired " + this.transactionId);
         }
         return;
     }

     //transactionId = s.getTransactionId();    

     if (s.getIsRegionTx()) { // region transaction)
           synchronized (commitCheckLock) {
                switch (s.getStatus()) {
                    case PENDING:
                    case START_COMMIT:
                    case COMMIT_PENDING:
                         if (LOG.isInfoEnabled()) LOG.info("leaseExpired region transaction " + transactionId + " was " + s.getStatus() + ", abort");	       
                         s.setStatus(Status.ABORTED);  	     
	                 break;
                    default:
                         if (LOG.isWarnEnabled()) {
                             LOG.warn("leaseExpired  Unexpected status on expired lease for region transaction " + transactionId);
		                 }
		} // switch
	   }   // sync commitCheckLock 
	   if (s.getStatus().equals(Status.ABORTED)) retireTransaction(s, true);
           try {
               unLockRegionAll(this.transactionId);
           } catch (Exception e) {
              LOG.error("unLockRegionAll failed: " + transactionId, e);
           }
     }      
    else {
     switch (s.getStatus()) {
       case PENDING:
       case START_COMMIT:
            if (LOG.isInfoEnabled()) LOG.info("leaseExpired transaction " + transactionId + " was " + s.getStatus() + ", renew Transaction lease");
            //s.setStatus(Status.ABORTED);  
            //retireTransaction(s, true);
            String leaseKey = getTransactionalLeaseId(transactionId);
            // default MAX_COMMIT_PENDING_WAITS = 0, no lease renew at all, change lease timeout in property for lease length
            if (s.getCommitPendingWaits() >= MAX_COMMIT_PENDING_WAITS) {  // only possible for active transaction
                   if (LOG.isInfoEnabled()) LOG.info("leaseExpired  after renew " + s.getCommitPendingWaits() +
		                         " times, doom transaction " + transactionId);
                   s.setStatus(Status.DOOMED); 
                   s.clearState();
                   synchronized(longRunningTransactions) {
	                  longRunningTransactions.add(new Long(transactionId));
	               }
                   //resolveTransactionFromLog(s);
                   break;
             } // all transactions will be added into leaseExpire list for chore to run stable transcation protocol
             if (LOG.isInfoEnabled()) LOG.info("leaseExpired,  renewing lease and contacting TM for resolution through chore");
             s.incrementCommitPendingWaits();
             if (LOG.isInfoEnabled()) LOG.info("leaseExpired, adding transaction: " + transactionId + " to long running transaction list");
             synchronized(longRunningTransactions) {
                longRunningTransactions.add(new Long(transactionId));
             }
             try {
	             if (LOG.isInfoEnabled()) LOG.info("TRAF Lease Listener: renew lease for long running txn " + transactionId);
	             transactionLeases.renewLease(leaseKey);	 
	     } catch (LeaseException e) {
                        try {
			    if (LOG.isInfoEnabled()) LOG.info("TRAF Lease Listener: cancel lease after renew fails for long running txn " + transactionId);
			    transactionLeases.cancelLease(leaseKey);
			    if (LOG.isInfoEnabled()) LOG.info("TRAF Lease Listener: craete new lease after cancel for long running txn " + transactionId);
                            transactionLeases.createLease(leaseKey, transactionLeaseTimeout, new TransactionLeaseListener(transactionId));
                        } catch (LeaseStillHeldException | LeaseException e1) {
                            if (LOG.isInfoEnabled()) LOG.info("TRAF Lease Listener: fails to either recreate or renew lease for long running txn " + transactionId);
                            //throw new RuntimeException(e1);
                        }
              }
            break;
	 case COMMIT_PENDING:
             if (LOG.isInfoEnabled()) LOG.info("leaseExpired transaction " + transactionId + " was " + s.getStatus() + ", for Chore to resolve");
	     break;
         case ABORTED:
         case SHIELDED:
         case DOOMED:
             if (LOG.isWarnEnabled()) {
                 LOG.warn("leaseExpired transaction " + transactionId + " was " + s.getStatus() + ", for Chore to resolve");
             }
             s.setStatus(Status.ABORTED);
             retireTransaction(s, true);
             try {
                 unLockRegionAll(this.transactionId);
             } catch (Exception e) {
                 LOG.error("unLockRegionAll failed: " + transactionId, e);
             }
             break;
         default:
            if (LOG.isWarnEnabled()) {
                LOG.warn("leaseExpired  Unexpected status on expired lease for region transaction " + transactionId);
            }
       } // switch
       unLockAll(this.transactionId);
     } // non-reggion txn
   } // sync transactionsById
   } // end of leaseExpired
 
 } // end of  TransactionLeaseListener

  /**
   * Processes a delete using a regional transaction
   * @param long tid
   * @param Delete delete      
   * @param Boolean autoCommit      
   * @throws IOException 
   */
  public void deleteRegionTx(final long tid, final long startId, final long commitId,
                              final Delete delete, final Boolean autoCommit, final Boolean skipcc, final String query)
    throws IOException {
    long startTime = System.currentTimeMillis();
    long time1 = 0, time2 = 0, time3 = 0, time4 = 0, time5 = 0; 
    if (LOG.isTraceEnabled()) LOG.trace("deleteRegionTx  Enter, tid: " + tid
              + " startId: " + startId + " commitId: " + commitId);
       
            if (LOG.isDebugEnabled()) LOG.debug("HAX - CALL addDelete, deleteRegionTx: "
                          + Hex.encodeHexString(delete.getRow()) 
                          + " trans id: " + tid
                          + " region info: " + m_regionDetails  );      

    //checkBlockNonPhase2(tid);
    //TBD 1 -- TrxTransactionState state = this.beginTransIfNotExist(tid, startId, true, skipcc); // This is a Region TX
    //checkBlockNewTrans(transactionId);
    //TBD 2 -- this.beginTransaction(transactionId, startId, regionTx, skipcc);
    //checkBlockNonPhase2(transactionId);

    TrxTransactionState state = beginRegionTransaction(tid, startId, skipcc);

    lockRegionTx(tid, delete.getRow(), lockMapping[READCOMMITTED][DML_LOCK], query);
    state.addDelete(delete, TrxRegionEndpoint.useCommitIdInCells, false);

    if (LOG.isTraceEnabled()) LOG.trace("begin deleteRegionTx - Adding transaction: [" + tid + "] in region ["
                + m_regionDetails + "]" + " to list");

    // perform conflict checking.
    // TBD 3 -- boolean success = commitIfPossible(tid, startId, commitId, 1, 0 /* region txn does no have tmTableCDCAttr */, true, autoCommit, skipcc);
    //int status = commitRequest(transactionId, skipcc, startEpoch, participantNum);

    synchronized (commitCheckLock) {
       checkBlockNonPhase2(tid);

       if (!LockConstants.ENABLE_ROW_LEVEL_LOCK && skipcc == false && noConflictCheckForIndex == false ){
          try {
             checkConflict(state);
          } catch (IOException e) {
             state.setStatus(Status.ABORTED);
             retireTransaction(state, true);
             if (LOG.isTraceEnabled()) LOG.trace("deleteRegionTx commitRequest encountered conflict txId: "
                         + tid + "returning COMMIT_CONFLICT", e);
             throw new IOException(e);
          }
       }
       // Order is important
       state.setStatus(Status.COMMIT_PENDING);
       state.setCPEpoch(controlPointEpoch.get());
       state.setSequenceNumber(nextSequenceId.get());
       commitPendingTransactions.add(state);
       nextSequenceId.getAndIncrement();
       commitedTransactionsBySequenceNumber.put(state.getSequenceNumber(), state);
    } // exit sync block of commitCheckLock

    // OK to commit
    state.setCommitId(commitId);
    //TBD state.setMutationClient(tmTableCDCAttr); // set mutation client from TM Table Attributes (e.g. SYNC or IBR)
    // use SYNC_WAL to maintain durability for region transaxction, no need to write sync prepare, only through sync region.delete
    //this setting could be moved in client TTable
    //get delete from WOrderList 1st WAction (due to startId/timeStamp update in addDelete)
    delete.setDurability(Durability.SYNC_WAL);
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
      time1 = System.currentTimeMillis();

    try {
       RetCode retCode = null;
       try {
          //rwLock(wLock);
          retCode = lock(tid, LockMode.LOCK_RX, query);
          if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
            time2 = System.currentTimeMillis();
          m_Region.delete(delete);
       } catch (Exception e) {
          LOG.error("failed to get LOCK_RX (loc 5) " + tid + " " + m_regionName);
          unLockRegionAll(tid);
          if (LOG.isWarnEnabled()) {
              LOG.warn("deleteRegionTx commit -" + " txId " + tid + " with commitId " + commitId
                 + ", Executing delete caught an exception ",e);
          }
          throw new IOException("deleteRegionTx -" + " txId " + tid + " with commitId " + commitId
                 + ", Executing delete caught an exception " + e);
       } finally {
          //rwUnLock(wLock);
          if (retCode == RetCode.OK || retCode == RetCode.OK_WITHRETRY) {
              unLock(tid, LockMode.LOCK_RX);
          }
       }
       if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
         time3 = System.currentTimeMillis();
       // just use commitId since region transaction does not apply on XDC case, only for IBR case
       if (commitId > 2) { // use commitId to drive mutation capture, rather than configuredPITRecovery
               if (useMC2) {
                   if (mutationCapture2 == null) {
                           mutationCapture2 = MutationCapture2.MC2_getInstance(this.config, 
                           this.fs,
                           context,
                           regionInfo,
                           0, 1);
                   }
                   mutationCapture2.MC2_doMutationAppend(state, regionInfo.getTable().getNameAsString());	
               }  
               else {
                   mutationCapture.txnMutationBuilder(state, 5000, 15000);   
               }
        } // cid > 2
      if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
        time4 = System.currentTimeMillis();
    } catch(IOException e) {
        unLockRegionAll(tid);
        LOG.error("deleteRegionTx - CDC Exception to commit transaction branch ", e);
        throw new IOException("Trafodion CDC Exception deleteRegionTx Commit", e); // throw new RuntimeException(e);
    }

    state.setStatus(Status.COMMITED);

    synchronized (commitPendingTransactions) {
       if (!commitPendingTransactions.remove(state)) {
          unLockRegionAll(tid);
          LOG.error("deleteRegionTx -" + " txid: " + tid + "with startId " + startId
               + " regionTx: " + state.getIsRegionTx() + ", Committing a non-query transaction that is not in commitPendingTransactions");
          // synchronized statements are cleared for a throw
          throw new IOException("deleteRegionTx failure "+ " txid: " + tid + "with startId " + startId
               + " regionTx: " + state.getIsRegionTx() + " is not in commitPendingTransactions");
       }
      if (drainMC2Request) {
             drainCPL.remove(state); // remove the state from drain list, when it is empty, the wait completes
             if (LOG.isDebugEnabled()) LOG.debug("PIT CDC: remain waiting-to-drain CPL size " + drainCPL.size());
      } // only when there is a pending flush-close MC (backup or restore) req waiting on draing all the prepared branches       
    }

    state.setCommitProgress(CommitProgress.COMMITED);
    if (LockConstants.ENABLE_ROW_LEVEL_LOCK && false == skipLock()) {
      retireTransaction(state, true, false);
      removeUnNeededCommitedTransactions(state.getSequenceNumber());
    } else {
      retireTransaction(state, false, false);
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      time5 = System.currentTimeMillis();
      if ((time5 - startTime) >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " deleteRegionTx inner txID " + tid + " TC " + (time5 - startTime) + " time1 " + (time1 - startTime) + " time2 " + (time2 - time1) + " time3 " + (time3 - time2) + " time4 " + (time4 - time3) + " time5 " + (time5 - time4));
          }
    }
    if (LOG.isTraceEnabled()) LOG.trace("deleteRegionTx - tid " + tid + " EXIT successful.");
  }

  /**
   * Processes a transactional delete
   * @param long transactionId
   * @param Delete delete      
   * @throws IOException 
   */
  public void delete(final long transactionId, final long savepointId, final long pSavepointId, final long startId, final Delete delete, boolean implicitSavepoint, final String query, final boolean keep_del_rows)
    throws IOException {
    if (LOG.isTraceEnabled()) LOG.trace("delete -- ENTRY txId: " + transactionId + " savepointId " + savepointId);
    long time2 = 0, time3 = 0, time1 = System.currentTimeMillis();

    checkBlockNonPhase2(transactionId);

      try {
        Get g = new Get(delete.getRow());
        Result rs = this.get(transactionId, startId, /* skipScanConflict */ false, g, savepointId, pSavepointId, 0 /* readunCommitted */, LockMode.LOCK_U, implicitSavepoint, query);
        int rsc = 0;
        long lastTimestamp = 0l;
        if(rs != null ) {
          if(rs.list() != null ) {
            for (KeyValue kv : rs.list()){
              if(kv.getTimestamp() > lastTimestamp) {
                delete.setAttribute("KEEP_DEL_ROW",kv.getValue());
                delete.setAttribute("KEEP_DEL_ROW_TS", Bytes.toBytes(kv.getTimestamp()));
                lastTimestamp = kv.getTimestamp();
              }
              rsc++;
            }
          }
          else {
             if (LOG.isWarnEnabled()) {
                 LOG.warn("HBaseBinlog: cannot get delete row via a get, rs.list is null, rowkey " + Hex.encodeHexString(delete.getRow()));
             }
          }
          if(rsc > 1) {
            if(LOG.isDebugEnabled())
                LOG.debug("HBaseBinlog: therer are more than 1 cells for this delete, rowkey " + Hex.encodeHexString(delete.getRow()));
          }

        }
        else {
            if (LOG.isWarnEnabled()) {
                LOG.warn("HBaseBinlog: cannot get delete row via a get, rs is null, rowkey " + Hex.encodeHexString(delete.getRow()));
            }
        }

      }
      catch (Exception e) {
        LOG.error("HBaseBinlog: cannot keep delete row", e);
      }
    if(keep_del_rows == false) {
        if (LOG.isWarnEnabled()) {
            LOG.warn("HBaseBinlog: DELETE keep_old_row set to false for tid " + transactionId + " for region " + m_regionDetails );
        }
   }

//    if(this.checkRowBelongs)
//      checkRow(delete.getRow(), "Delete");
    TrxTransactionState state = this.beginTransIfNotExist(transactionId, startId);
    if (!state.getStatus().equals(Status.PENDING) && !state.getStatus().equals(Status.SHIELDED)) { // Active
       throw new IOException("delete late checkin for transaction " + transactionId + " in region " + m_regionDetails);
    }

    int error = INIT_SVPT_ERROR;

    // Savepoint Checkin 
    if (savepointId > 0) {
        error = state.savepointCheckin(savepointId, SavepointOp.DML_SVPT_OP);
        if (error < 0) {
             throw new IOException("Savepoint checkin error " + error + " on tid " + transactionId + " svpt " + savepointId + 
                    " op delete " + SavepointOp.DML_SVPT_OP + " in region " + m_regionDetails);
        }
    }

    try {
       if (TrxRegionEndpoint.useCommitIdInCells == true) {
       //clone the delete to change the timestamp.
       byte[] rowkey = delete.getRow();
       Delete newDelete = new Delete( rowkey,startId );
       NavigableMap<byte[], List<Cell>> familyCellMap = delete.getFamilyCellMap();
       for (Entry<byte[], List<Cell>> entry : familyCellMap.entrySet()) {
          for (Iterator<Cell> iterator = entry.getValue().iterator(); iterator.hasNext();) {
             Cell cell = iterator.next();
             byte[] family = CellUtil.cloneFamily(cell);
             byte[] qualifier = CellUtil.cloneQualifier(cell);
             newDelete.addColumns(family,qualifier,startId);
             //NOTE: HBase 1.0 this API will change ...
             //here use deleteColumns with timestamp, so it will delete all history version of this row
          }
       }
       lock(transactionId, savepointId, pSavepointId, newDelete.getRow(), lockMapping[READCOMMITTED][DML_LOCK], implicitSavepoint, query);
       
       if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
         time2 = System.currentTimeMillis();
       if (LOG.isDebugEnabled()) LOG.debug("HAX - CALL addDelete, delete 1: "
                          + Hex.encodeHexString(newDelete.getRow()) 
                          + " trans id: " + transactionId
                          + " region info: " + m_regionDetails  );  
       
       if(keep_del_rows == true) {
         newDelete.setAttribute("KEEP_DEL_ROW", delete.getAttribute("KEEP_DEL_ROW"));
         newDelete.setAttribute("KEEP_DEL_ROW", delete.getAttribute("KEEP_DEL_ROW_TS"));
       }

       state.addDelete(newDelete, TrxRegionEndpoint.useCommitIdInCells, false, savepointId, pSavepointId);
    }
    else {
       // Just add the existing delete
       lock(transactionId, savepointId, pSavepointId, delete.getRow(), lockMapping[READCOMMITTED][DML_LOCK], implicitSavepoint, query);
        
       if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
         time2 = System.currentTimeMillis(); 
       if (LOG.isDebugEnabled()) LOG.debug("HAX - CALL addDelete, delete 2: "
                          + Hex.encodeHexString(delete.getRow()) 
                          + " trans id: " + transactionId
                          + " region info: " + m_regionDetails  ); 
          
       state.addDelete(delete, TrxRegionEndpoint.useCommitIdInCells, false, savepointId, pSavepointId);
    }
    } // try
    finally {
    //Savepoint Checkout
    if ((savepointId > 0) && (error == OK_SVPT_ERROR)) {
        state.savepointCheckout(savepointId, SavepointOp.DML_SVPT_OP);
        if (LOG.isTraceEnabled()) LOG.trace("delete -- EXIT txId: " + transactionId
             + " savepointId " + savepointId);
    }
    }// finally
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      time3 = System.currentTimeMillis();
      if ((time3 - time1) >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " delete inner txID " + transactionId + " TC " + (time3 - time1) + " time1 " + (time2 - time1) + " time2 " + (time3 - time2) + " useInCell " + (TrxRegionEndpoint.useCommitIdInCells ? "true" : "false"));
          }
    }
  }


  /**
   * Processes multiple transactional deletes    
   * @param long transactionId
   * @param Delete[] deletes   
   * @throws IOException 
   */
  public synchronized void delete(final long transactionId, final long savepointId, final long pSavepointId, final long startId, Delete[] deletes, boolean implicitSavepoint, final String query)
    throws IOException {
    if (LOG.isTraceEnabled()) LOG.trace("Enter deletes[], txid: " + transactionId + " savepointId " + savepointId);
    long timeCost = System.currentTimeMillis();
    long time1 = 0, time2 = 0, time3 = 0;

    TrxTransactionState state = this.beginTransIfNotExist(transactionId, startId);
    if (!state.getStatus().equals(Status.PENDING) && !state.getStatus().equals(Status.SHIELDED)) { // Active
       throw new IOException("delete[] late checkin for transaction " + transactionId + " in region " + m_regionDetails);
    }

    int error = INIT_SVPT_ERROR;

    // Savepoint Checkin 
    if (savepointId > 0) {
        error = state.savepointCheckin(savepointId, SavepointOp.DML_SVPT_OP);
        if (error < 0) {
             throw new IOException("Savepoint checkin error " + error + " on tid " + transactionId + " svpt " + savepointId + 
                    " op delete multiple " + SavepointOp.DML_SVPT_OP + " in region " + m_regionDetails);
        }
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
      time1 = System.currentTimeMillis();
    try {
    for (Delete del : deletes) {
//      if(this.checkRowBelongs)
//        checkRow(del.getRow(), "Delete");

      if (TrxRegionEndpoint.useCommitIdInCells == true) {
         //clone the delete to change the timestamp.
         byte[] rowkey = del.getRow();
         Delete newDelete = new Delete( rowkey,startId );
         NavigableMap<byte[], List<Cell>> familyCellMap = del.getFamilyCellMap();
         for (Entry<byte[], List<Cell>> entry : familyCellMap.entrySet()) {
            for (Iterator<Cell> iterator = entry.getValue().iterator(); iterator.hasNext();) {
               Cell cell = iterator.next();
               byte[] family = CellUtil.cloneFamily(cell);
               byte[] qualifier = CellUtil.cloneQualifier(cell);
               newDelete.addColumns(family,qualifier,startId);
               //NOTE: HBase 1.0 this API will change ...
               //here use deleteColumns with timestamp, so it will delete all history version of this row
            }
         }
         long tmptime = System.currentTimeMillis();
         lock(transactionId, savepointId, pSavepointId, newDelete.getRow(), lockMapping[READCOMMITTED][DML_LOCK], implicitSavepoint, query);

         if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
           time2 += (System.currentTimeMillis() - tmptime);
         if (LOG.isDebugEnabled()) LOG.debug("HAX - CALL addDelete, deletes 3: "
                          + Hex.encodeHexString(newDelete.getRow()) 
                          + " trans id: " + transactionId
                          + " region info: " + m_regionDetails  );  
          
         state.addDelete(newDelete, TrxRegionEndpoint.useCommitIdInCells, false, savepointId, pSavepointId);
      }
      else {
         // Just add the existing delete
         long tmptime = System.currentTimeMillis();
         lock(transactionId, savepointId, pSavepointId, del.getRow(), lockMapping[READCOMMITTED][DML_LOCK], implicitSavepoint, query);

         if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
           time2 += (System.currentTimeMillis() - tmptime);

         if (LOG.isDebugEnabled()) LOG.debug("HAX - CALL addDelete, deletes 4: "
                          + Hex.encodeHexString(del.getRow()) 
                          + " trans id: " + transactionId
                          + " region info: " + m_regionDetails  );  
            
         state.addDelete(del, TrxRegionEndpoint.useCommitIdInCells, false, savepointId, pSavepointId);
      }
    }
    } // try
    finally {
    //Savepoint Checkout
    if ((savepointId > 0) && (error == OK_SVPT_ERROR)) {
        state.savepointCheckout(savepointId, SavepointOp.DML_SVPT_OP);
        if (LOG.isTraceEnabled()) LOG.trace("delete multiple -- EXIT txId: " + transactionId
             + " savepointId " + savepointId);
    }
    } // finally
    
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      timeCost = System.currentTimeMillis() - timeCost;
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " deletes inner txID " + transactionId + " TC " + timeCost + " Row_lock " + time2 + " useInCell " + (TrxRegionEndpoint.useCommitIdInCells ? "true" : "false"));
          }
    }
  }

  /**
   * Processes a checkAndDelete operation using a region transaction
   * @param long tid
   * @param byte[] row
   * @param byte[] family
   * @param byte[] qualifier
   * @param byte[] value
   * @param Delete delete 
   * @return boolean
   * @throws IOException 
   */
  public boolean checkAndDeleteRegionTx(final long tid, final long startId,
                                final long commitId,
                                final byte[] row, byte[] family,
                                final byte[] qualifier, final byte[] value,
                                final boolean skipCheck,
                                final Delete delete,
                                final boolean autoCommit, final String query) throws IOException {

    if (LOG.isTraceEnabled()) LOG.trace("Enter checkAndDeleteRegionTx, tid: "
                + tid + ", on HRegion " + this);

    boolean result = false;
    byte[] rsValue = null;
    long startTime = System.currentTimeMillis();
    long time1 = 0, time2 = 0, time3 = 0, time4 = 0, time5 = 0;

    try {

      Result rs = null;
      if (skipCheck == false){
         Get get = new Get(row);
         get.addColumn(family, qualifier);

         // This get is only to verify the rows existence or not and will never be returned to the client,
         // so we don't need to perform this transactionally and create a scan range.  The subsequent write will.
         rs = m_Region.get(get);
      }
      else{
         if (LOG.isTraceEnabled()) LOG.trace("checkAndDeleteRegionTx skipping check for tid: " + tid + ", on HRegion " + this);
      }
      if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
        time1 = System.currentTimeMillis();

      boolean valueIsNull = value == null ||
                            value.length == 0;

      if (skipCheck ||
         (rs.isEmpty() && valueIsNull)) {
         this.deleteRegionTx(tid, startId, commitId, delete, autoCommit, false /* skipcc */, query);
         result = true;
         if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
           time2 = System.currentTimeMillis();
      } else if (!rs.isEmpty() && valueIsNull) {
        rsValue = rs.getValue(family, qualifier);
        if (rsValue != null && rsValue.length == 0) {
           this.deleteRegionTx(tid, startId, commitId, delete, autoCommit, false /* skipcc */, query);
           result = true;
        }
        else
          result = false;
        if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
          time3 = System.currentTimeMillis();
      } else if ((!rs.isEmpty())
                && !valueIsNull
                && (Bytes.equals(rs.getValue(family, qualifier), value))) {
         this.deleteRegionTx(tid, startId, commitId, delete, autoCommit, false /* skipcc */, query);
         result = true;
         if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
           time4 = System.currentTimeMillis();
      } else {
        result = false;
      }
    } catch (Exception e) {
      LOG.error("checkAndDeleteRegionTx - tid " + tid + ", Caught internal exception returning false ", e);
      throw new IOException("checkAndDeleteRegionTx - " + e.toString());
    }
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
      time5 = System.currentTimeMillis();

    if (LOG.isTraceEnabled()) LOG.trace("checkAndDeleteRegionTx EXIT - returns " + result + ", tid " + tid
        + ", row " + Bytes.toStringBinary(row) + ", row in hex " + Hex.encodeHexString(row));
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      if ((time5 - startTime) >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " checkAndDeleteRegionTx inner txID " + tid + " TC " + (time5 - startTime) + " time1 " + (time1 - startTime) + (time2 > 0 ? (" time2 " + (time2 - time1)) : " ")
                     + (time3 > 0 ? (" time3 " + (time3 - time1)) : " ") + (time4 > 0 ? (" time4 " + (time4 - time1)) : " "));
          }
    }
    return result;
  }

  /**
   * Processes a transactional checkAndDelete
   * @param long transactionId
   * @param long savepointId
   * @param byte[] row
   * @param byte[] family
   * @param byte[] qualifier
   * @param byte[] value
   * @param Delete delete 
   * @return boolean
   * @throws IOException 
   */
  public boolean checkAndDelete(final long transactionId,
                                final long savepointId,
                                final long pSavepointId,
                                final long startId,
                                byte[] row, byte[] family,
                                byte[] qualifier, byte[] value, final boolean skipCheck, Delete delete, boolean implicitSavepoint, final String query)
    throws IOException {
    long time3 = 0, time2 = 0, time1 = System.currentTimeMillis();
    long time4 = 0, time5 = 0, time6 = 0, time7 = 0;

    if (LOG.isTraceEnabled()) LOG.trace("Enter checkAndDelete, txid: "
                + transactionId + " savepointId " + savepointId + " skipCheck " + skipCheck + ", on HRegion " + this);

    TrxTransactionState state = this.beginTransIfNotExist(transactionId, startId);
    if (!state.getStatus().equals(Status.PENDING) && !state.getStatus().equals(Status.SHIELDED)) { // Active
       throw new IOException("checkAndDelete late checkin for transaction " + transactionId + " in region " + m_regionDetails);
    }

    if (!state.getStatus().equals(Status.PENDING)) { // Active
       throw new IOException("checkAndDelete late checkin for transaction " + transactionId + " in region " + m_regionDetails);
    }

    boolean result = false;
    byte[] rsValue = null;

//    if(this.checkRowBelongs)
//      checkRow(row, "checkAndDelete");

    try {
      Result rs = null;
      if (skipCheck == false){
         Get get = new Get(row);
         get.addColumn(family, qualifier);
         if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
           time2 = System.currentTimeMillis();

         // this will call getScanner (and then add a state scan range)
         rs = this.get(transactionId, startId, /* skipScanConflict */ false, get, savepointId, pSavepointId, 10 /* readCommitted */, LockMode.LOCK_U, implicitSavepoint, query);
      }
      else{
         if (LOG.isTraceEnabled()) LOG.trace("checkAndDelete skipping check for txid: " + transactionId + ", on region " + m_regionDetails);
      }
      boolean valueIsNull = value == null ||
                            value.length == 0;

      if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
        time3 = System.currentTimeMillis();
      if (skipCheck ||
         (rs.isEmpty() && valueIsNull)) {
        this.delete(transactionId, savepointId, pSavepointId, startId, delete, implicitSavepoint, query, false);
        result = true;
        if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
          time4 = System.currentTimeMillis();
      } else if (!rs.isEmpty() && valueIsNull) {
        rsValue = rs.getValue(family, qualifier);
        if (rsValue != null && rsValue.length == 0) {
          this.delete(transactionId, savepointId, pSavepointId, startId, delete, implicitSavepoint, query, false);
          result = true;
        }
        else
          result = false;
        if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
          time5 = System.currentTimeMillis();
      } else if ((!rs.isEmpty())
                && !valueIsNull
                && (Bytes.equals(rs.getValue(family, qualifier), value))) {
        this.delete(transactionId, savepointId, pSavepointId, startId, delete, implicitSavepoint, query, false);
        result = true;
        if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
          time6 = System.currentTimeMillis();
      } else {
        result = false;
      }
    } catch (Exception e) {
      if (LOG.isWarnEnabled()) LOG.warn("checkAndDelete - txid " + transactionId + ", Caught internal exception ", e);
     throw new IOException("checkAndDelete - " + e.toString());
    }

    if (LOG.isTraceEnabled()) LOG.trace("checkAndDelete EXIT - returns " + result + ", transId " + transactionId + ", row " + Bytes.toStringBinary(row) + ", row in hex " + Hex.encodeHexString(row));
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      time7 = System.currentTimeMillis();

      if ( (time7 - time1) >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " checkAndDelete inner txID " + transactionId + " TC " + (time7 - time1) + " time1 " + (time2 - time1) + " time2 " + (time3 - time2) + (time4 > 0 ? (" time3 " + (time4 - time3)) : "")
               + (time5 > 0 ? (" time4 " + (time5 - time3)) : "") + (time6 > 0 ? (" time5 " + (time6 - time3)) : ""));
          }
    }

    return result;
  }

  /**
   * Processes a transactional checkAndPut
   * @param long transactionId
   * @param long startId
   * @param byte[] row
   * @param byte[] family
   * @param byte[] qualifier
   * @param byte[] value
   * @param boolean skipCheck
   * @param Put put    
   * @return boolean
   * @throws IOException 
   */
  public boolean checkAndPut(final long transactionId, final long savepointId, final long pSavepointId,
                            final long startId, byte[] row, byte[] family,
                            byte[] qualifier, byte[] value, final boolean skipCheck, Put put, boolean implicitSavepoint, final byte[] capValue, final String query, boolean keepOldRow)
    throws IOException {
    long time3 = 0, time2 = 0, time1 = System.currentTimeMillis();
    long time4 = 0, time5 = 0, time6 = 0, time7 = 0;

    if (LOG.isTraceEnabled()) LOG.trace("Enter checkAndPut, txid: "
                + transactionId + " skipCheck " + skipCheck + ", on HRegion " +  m_regionDetails);
    TrxTransactionState state = this.beginTransIfNotExist(transactionId, startId);
    if (!state.getStatus().equals(Status.PENDING) && !state.getStatus().equals(Status.SHIELDED)) { // Active
       LOG.error("checkAndPut late checkin for transaction " + transactionId + " in region " + m_regionDetails);
       throw new IOException("checkAndPut late checkin for transaction " + transactionId + " in region " + m_regionDetails);
    }
    boolean result = false;
    byte[] rsValue = null;

//    if(this.checkRowBelongs)
//      checkRow(row, "checkAndPut");

    Result rs = null;
    try {
      if (skipCheck == false){
         Get get = new Get(row);
         get.addColumn(family, qualifier);
         if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
           time2 = System.currentTimeMillis();

         // this will call getScanner (and then add a state scan range), and later put will call addWrite
         // and then addRead would also add a scan range, maybe leave it now and optimize later
         rs = this.get(transactionId, startId, /* skipScanConflict */ false, get, savepointId, pSavepointId, 10 /* readCommitted */, LockMode.LOCK_U, implicitSavepoint, query);
      }
      else{
         if (LOG.isTraceEnabled()) LOG.trace("checkAndPut skipping check for txid: " + transactionId + ", on HRegion " + this);
      }

      boolean valueIsNull = value == null ||
                            value.length == 0;
      boolean capValueIsNull = (capValue == null || capValue.length == 0);
      if (LOG.isTraceEnabled()) LOG.trace("checkAndPut " + transactionId + "capValue: " + (capValue == null ? " null" : " not null: " + capValue.length));
      if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
        time3 = System.currentTimeMillis();
      if (skipCheck ||
         (rs.isEmpty() && valueIsNull)) {
        this.put(transactionId, savepointId, pSavepointId, startId, put, false, implicitSavepoint, query, keepOldRow);
        result = true;
        if (capValueIsNull == false) {
            state.addToCheckAndPutSet(capValue);
        }
        if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
          time4 = System.currentTimeMillis();
      } else if (!rs.isEmpty() && valueIsNull) {
        rsValue = rs.getValue(family, qualifier);
        if (rsValue != null && rsValue.length == 0) {
          this.put(transactionId, savepointId, pSavepointId, startId, put, false, implicitSavepoint, query, keepOldRow);
          result = true;
          if (capValueIsNull == false) {
              state.addToCheckAndPutSet(capValue);
          }
        }
        else {
          if (LOG.isTraceEnabled()) LOG.trace("checkAndPut - txid " + transactionId + ", row " + Bytes.toStringBinary(row) + ", row in hex " + Hex.encodeHexString(row) + ", first check setting result to false in region " + m_regionDetails);
          if (capValueIsNull) {
              result = false;
          } else {
              if (state.getFromCheckAndPutSet(capValue)) {
                  result = true;
              } else {
                  result = false;
              }
          }
        }
        if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
          time5 = System.currentTimeMillis();
      } else if ((!rs.isEmpty()) && !valueIsNull   
                && (Bytes.equals(rs.getValue(family, qualifier), value))) {
         this.put(transactionId, savepointId, pSavepointId, startId, put , false, implicitSavepoint, query, keepOldRow);
         result = true;
         if (capValueIsNull == false) {
             state.addToCheckAndPutSet(capValue);
         }
        if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
           time6 = System.currentTimeMillis();
      } else {
        if (LOG.isTraceEnabled()) LOG.trace("checkAndPut - txid " + transactionId + ", row " + Bytes.toStringBinary(row) + ", row in hex " + Hex.encodeHexString(row) + ", second check setting result to false in region " + m_regionDetails);
        result = false;
      }
    } catch (Exception e) {
      if (!isLockException(e)) {
          if (LOG.isWarnEnabled()) LOG.warn("checkAndPut - txid " + transactionId + ", regionName " + m_regionName + ", Caught internal exception ", e);
      }
      throw new IOException("checkAndPut - " + e.toString());
    }

    if (LOG.isTraceEnabled()) LOG.trace("checkAndPut EXIT - returns " + result + ", transId " + transactionId + ", row " + Bytes.toStringBinary(row) + ", row in hex " + Hex.encodeHexString(row) + " in region " + m_regionDetails);
    if (result == false) {
        if (LOG.isInfoEnabled()) {
            LOG.info("checkAndPut EXIT - returns " + result + ", transId " + transactionId + ", row " + Bytes.toStringBinary(row) + ", row in hex " + Hex.encodeHexString(row) + " in region " + m_regionDetails);
        }
    }
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      time7 = System.currentTimeMillis();

      if ((time7 - time1) >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " checkAndPut inner txID " + transactionId + " TC " + (time7 - time1) + " time1 " + (time2 - time1) + " time2 " + (time3 - time2) + (time4 > 0 ? (" time3 " + (time4 - time3)) : " ")
               + (time5 > 0 ? (" time4 " + (time5 - time3)) : " ") + (time6 > 0 ? (" time5 " + (time6 - time3)) : " "));
          }
    }
    return result;
  }

  /**
   * Processes a checkAndPut using a region transaction
   * @param long tid
   * @param long startId
   * @param byte[] row
   * @param byte[] family
   * @param byte[] qualifier
   * @param byte[] value
   * @param Put put  
   * @param boolean autoCommit    
   * @return boolean
   * @throws IOException 
   */
  public boolean checkAndPutRegionTx(final long tid, final long startId, final long commitId, byte[] row, byte[] family,
                            byte[] qualifier, byte[] value, final boolean skipCheck, Put put, final boolean autoCommit, final String query)
    throws IOException {

    long time3 = 0, time2 = 0, time1 = System.currentTimeMillis();
    long time4 = 0, time5 = 0, time6 = 0;
    if (LOG.isTraceEnabled()) LOG.trace("Enter checkAndPutRegionTx, tid: "
                + tid + " autoCommit " + autoCommit + " skipCheck " + skipCheck + ", on HRegion " + this);

    boolean result = false;
    byte[] rsValue = null;

    Result rs = null;
    try {
      if (skipCheck == false){

         Get get = new Get(row);
         get.addColumn(family, qualifier);

         // This is a checkAndPut whose get result is never retirned to the client or used in a computation,
         // so this get need not create a scan range for conflicts because the subsequent write will
         rs = m_Region.get(get);
      }
      else{
         if (LOG.isTraceEnabled()) LOG.trace("checkAndPutRegionTx skipping check for tid: " + tid + ", on HRegion " + this);
      }

      if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
        time2 = System.currentTimeMillis();
      boolean valueIsNull = value == null ||
                            value.length == 0;

      if (skipCheck ||
         (rs.isEmpty() && valueIsNull)) {
         this.putRegionTx(tid, startId, commitId, put, autoCommit, false /* skipcc */, query);
         result = true;
         if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
           time3 = System.currentTimeMillis();
      } else if (!rs.isEmpty() && valueIsNull) {
        rsValue = rs.getValue(family, qualifier);
        if (rsValue != null && rsValue.length == 0) {
             this.putRegionTx(tid, startId, commitId, put, autoCommit, false /* skipcc */, query);
             result = true;
        }
        else { 
          if (LOG.isTraceEnabled()) LOG.trace("checkAndPutRegionTx - tid " + tid
           + ", row " + Bytes.toStringBinary(row) + ", row in hex " + Hex.encodeHexString(row)
           + ", first check setting result to false");
          result = false;
        }
        if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
          time4 = System.currentTimeMillis();
      } else if ((!rs.isEmpty()) && !valueIsNull   
                && (Bytes.equals(rs.getValue(family, qualifier), value))) {
             this.putRegionTx(tid, startId, commitId, put, autoCommit, false /* skipcc */, query);
             result = true;
        if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
           time5 = System.currentTimeMillis();
      } else {  
          if (LOG.isTraceEnabled()) LOG.trace("checkAndPutRegionTx - tid " + tid
           + ", row " + Bytes.toStringBinary(row) + ", row in hex " + Hex.encodeHexString(row)
           + ", second check setting result to false");
        result = false;
      }
    } catch (Exception e) { 
      LOG.error("checkAndPutRegionTx - tid " + tid + ", Caught internal exception ", e);
      throw new IOException("checkAndPutRegionTx - " + e.toString());
    }

    if (LOG.isTraceEnabled()) LOG.trace("checkAndPutRegionTx EXIT - returns "
        + result + ", tid " + tid + ", row " + Bytes.toStringBinary(row)
        + ", row in hex " + Hex.encodeHexString(row));

    if (result == false) {
        if (LOG.isInfoEnabled()) {
            LOG.info("checkAndPutRegionTx EXIT - returns " + result + ", tid " + tid + ", row " + Bytes.toStringBinary(row) + ", row in hex " + Hex.encodeHexString(row) + ", in region " + m_regionDetails);
        }
    }
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      time6 = System.currentTimeMillis();
      if (RSConstants.RECORD_TIME_COST_COPRO >=0 && (time6 - time1) >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " checkAndPutRegionTx inner txID " + tid + " TC " + (time6 - time1) + " time1 " + (time2 - time1) + (time3 > 0 ? (" time2 " + (time3 - time2)) : " ")
                + (time4 > 0 ? (" time3 " + (time4 - time2)) : " ") + (time5 > 0 ? (" time4 " + (time5 - time2)) : " "));
          }
    }
    return result;
  }

  /**
   * Obtains a transactional Result for Get          
   * @param long transactionId
   * @param long startId
   * @param Get get             
   * @return Result 
   * @throws IOException 
   */
  public Result get(final long transactionId, final long startId, final int lockMode, final Get get, final String query)
                          throws IOException {
      return get(transactionId, startId, /* skipScanConflict */ false, get, NULL_SAVEPOINT, NULL_SAVEPOINT, 10 /* readCommitted */, lockMode, false, query);
  }                              

  /**
   * Obtains a transactional Result for Get          
   * @param long transactionId
   * @param long startId
   * @param Get get             
   * @return Result 
   * @throws IOException 
   */
  public Result get(final long transactionId, final long startId, final boolean skipScanConflict,
                    final Get get, final long savepointId, final long pSavepointId,
                    final int isolationLevel, final int lockMode, boolean implicitSavepoint, final String query) throws IOException {
    if (LOG.isDebugEnabled()) LOG.debug("get --  ENTRY txId: " + transactionId
                + " savepointId " + savepointId + " skipScanConflict " + skipScanConflict
                + " get row is " + Bytes.toStringBinary(get.getRow()) + " hex: " + Hex.encodeHexString(get.getRow()));
    
    /*
    if (LOG.isTraceEnabled()) {
	Map<byte[],NavigableSet<byte[]>> lv_fm = get.getFamilyMap();
	byte [][] lv_fms = lv_fm.keySet().toArray(new byte[0][0]);
	byte[] lv_f = lv_fms[0];
	if (LOG.isTraceEnabled()) LOG.trace("family: " + new String(lv_f));
	NavigableSet<byte []> lv_set = lv_fm.get(lv_f);
	if (LOG.isTraceEnabled()) LOG.trace("lv_set size: " + lv_set.size());
    }
    */

    long time1 = System.currentTimeMillis(), time2 = 0, time3 = 0;
    checkBlockNonPhase2(transactionId);

    Scan scan = new Scan(get);
    scan.setSmall(true);
    List<Cell> results = new ArrayList<Cell>();

    RegionScanner scanner = null;

    try {
      scanner = getScanner(transactionId, startId, skipScanConflict, scan, savepointId, pSavepointId, isolationLevel, lockMode, false, implicitSavepoint, query);
      if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
        time2 = System.currentTimeMillis();
      if (scanner != null)
        scanner.next(results);       
    } catch(Exception e) {
      if (!isLockException(e)) {
           if (LOG.isWarnEnabled()) {
              LOG.warn("get - txId " + transactionId + " (loc 7) in region " + m_regionDetails + ", Caught internal exception "
                 + e.getMessage() + " " + stackTraceToString(e));
           }
      }
      throw new IOException("get - txId " + transactionId + ", Caught internal exception " + e.getMessage() + " " + stackTraceToString(e));
    }
    finally {
      if (scanner != null) {
        scanner.close();
      }
    }

    if (LOG.isTraceEnabled()) LOG.trace("get -- EXIT txId: " + transactionId + " returning " + results.size() + " cells");
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      time3 = System.currentTimeMillis();
      if ((time3 - time1) >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " get inner txID " + transactionId + " TC " + (time3 - time1) + " time1 " + (time2 - time1) + " time2 " + (time3 - time2));
          }
    }
    return Result.create(results);       
  }

  /**
   * Obtain a RegionScanner                        
   * @param long transactionId
   * @param Scan scan
   * @return RegionScanner
   * @throws IOException 
   */
  public RegionScanner getScanner(final long transactionId, final long startId, final Scan scan, final String query)
                        throws IOException {
      return getScanner(transactionId, startId, /* skipScanConflict */ false, scan, NULL_SAVEPOINT, NULL_SAVEPOINT, 10 /* readCommitted */, LockMode.LOCK_NO, false, false, null, query);  // TBD, SAV, use -1 (NULL_SAVEPOINT) for svpt on some get* w/o valid svpt arg
  }

  public RegionScanner getScanner(final long transactionId, final long startId, final Scan scan, final long savepointId, final long pSavepointId, boolean implicitSavepoint, final String query)
                        throws IOException {
      return getScanner(transactionId, startId, /* skipScanConflict */ false, scan, savepointId, pSavepointId, 10 /* readCommitted */, LockMode.LOCK_NO, false, implicitSavepoint, null, query);  // TBD, SAV, use -1 (NULL_SAVEPOINT) for svpt on some get* w/o valid svpt arg
  }

  public RegionScanner getScanner(final long transactionId, final long startId, final Scan scan, final long savepointId, final long pSavepointId, boolean implicitSavepoint, Object[] checkResult, final String query)
                        throws IOException {
      return getScanner(transactionId, startId, /* skipScanConflict */ false, scan, savepointId, pSavepointId, 10 /* readCommitted */, LockMode.LOCK_NO, false, implicitSavepoint, checkResult, query);  // TBD, SAV, use -1 (NULL_SAVEPOINT) for svpt on some get* w/o valid svpt arg
  }

  public RegionScanner getScanner(final long transactionId, final long startId, final Scan scan, final long savepointId, final long pSavepointId, boolean implicitSavepoint, Object[] checkResult, final String query, int isolationLevel, int lockMode)
                        throws IOException {
      return getScanner(transactionId, startId, /* skipScanConflict */ false, scan, savepointId, pSavepointId, isolationLevel, lockMode, false, implicitSavepoint, checkResult, query);  // TBD, SAV, use -1 (NULL_SAVEPOINT) for svpt on some get* w/o valid svpt arg
  }

  public RegionScanner getScanner(final long transactionId, final long startId, final boolean skipScanConflict, final int lockMode,
          final Scan scan, final String query) throws IOException {
      return getScanner(transactionId, startId, skipScanConflict, scan, NULL_SAVEPOINT, NULL_SAVEPOINT, 10 /* readCommitted */, lockMode, false, false, null, query);  // TBD, SAV, use -1 (NULL_SAVEPOINT) for svpt on some get* w/o valid svpt arg
  }

  public RegionScanner getScanner(final long transactionId, final long startId, final boolean skipScanConflict,
                                  final Scan scan, final long savepointId, final long pSavepointId,
                                  final int isolationLevel, final int lockMode, final boolean lockViolated, boolean implicitSavepoint, final String query) throws IOException {
      return getScanner(transactionId, startId, skipScanConflict, scan, savepointId, pSavepointId, isolationLevel, lockMode, lockViolated, implicitSavepoint, null, query);
  }

  /**
   * Obtain a RegionScanner                        
   * @param long transactionId
   * @param Scan scan     
   * @param long savepointId
   * @return RegionScanner
   * @throws IOException 
   */
  public RegionScanner getScanner(final long transactionId, final long startId, final boolean skipScanConflict,
                                  final Scan scan, final long savepointId, final long pSavepointId,
                                  final int isolationLevel, final int lockMode, final boolean lockViolated, boolean implicitSavepoint, Object[] checkResult, final String query) throws IOException {
    long time1 = System.currentTimeMillis(), time2 = 0, time3 = 0;
    long time4 = 0, time5 = 0, time6 = 0, time7 = 0, time8 = 0, time9 = 0;

    if (LOG.isDebugEnabled()) LOG.debug("RegionScanner getScanner -- ENTRY txId: " + transactionId
       + " savepointId " + savepointId + " skipScanConflict " + skipScanConflict + " with scan range startKey="
       + (Bytes.equals(scan.getStartRow(), HConstants.EMPTY_START_ROW) ? "null" : Hex.encodeHexString(scan.getStartRow()))
       + " stopRow=" + (Bytes.equals(scan.getStopRow(), HConstants.EMPTY_START_ROW) ? "null" : Hex.encodeHexString(scan.getStopRow()))
       + " in region " + m_regionDetails + " query " + query);

    TrxTransactionState state = this.beginTransIfNotExist(transactionId, startId);
    if(lockViolated==true) state.setLockProtected(false);
    if (!state.getStatus().equals(Status.PENDING) && !state.getStatus().equals(Status.SHIELDED)) { // Active
       LOG.error("getScanner late checkin for transaction " + transactionId + " current state " + state.getStatus() + " in region " + m_regionDetails);
       throw new IOException("getScanner late checkin for transaction " + transactionId + " current state " + state.getStatus() + " in region " + m_regionDetails);
    }

    state.addScan(scan, savepointId, pSavepointId, skipScanConflict);
    int isoLevel = transformIsolationLevel(isolationLevel);

    List<KeyValueScanner> scanners = new ArrayList<KeyValueScanner>(1);     

    if (LOG.isDebugEnabled()) LOG.debug("RegionScanner getScanner -- adding scan to scanners, txId: " + transactionId
         + " savepointId " + savepointId + " skipScanConflict " + skipScanConflict);
    scanners.add(state.getScanner(scan));

    Scan deleteWrapScan = wrapWithDeleteFilter(scan, state);
    if (LOG.isTraceEnabled()) LOG.trace("RegionScanner getScanner -- Calling t_Region.getScanner txId: " + transactionId );
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
      time2 = System.currentTimeMillis();

    RegionScanner gotScanner = null;
    if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
        gotScanner =  this.t_Region.getScanner(deleteWrapScan, scanners);
        if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
          time3 = System.currentTimeMillis();
    }
    else {
        Boolean updatableSelect = true;
        if (lockMode != LockMode.LOCK_U) {
            updatableSelect = false;
        }
        RetCode retCode = null;
        if (!Bytes.equals(scan.getStartRow(), HConstants.EMPTY_START_ROW) && (scan.getStartRow().equals(scan.getStopRow()))) { //only one row
            if(LOG.isDebugEnabled()) LOG.debug("RegionScanner getScanner -- lock one row isoLevel: " + isoLevel + " updatableSelect: " + updatableSelect);
            if (updatableSelect) {
                retCode = lock(transactionId, savepointId, pSavepointId, scan.getStartRow(), lockMapping[isoLevel][SEL_UPD_ROW_LOCK], implicitSavepoint, query);
            } else {
                if (isoLevel == READCOMMITTED && !LockConstants.ENABLE_LOCK_FOR_SELECT) {
                    retCode = lock(transactionId, savepointId, pSavepointId, lockMapping[isoLevel][SEL_TAB_LOCK], implicitSavepoint, query);
                } else {
                    retCode = lock(transactionId, savepointId, pSavepointId, scan.getStartRow(), lockMapping[isoLevel][SEL_ROW_LOCK], implicitSavepoint, query);
                }
            }
            if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
              time4 = System.currentTimeMillis();
            gotScanner =  this.t_Region.getScanner(deleteWrapScan, scanners);
            // for select statement in READCOMMITTED isolation, should unlock after get the data
            if (isoLevel == READCOMMITTED && !updatableSelect && !skipLock() && retCode != RetCode.OK_LOCKED) {
                unLock(transactionId, savepointId, scan.getStartRow(), lockMapping[isoLevel][SEL_ROW_LOCK]);
            }
            if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
              time5 = System.currentTimeMillis();
        }
        else if (isFullTableScan(scan)) { // table lock
            if(LOG.isDebugEnabled()) LOG.debug("RegionScanner getScanner -- lock table isoLevel: " + isoLevel + " updatableSelect: " + updatableSelect);
            int currentLockMode = LockMode.LOCK_NO;
            if (!LockConstants.ENABLE_TABLELOCK_FOR_FULL_SCAN && isoLevel == READCOMMITTED) {
                if (updatableSelect) {
                    currentLockMode = lockMapping[isoLevel][DML_META_TAB_LOCK];
                } else {
                    currentLockMode = lockMapping[isoLevel][SEL_META_TAB_LOCK];
                }
            } else {
                if (updatableSelect) {
                    currentLockMode = lockMapping[isoLevel][SEL_UPD_TAB_LOCK];
                } else {
                    currentLockMode = lockMapping[isoLevel][SEL_TAB_LOCK];
                }
            }
            retCode = lock(transactionId, savepointId, pSavepointId, currentLockMode, implicitSavepoint, query);

            if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
              time6 = System.currentTimeMillis();
            gotScanner =  this.t_Region.getScanner(deleteWrapScan, scanners);
            // for select statement in READCOMMITTED isolation, should unlock after get the data
            if (LockConstants.ENABLE_LOCK_FOR_SELECT && LockConstants.ENABLE_TABLELOCK_FOR_FULL_SCAN && isoLevel == READCOMMITTED && !updatableSelect && !skipLock()) {
                if (retCode == RetCode.OK_LOCKED) {
                    checkResult[2] = true;
                }
            }
            if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
              time7 = System.currentTimeMillis();
        }
        else {
            if (isoLevel == READCOMMITTED && !updatableSelect && !skipLock() && !LockConstants.ENABLE_LOCK_FOR_SELECT) {
                lock(transactionId, savepointId, pSavepointId, lockMapping[isoLevel][SEL_TAB_LOCK], implicitSavepoint, query);
            }
            try {
                //rwLock(rLock);
                retCode = lock(transactionId, LockMode.LOCK_RS, query);
                gotScanner =  this.t_Region.getScanner(deleteWrapScan, scanners);
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
  		  time8 = System.currentTimeMillis();
            } catch (Exception e) {
                LOG.error("failed to get LOCK_RS(loc 2) " + transactionId + " " + m_regionName);
                throw e;
            } finally {
                //rwUnLock(rLock);
                if (retCode == RetCode.OK || retCode == RetCode.OK_WITHRETRY) {
                    unLock(transactionId, LockMode.LOCK_RS);
                }
            }
        }
    }
    if (gotScanner != null)
      if (LOG.isTraceEnabled()) LOG.trace("RegionScanner getScanner -- obtained scanner was not null,  txId: " + transactionId );
    else
      if (LOG.isTraceEnabled()) LOG.trace("RegionScanner getScanner -- obtained scanner was null,  txId: " + transactionId );
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      time9 = System.currentTimeMillis();
      if ((time9 - time1) >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " RegionScanner getScanner inner txID " + transactionId + " TC " + (time9 - time1) + " time1 " + (time2 - time1) + (time3 > 0 ? (" time2 " + (time3 - time2)) : " ")
                     + (time4 > 0 ? (" time3 " + (time4 - time2)) : " ") + (time5 > 0 ? (" time4 " + (time5 - time4)) : " ") + (time6 > 0 ? (" time5 " + (time6 - time2)) : " ")
                     + (time7 > 0 ? (" time6 " + (time7 - time6)) : " " ) + (time8 > 0 ? (" time7 " + (time8 - time2)) : " " ));
          }
    }
    return gotScanner;
  }

  /**
   * Wraps the transactional scan with a delete filter
   * @param Scan scan
   * @param TrxTransactionState state
   * @return Scan 
   */
  private Scan wrapWithDeleteFilter(final Scan scan,
                                    final TrxTransactionState state) {
    if (LOG.isTraceEnabled()) LOG.trace("wrapWithDeleteFilter -- ENTRY");
    FilterBase deleteFilter = new FilterBase() {

      private boolean rowFiltered = false;

      @Override
      public void reset() {
        rowFiltered = false;
      }

      @Override
      public boolean hasFilterRow() {
        return true;
      }

      @Override
      public ReturnCode filterKeyValue(final Cell v){
    	  return ReturnCode.INCLUDE;
      }

      @Override
      public void filterRowCells(final List<Cell> kvs) {
        state.applyDeletes(kvs, scan.getTimeRange().getMin(),
                           scan.getTimeRange().getMax());
        rowFiltered = kvs.isEmpty();
      }

      public boolean filterRow() {
        return rowFiltered;
      }

    };

    if (scan.getFilter() == null) {
        scan.setFilter(deleteFilter);
      if (LOG.isTraceEnabled()) LOG.trace("no previous filter, wrapWithDeleteFilter -- EXIT");
      return scan;
    }

    FilterList wrappedFilter = new FilterList(Arrays.asList(deleteFilter,
                                             scan.getFilter()));
    scan.setFilter(wrappedFilter);
    if (LOG.isTraceEnabled()) LOG.trace("new filter array, wrapWithDeleteFilter -- EXIT");

    return scan;
  }

  public void putRegionTx(RpcController controller,
                  PutRegionTxRequest request,
      RpcCallback<PutRegionTxResponse> done) {
// The default response seems redundant
//    PutRegionTxResponse response = PutRegionTxResponse.getDefaultInstance();

    MutationProto proto = request.getPut();
    MutationType type = proto.getMutateType();
    Put put = null;
    Throwable t = null;
    MemoryUsageException mue = null;
    long tid = request.getTid();
    long commitId = request.getCommitId();
    boolean autoCommit = request.getAutoCommit();
    long startTime = System.currentTimeMillis();
    String query = Bytes.toString(request.getQueryContext().toByteArray());


    totalPutRegionTx.getAndIncrement();

    // If commitId is not set, then we didn't get a tid in the RMInterface and we get an id internally here
    if (commitId < 2) {
       tid = nextRegionTxId.getAndIncrement();
       if (LOG.isTraceEnabled()) LOG.trace("putRegionTx - getting new tid "
            + tid + ", region " + m_regionDetails);
    }
    else {
       if (LOG.isTraceEnabled()) LOG.trace("putRegionTx - using provided tid "
            + tid + ", region " + m_regionDetails);
    }

    if (memoryThrottle == true) {
       if(memoryUsageWarnOnly == true)  {
           if (LOG.isWarnEnabled()) {
               LOG.warn("TrxRegionEndpoint coprocessor: putRegionTx - performing memoryPercentage " + memoryPercentage
                    + ", warning memory usage exceeds indicated percentage");
           }
       }
       else {
          if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor: putRegionTx - performing memoryPercentage "
                             + memoryPercentage + ", generating memory usage exceeds indicated percentage exception");
          mue = new MemoryUsageException("putRegionTx memory usage exceeds " + memoryUsageThreshold
                   + " percent, tid is " + tid);
       }
    }
    else{
       try {
          checkMemeoryUsage(tid);
          put = ProtobufUtil.toPut(proto);
       } catch (Throwable e) {
         if (LOG.isWarnEnabled()) LOG.warn("putRegionTx - tid " + tid
                    + ", Caught exception ", e);
         t = e;
       }

       if ((mue == null && type == MutationType.PUT && proto.hasRow()) && (put != null)){
          // Process in local memory
          try {
             putRegionTx(tid, tid, commitId, put, autoCommit, false /* skipcc */, query);
          } catch (Throwable e) {
             if (!isLockException(e)) {
                 if (LOG.isWarnEnabled()) LOG.warn("putRegionTx - tid " + tid
                     + ", regionName " + m_regionName + ", Caught exception after  internal put - ", e);
             }
             t = e;
          }

          if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor: putRegionTx - tid "  + tid + ", region " + m_regionDetails
                   + ", type " + type + ", row " + Bytes.toStringBinary(proto.getRow().toByteArray())
                    + ", row in hex " + Hex.encodeHexString(proto.getRow().toByteArray()));
       }
       else{
          if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor: putRegionTx - tid "  + tid + ", region " + m_regionDetails
                    + "- no valid PUT type or does not contain a row");
       }
    }

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.PutRegionTxResponse.Builder putRegionTxResponseBuilder = PutRegionTxResponse.newBuilder();

    putRegionTxResponseBuilder.setHasException(false);

    if (t != null)
    {
      putRegionTxResponseBuilder.setHasException(true);
      putRegionTxResponseBuilder.setException(t.toString());
    }

    if (mue != null)
    {
      if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor: putRegionTx - performing memoryPercentage " + memoryPercentage
          + ", posting memory usage exceeds indicated percentage exception");
      putRegionTxResponseBuilder.setHasException(true);
      putRegionTxResponseBuilder.setException(mue.toString());
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      long timeCost = System.currentTimeMillis();
      putRegionTxResponseBuilder.setCoproSTime(startTime);
      putRegionTxResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[31] += timeCost;
      callCount[31]++;
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " putRegionTx CC " + callCount[31] + " ATC " + (costSum[31] / callCount[31]) + " TC " + timeCost);
          }
    }

    PutRegionTxResponse presponse = putRegionTxResponseBuilder.build();
    done.run(presponse);
  }

  /**
   * Do a transactional put using a region transaction
   *
   * @param long tid
   * @param boolean autoCommit
   * @param Put put
   * @throws IOException
   */

  public void putRegionTx(final long tid, final long startId, final long commitId, final Put put, final boolean autoCommit, boolean skipcc, final String query)
    throws IOException {
    long preTime = 0, tmpTime =0, startTime = System.currentTimeMillis();
    long time1 = 0, time2 = 0, time3 = 0, time4 = 0, time5 = 0;
    long time6 = 0, time7 = 0, time8 = 0;
    if (LOG.isTraceEnabled()) LOG.trace("putRegionTx  Enter, tid: " + tid
              + " startId: " + startId + " commitId: " + commitId);

    //checkBlockNonPhase2(tid);
    //TBD 1 -- TrxTransactionState state = this.beginTransIfNotExist(tid, startId, true, skipcc); // This is a Region TX 
    //checkBlockNewTrans(transactionId);
    //TBD 2 -- this.beginTransaction(transactionId, startId, regionTx, skipcc);
    //checkBlockNonPhase2(transactionId);
    
    TrxTransactionState state = beginRegionTransaction(tid, startId, skipcc);

    //check if it is an INSERT which cannot get anything , ISUPSERT attr is used here
    byte[] isUpsertb = put.getAttribute("ISUPSERT");
    if(isUpsertb != null ) //not an insert
    {
      try {
        Get g = new Get(put.getRow());
        Result rs = m_Region.get(g);
        int rsc = 0;
        long lastTimestamp = 0l;
        if(rs != null ) {
          if(rs.list() != null ) {
            for (KeyValue kv : rs.list()){
              rsc++;
              if(kv.getTimestamp() > lastTimestamp) {
                put.setAttribute("KEEP_DEL_ROW",kv.getValue());
                put.setAttribute("KEEP_DEL_ROW_TS", Bytes.toBytes(kv.getTimestamp()));
                lastTimestamp = kv.getTimestamp();
              }
            }
          }
          else
          {
              if (LOG.isWarnEnabled()) {
                  LOG.warn("HBaseBinlog: putRegionTx cannot get old put row via a get, rs.list is null, rowkey " + Hex.encodeHexString(put.getRow()));
              }
          }
          if(rsc > 1){
            if (LOG.isDebugEnabled())
                LOG.debug("HBaseBinlog: putRegionTx there are more than 1 kv for this put, rowkey " + Hex.encodeHexString(put.getRow()));
          }
        }
        else
        {
            if (LOG.isWarnEnabled()) {
                LOG.warn("HBaseBinlog: putRegionTx cannot get old put row via a get, rs is null, rowkey " + Hex.encodeHexString(put.getRow()));
            }
         }
      }
      catch (Exception e) {
        LOG.error("HBaseBinlog: cannot keep put row", e);
      }
     }//if INSERT

     if (LOG.isDebugEnabled()) LOG.debug("HAX - CALL addWrite, putRegionTx: "
                          + Hex.encodeHexString(put.getRow()) 
                          + " trans id: " + tid
                          + " region info: " + m_regionDetails  );       

    lockRegionTx(tid, put.getRow(), lockMapping[READCOMMITTED][DML_LOCK], query);
    //if the row is locked, no need for addWrite to do conflict checking 
    byte[] getrow = put.getRow();
    //rowInHex = Hex.encodeHexString(getrow);
    ByteArrayKey rowInHex = new ByteArrayKey(getrow);
    if(!LockConstants.ENABLE_ROW_LEVEL_LOCK && !selectForUpdateLockHashmap.containsKey(rowInHex))
      state.addWrite(put, TrxRegionEndpoint.useCommitIdInCells, false, false);
    else
    {
      if (LOG.isDebugEnabled()) LOG.debug("LOCKDBG: addWrite with conf check false for row " + rowInHex );
      state.addWrite(put, TrxRegionEndpoint.useCommitIdInCells, false, true);
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      preTime = System.currentTimeMillis();
      time1 = preTime - startTime;
    }
    if (LOG.isTraceEnabled()) LOG.trace("begin putRegionTx - Adding transaction: [" + tid + "] in region ["
                + m_regionDetails + "]" + " to list");
    
    // perform conflict checking.
    // TBD 3 -- boolean success = commitIfPossible(tid, startId, commitId, 1, 0 /* region txn does no have tmTableCDCAttr */, true, autoCommit, skipcc);
    //int status = commitRequest(transactionId, skipcc, startEpoch, participantNum);

    synchronized (commitCheckLock) {
       checkBlockNonPhase2(tid);

       if (!LockConstants.ENABLE_ROW_LEVEL_LOCK && skipcc == false && noConflictCheckForIndex == false ){
          try {
             checkConflict(state);
          } catch (IOException e) {
             state.setStatus(Status.ABORTED);
             retireTransaction(state, true);
             if (LOG.isTraceEnabled()) LOG.trace("putRegionTx commitRequest encountered conflict txId: "
                     + tid + "returning COMMIT_CONFLICT", e);
             throw new IOException(e);
          }
       }
       // Order is important
       state.setStatus(Status.COMMIT_PENDING);
       state.setCPEpoch(controlPointEpoch.get());
       state.setSequenceNumber(nextSequenceId.get());
       commitPendingTransactions.add(state);
       nextSequenceId.getAndIncrement();
       commitedTransactionsBySequenceNumber.put(state.getSequenceNumber(), state);
    } // exit sync block of commitCheckLock
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      tmpTime = System.currentTimeMillis();
      time2 = tmpTime - preTime;
      preTime = tmpTime;
    }

    // OK to commit
    state.setCommitId(commitId);
    //TBD state.setMutationClient(tmTableCDCAttr); // set mutation client from TM Table Attributes (e.g. SYNC or IBR)
    // use SYNC_WAL to maintain durability for region transaxction, no need to write sync prepare, only through sync region.put
    //thios setting could be moved in client TTable
    //get put from WOrderList 1st WAction (due to startId/timeStamp update in addWrite)
    put.setDurability(Durability.SYNC_WAL); 

    try {
       RetCode retCode = null;
       try {
           //rwLock(wLock);
           retCode = lock(tid, LockMode.LOCK_RX, query);
           if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
             tmpTime = System.currentTimeMillis();
             time3 = tmpTime - preTime;
             preTime = tmpTime;
           }
           m_Region.put(put);
           if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
             tmpTime = System.currentTimeMillis();
             time4 = tmpTime - preTime;
             preTime = tmpTime;
           }
       } catch (Exception e) {
          LOG.error("failed to get LOCK_RX (loc 6) " + tid + " " + m_regionName);
          if (LOG.isWarnEnabled()) {
              LOG.warn("putRegionTx commit -" + " txId " + tid + " with commitId " + commitId
             + ", Executing put caught an exception ",e);
          }
          throw new IOException("putRegionTx -" + " txId " + tid + " with commitId " + commitId
             + ", Executing put caught an exception " + e);
       } finally {
          //rwUnLock(wLock);
          if (retCode == RetCode.OK || retCode == RetCode.OK_WITHRETRY) {
              unLock(tid, LockMode.LOCK_RX);
          }
       }
       if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
         tmpTime = System.currentTimeMillis();
         time5 = tmpTime - preTime;
         preTime = tmpTime;
       }
       // just use commitId since region transaction does not apply on XDC case, only for IBR case       
       if (commitId > 2) { // use commitId to drive mutation capture, rather than configuredPITRecovery
           // mutationCapture.txnMutationBuilder(state, 5000, 15000);
           if (useMC2) {   
               if (mutationCapture2 == null) {
                           mutationCapture2 = MutationCapture2.MC2_getInstance(this.config, 
                           this.fs,
                           context,
                           regionInfo,
                           0, 1);
               }
               mutationCapture2.MC2_doMutationAppend(state, regionInfo.getTable().getNameAsString());
           }
           else {
               mutationCapture.txnMutationBuilder(state, 5000, 15000);
            }
         } // cid > 2
       if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
         tmpTime = System.currentTimeMillis();
         time6 = tmpTime - preTime;
         preTime = tmpTime;
       }
    } catch(IOException e) {
       unLockRegionAll(tid);
       LOG.error("putRegionTx - CDC Exception to commit transaction branch ", e);
       throw new IOException("Trafodion CDC Exception putRegionTx Commit", e); // throw new RuntimeException(e);
    }

    state.setStatus(Status.COMMITED);

    synchronized (commitPendingTransactions) {
       if (!commitPendingTransactions.remove(state)) {
          unLockRegionAll(tid);
          LOG.error("putRegionTx -" + " txid: " + tid + "with startId " + startId
                  + " regionTx: " + state.getIsRegionTx() + ", Committing a non-query transaction that is not in commitPendingTransactions");
                      // synchronized statements are cleared for a throw
          throw new IOException("putRegionTx failure "+ " txid: " + tid + "with startId " + startId
                  + " regionTx: " + state.getIsRegionTx() + " is not in commitPendingTransactions");
       }
      if (drainMC2Request) {
             drainCPL.remove(state); // remove the state from drain list, when it is empty, the wait completes
             if (LOG.isDebugEnabled()) LOG.debug("PIT CDC: remain waiting-to-drain CPL size " + drainCPL.size());
      } // only when there is a pending flush-close MC (backup or restore) req waiting on draing all the prepared branches       
    }

    state.setCommitProgress(CommitProgress.COMMITED);
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      tmpTime = System.currentTimeMillis();
      time7 = tmpTime - preTime;
      preTime = tmpTime;
    }
    if (LockConstants.ENABLE_ROW_LEVEL_LOCK && false == skipLock()) {
      retireTransaction(state, true, false);
      removeUnNeededCommitedTransactions(state.getSequenceNumber());
    } else {
      retireTransaction(state, false, false);
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      tmpTime = System.currentTimeMillis();
      time8 = tmpTime - preTime;
      preTime = tmpTime;
      if ((time8 - startTime) >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " putRegionTx inner txID " + tid + " TC " + (time8 - startTime) + " time1 " + time1 + " time2 " + time2 + " time3 " + time3 + " time4 " + time4
              + " time5 " + time5 + " time6 " + time6 + " time7 " + time7 + " time8 " + time8);
          }
    }
    if (LOG.isTraceEnabled()) LOG.trace("putRegionTx - tid " + tid + " EXIT successful.");
  }

  /**
   * Add a write to the transaction. Does not get applied until commit
   * process.
   * @param long transactionId
   * @param Put put
   * @throws IOException
   */

  public void put(final long transactionId, final long savepointId, final long pSavepointId, final long startId, final Put put, boolean lockViolated, boolean implicitSavepoint, final String query, final boolean keep_del_rows)
    throws IOException {
    long preTime = 0, tmpTime =0, startTime = System.currentTimeMillis();
    long time1 = 0, time2 = 0, time3 = 0, time4 = 0, time5 = 0;
    if (LOG.isTraceEnabled()) LOG.trace("Enter put, txid: "
                 + transactionId + " startId " + startId);

    checkBlockNonPhase2(transactionId);
      //check if it is an INSERT which cannot get anything , ISUPSERT attr is used here
      byte[] isUpsertb = put.getAttribute("ISUPSERT");
      try {
        Get g = new Get(put.getRow());
        Result rs = this.get(transactionId, startId, /* skipScanConflict */ false, g, savepointId, pSavepointId, 0 /* readunCommitted */, LockMode.LOCK_U, implicitSavepoint, query);
        int rsc = 0;
        long lastTimestamp = 0l;
        if(rs != null ) {
          if(rs.list() != null ) {
            for (KeyValue kv : rs.list()){
              rsc++;
              if(kv.getTimestamp() > lastTimestamp) {
                put.setAttribute("KEEP_DEL_ROW",kv.getValue());
                put.setAttribute("KEEP_DEL_ROW_TS", Bytes.toBytes(kv.getTimestamp()));
                lastTimestamp = kv.getTimestamp();
              }
            }
          }
          else
          {
            if(isUpsertb != null) //not an insert
            {
              if(Bytes.toInt(isUpsertb) == 0) //update 
                  if (LOG.isWarnEnabled()) {
                      LOG.warn("HBaseBinlog: cannot get old put row via a get, rs.list is null, rowkey " + Hex.encodeHexString(put.getRow()) + " tid " + transactionId + " region " + m_regionDetails);
                  }
            }
          }
          if(rsc > 1){
            if (LOG.isDebugEnabled())
                LOG.debug("HBaseBinlog: there are more than 1 kv for this put, rowkey " + Hex.encodeHexString(put.getRow()));
          }
        }
        else
        {
            if(isUpsertb != null ) //not an insert
            {
              if(Bytes.toInt(isUpsertb) == 0) //update 
                  if (LOG.isWarnEnabled()) {
                      LOG.warn("HBaseBinlog: cannot get old put row via a get, rs is null, rowkey " + Hex.encodeHexString(put.getRow())  + " tid " + transactionId + " region " + m_regionDetails);
                  }
            }
         }
      }
      catch (Exception e) {
        LOG.error("HBaseBinlog: cannot keep put row ", e);
      }

    //for 167, this is an warning
    if(keep_del_rows == false)
      if (LOG.isWarnEnabled()) {
          LOG.warn("HBaseBinlog: keep_old_row set to false for tid " + transactionId + " for region " + m_regionDetails );
      }
//    if(this.checkRowBelongs)
//      checkRow(put.getRow(),"Put");
    TrxTransactionState state = this.beginTransIfNotExist(transactionId, startId);
    if (!state.getStatus().equals(Status.PENDING) && !state.getStatus().equals(Status.SHIELDED)) { // Active
       throw new IOException("put late checkin for transaction " + transactionId + " in region " + m_regionDetails);
    }

    if(lockViolated == true) state.setLockProtected(false);

    int error = INIT_SVPT_ERROR;

    // Savepoint Checkin  
    if (savepointId > 0) {
        error = state.savepointCheckin(savepointId, SavepointOp.DML_SVPT_OP);
        if (error < 0) {
             throw new IOException("Savepoint checkin error " + error + " on tid " + transactionId + " svpt " + savepointId + 
                        " op put " + SavepointOp.DML_SVPT_OP + " in region " + m_regionDetails);
        }
    }
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      preTime = System.currentTimeMillis();
      time1 = preTime - startTime;
    }
    
    try {
    // If the useCommitIdInCells is true, then we want to use the startId as the timestamp for the put.
    // Later, this timestamp will be replaced by the commitId.  So we need to make a copy of the put 
    // before adding it to the write ordering list.  Try to use getFamilyCellMap to get out all data 
    // from the put object and generate a new one
    if (TrxRegionEndpoint.useCommitIdInCells == true) {
       byte[] rowkey = put.getRow(); 
       for (WriteAction wa : state.getWriteOrdering()) {
          if(wa.getPut() != null) {
             Put waPut = wa.getPut();
             byte[] waRowKey = waPut.getRow(); 
             if (Arrays.equals(rowkey, waRowKey)) {
                if (LOG.isTraceEnabled()) LOG.trace("put, found an update for the same row in txid: "
                 + transactionId + " rowkey " + rowkey + " in region: " + m_regionDetails);

                NavigableMap<byte[], List<Cell>> putFamilyCellMap = put.getFamilyCellMap();
                NavigableMap<byte[], List<Cell>> waFamilyCellMap = waPut.getFamilyCellMap();
                for (Entry<byte[], List<Cell>> putEntry : putFamilyCellMap.entrySet()) {
                   for (Iterator<Cell> putIterator = putEntry.getValue().iterator(); putIterator.hasNext();) {
                      Cell cell = putIterator.next();
                      byte[] family = CellUtil.cloneFamily(cell);
                      byte[] qualifier = CellUtil.cloneQualifier(cell);

                      // Now look for this Cell in the wa put and if we find it we overwrite the wa put 
                      for (Entry<byte[], List<Cell>> waEntry : waFamilyCellMap.entrySet()) {
                         for (Iterator<Cell> waIterator = waEntry.getValue().iterator(); waIterator.hasNext();) {
                            Cell waCell = waIterator.next();
                            byte[] waFamily = CellUtil.cloneFamily(waCell);
                            byte[] waQualifier = CellUtil.cloneQualifier(waCell);
                            if (Arrays.equals(family, waFamily) && Arrays.equals(qualifier, waQualifier)) {
                               if (LOG.isTraceEnabled()) LOG.trace("put, "
                                    + " found the same family and qualifier in txid: "
                                    + transactionId + " qualifier " + qualifier + " in region: " + m_regionDetails);
                               CellUtil.setTimestamp(waCell, (startId-1));
                               if (LOG.isTraceEnabled()) LOG.trace("put, attempting to set cell timestamp to: " + (startId-1)
                                          + " actual timestamp: " + waCell.getTimestamp());

                               // A matching cell was found so we can stop the search
                               break;
                            }
                         }
                      }
                   } 
                }
             }
          }
       }

       if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
         tmpTime = System.currentTimeMillis();
         time2 = tmpTime - preTime;
         preTime = tmpTime;
       }
       Put newPut = new Put(rowkey, startId);
       NavigableMap<byte[], List<Cell>> familyCellMap = put.getFamilyCellMap();
       for (Entry<byte[], List<Cell>> entry : familyCellMap.entrySet()) {
          for (Iterator<Cell> iterator = entry.getValue().iterator(); iterator.hasNext();) {
             Cell cell = iterator.next();
             byte[] family = CellUtil.cloneFamily(cell);
             byte[] qualifier = CellUtil.cloneQualifier(cell);
             byte[] value = CellUtil.cloneValue(cell);
             newPut.addColumn(family,qualifier,startId,value);  
          }
       }
       if(keep_del_rows == true) {
         newPut.setAttribute("KEEP_DEL_ROW", put.getAttribute("KEEP_DEL_ROW"));
         newPut.setAttribute("KEEP_DEL_ROW_TS", put.getAttribute("KEEP_DEL_ROW_TS"));
       }
       byte[] getrow = newPut.getRow();
       lock(transactionId, savepointId, pSavepointId, getrow, lockMapping[READCOMMITTED][DML_LOCK], implicitSavepoint, query);
       //if the row is locked, no need for the addWrite to do the conflict checking
       ByteArrayKey rowInHex = new ByteArrayKey(getrow);
       if(!LockConstants.ENABLE_ROW_LEVEL_LOCK && !selectForUpdateLockHashmap.containsKey(rowInHex)) {
         if (LOG.isDebugEnabled()) LOG.debug("HAX - CALL addWrite, put 1: "
                          + Hex.encodeHexString(put.getRow()) 
                          + " trans id: " + transactionId
                          + " region info: " + m_regionDetails  );       
           
         state.addWrite(newPut, TrxRegionEndpoint.useCommitIdInCells, false, savepointId, pSavepointId, false);
         state.addInsRowsForUpdate(getrow);
       }
       else
       {
         if (!LockConstants.ENABLE_ROW_LEVEL_LOCK) {
           if (LOG.isDebugEnabled()) LOG.debug("LOCKDBG: addWrite with conf check false for row " + rowInHex );
           //check if lock by me? if not add into insrowsforupdate
           long tid = selectForUpdateLockHashmap.get(rowInHex);
           if(tid != transactionId)
             state.addInsRowsForUpdate(getrow);
         }
         state.addWrite(newPut, TrxRegionEndpoint.useCommitIdInCells, false, savepointId, pSavepointId, true);
       }
       if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
         tmpTime = System.currentTimeMillis();
         time3 = tmpTime - preTime;
         preTime = tmpTime;
       }
    }
    else {
       // Just add the existing put
       byte[] putRow = put.getRow();
       if (LOG.isTraceEnabled()) LOG.trace("put, txid: "
                 + transactionId + " startId " + startId + " adding put to writeOrdering" +
                  ", putRow = " + Bytes.toStringBinary(putRow) + ", row in hex " + Hex.encodeHexString(putRow));

       if (LOG.isDebugEnabled()) LOG.debug("HAX - CALL addWrite, put 2: "
                          + Hex.encodeHexString(put.getRow()) 
                          + " trans id: " + transactionId
                          + " region info: " + m_regionDetails  );    
                 
       lock(transactionId, savepointId, pSavepointId, putRow, lockMapping[READCOMMITTED][DML_LOCK], implicitSavepoint, query);
       if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
         tmpTime = System.currentTimeMillis();
         time4 = tmpTime - preTime;
         preTime = tmpTime;
       }
       //if the row is locked, no need for addWrite to do conflict checking
       ByteArrayKey rowInHex = new ByteArrayKey(putRow);
       if(!LockConstants.ENABLE_ROW_LEVEL_LOCK && !selectForUpdateLockHashmap.containsKey(rowInHex))
       {
         state.addWrite(put, TrxRegionEndpoint.useCommitIdInCells, false, savepointId, pSavepointId, false);
         state.addInsRowsForUpdate(put.getRow());
       }
       else
       {
         if (!LockConstants.ENABLE_ROW_LEVEL_LOCK) {
           if (LOG.isDebugEnabled()) LOG.debug("LOCKDBG: addWrite with conf check false for row " + rowInHex );
           //check if lock by me? if not add into insrowsforupdate
           long tid = selectForUpdateLockHashmap.get(rowInHex);
           if(tid != transactionId)
             state.addInsRowsForUpdate(put.getRow());
         }
         state.addWrite(put, TrxRegionEndpoint.useCommitIdInCells, false, savepointId, pSavepointId, true);
       }
       if(enableTmpWriterLock) {
          state.addTmpWLock(rowInHex);
       }
       if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
         tmpTime = System.currentTimeMillis();
         time5 = tmpTime - preTime;
         preTime = tmpTime;
       }
     }
   } // try
   finally {
   //Savepoint Checkout
   if ((savepointId > 0) && (error == OK_SVPT_ERROR)) {
       state.savepointCheckout(savepointId, SavepointOp.DML_SVPT_OP);
       if (LOG.isTraceEnabled()) LOG.trace("put -- EXIT txId: " + transactionId
             + " savepointId " + savepointId);
   } 
   } // finally
   if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
     tmpTime = System.currentTimeMillis();
     if ((tmpTime - startTime) >= RSConstants.RECORD_TIME_COST_COPRO)
         if (LOG.isWarnEnabled()) {
             LOG.warn(m_regionName + " put inner txID " + transactionId + " TC " + (tmpTime - startTime) + " time1 " + time1 + " time2 " + time2 + " time3 " + time3 + " time4 " + time4 + " time5 " + time5);
         }
   }
  }

  public void constructIndoubtTransactions() {
      
#ifdef CDH5.7 APACHE1.2 CDH5.16 
    MultiVersionConcurrencyControl.WriteEntry writeEntry = null;
    long mvccNum = 0;
#endif

      synchronized (recoveryCheckLock) {
            if ((indoubtTransactionsById == null) || (indoubtTransactionsById.size() == 0)) {
              if (LOG.isInfoEnabled()) LOG.info("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                                    " has no in-doubt transaction, set region state REGION_STATE_START ");
              if(regionState.intValue() != REGION_STATE_START) // M-18522, this region is not start yet, then do a start, other wise ,no need to redo the start
              {
                regionState.set(REGION_STATE_START); // region is started for transactional access
                try {
                  startRegionAfterRecovery();
                } catch (IOException exp1) {
                    if (LOG.isErrorEnabled()) LOG.error("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                                      " flush error during region start ", exp1);
                }
              } 
              reconstructIndoubts = 1; 
              return;
            }

	    if ((m_isTrafodionMetadata) || 
            (LOG.isTraceEnabled()) ||
            (m_detailedLogging))
		LOG.info("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
			 " reconstruct in-doubt transaction with size " + indoubtTransactionsById.size());

            if (reconstructIndoubts == 0) {
            //Retrieve (tid,Edits) from indoubt Transaction and construct/add into desired transaction data list
            for (Entry<Long, List<WALEdit>> entry : indoubtTransactionsById.entrySet()) {
                      long txid = 0;
                      long transactionId = entry.getKey();
                      ArrayList<WALEdit> editList = (ArrayList<WALEdit>) entry.getValue();
                      //editList = (ArrayList<WALEdit>) indoubtTransactionsById.get(transactionId);
		      if ((m_isTrafodionMetadata) || 
                  (LOG.isTraceEnabled()) ||
                  (m_detailedLogging))
			  LOG.info("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails + 
				   " process in-doubt transaction " + transactionId);
		      TrxTransactionState state = new TrxTransactionState(transactionId, /* 1L my_Region.getLog().getSequenceNumber()*/
									  nextLogSequenceId.getAndIncrement(), 
									  nextLogSequenceId, 
									  regionInfo, 
									  m_Region.getTableDesc(), 
									  tHLog,
#ifdef CDH5.7 APACHE1.2 CDH5.16
									  false, this.t_Region,
#else									  
									  false,
#endif									  
									  -1, m_regionName);  // don't worry about startId here

		      if ((m_isTrafodionMetadata) || 
                  (LOG.isTraceEnabled()) ||
                  (m_detailedLogging))
			  LOG.info("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
				   " create prepared transaction state for " + transactionId);

                      state.setFullEditInCommit(true);
		      state.setStartSequenceNumber(nextSequenceId.get());
                      state.setChoreMinSequenceNumber(state.getStartSequenceNumber());
                      synchronized (transactionsById) {
    	                  transactionsById.put(getTransactionalUniqueId(transactionId), state);
                      }

                      // Re-establish write ordering (put and get) for in-doubt transactional
                     int num  = editList.size();
                     if (LOG.isTraceEnabled()) LOG.trace("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                         " re-establish prepared transaction id " + transactionId + " with number of edit list kvs size " + num);
                    for (int i = 0; i < num; i++){
                          WALEdit b = editList.get(i);
                          if (LOG.isTraceEnabled()) LOG.trace("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                                    " re-establish prepared transaction id " + transactionId +
                                    " with " + b.size() + " kv in WALEdit " + i);
                          for (Cell kv : b.getCells()) {
                             Put put;
                             Delete del;
                             synchronized (editReplay) {
                             if (LOG.isTraceEnabled()) LOG.trace("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                                  " re-establish prepared transaction id " + transactionId +
                                  " write ordering Op Code " + kv.getTypeByte());
                             if (kv.getTypeByte() == KeyValue.Type.Put.getCode()) {
                               put = new Put(CellUtil.cloneRow(kv)); // kv.getRow()
                                put.addColumn(CellUtil.cloneFamily(kv), CellUtil.cloneQualifier(kv), kv.getTimestamp(), CellUtil.cloneValue(kv));
                                try {
                                 
                                    if (LOG.isDebugEnabled()) LOG.debug("HAX - CALL addWrite, construct indoubt put: "
                                        + Hex.encodeHexString(put.getRow()) 
                                          + " trans id: " + transactionId
                                          + " region info: " + m_regionDetails  );    
  
                                    state.addWrite(put, TrxRegionEndpoint.useCommitIdInCells, true);
                                }
                                catch (IOException ioe) {
                                     LOG.error("constructIndoubtTransactions -- caught late checkin exception in addWrite " + transactionId + " in region " + m_regionDetails);
                                }
                             }
                             else if (CellUtil.isDelete(kv))  {
                               del = new Delete(CellUtil.cloneRow(kv));
                                if (CellUtil.isDeleteFamily(kv)) {
                                   del.addFamily(CellUtil.cloneFamily(kv));
                                } else if (CellUtil.isDeleteType(kv)) {
                                   del.addColumn(CellUtil.cloneFamily(kv), CellUtil.cloneQualifier(kv));
                                }
                                try {      
                                    
                                    if (LOG.isDebugEnabled()) LOG.debug("HAX - CALL addDelete, construct indoubt delete: "
                                        + Hex.encodeHexString(del.getRow()) 
                                          + " trans id: " + transactionId
                                          + " region info: " + m_regionDetails  );                                    
                                                                        
                                    state.addDelete(del, TrxRegionEndpoint.useCommitIdInCells, true);
                                }
                                catch (IOException ioe) {
                                     LOG.error("constructIndoubtTransactions -- caught late checkin exception in addDelete " + transactionId + " in region " + m_regionDetails);
                                }                                    

                             } // handle put/delete op code
                             } // sync editReplay
                          } // for all kv in edit b
                    } // for all edit b in ediList 
                      state.setReinstated();
		      state.setStatus(Status.COMMIT_PENDING);
              state.setSequenceNumber(nextSequenceId.get());
              commitPendingTransactions.add(state);
              nextSequenceId.getAndIncrement();
		      state.resetEdit(); // move edits from state.e to state.pe during prepare time
		      commitedTransactionsBySequenceNumber.put(state.getSequenceNumber(), state);
		      if ((m_isTrafodionMetadata) || 
                  (LOG.isInfoEnabled()) ||
                  (m_detailedLogging))
			  LOG.info("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                                     " re-establish prepared transaction id " + transactionId +
				     " completed in prepared state");

                     // Rewrite HLOG for prepared edit (this method should be invoked in postOpen Observer ??
                    try {
                       //txid = this.tHLog.appendNoSync(this.regionInfo, this.regionInfo.getTable(),
                       //state.getEdit(), new ArrayList<UUID>(), TrxEnvironmentEdgeManager.currentTimeMillis(), this.m_Region.getTableDesc(),
                       //nextLogSequenceId, false, HConstants.NO_NONCE, HConstants.NO_NONCE);

#ifdef CDH5.7 APACHE1.2 CDH5.16	
			WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(), 
					     this.regionInfo.getTable(), 
					     WALKey.NO_SEQUENCE_ID,
					     TrxEnvironmentEdgeManager.currentTime(),
					     WALKey.EMPTY_UUIDS,
					     HConstants.NO_NONCE,
					     HConstants.NO_NONCE,
					     this.t_Region.getMVCC());	
					     
                       txid = this.tHLog.append(this.m_Region.getTableDesc(), this.regionInfo, wk, state.getPreparedEdit(), false);
		       
		       writeEntry = wk.getWriteEntry();
		       mvccNum = writeEntry.getWriteNumber();
		       
#else
			final WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(),
					  this.regionInfo.getTable(),
					  TrxEnvironmentEdgeManager.currentTime());

		       txid = this.tHLog.append(this.m_Region.getTableDesc(),
						this.regionInfo, 
						wk , 
						state.getPreparedEdit(),
						this.m_Region.getSequenceId(), 
						false, 
						null);
#endif
		       
		       if ((m_isTrafodionMetadata) ||
                   (LOG.isTraceEnabled()) ||
                   (m_detailedLogging))
			   LOG.info("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
			           "write WAL HLOG for prepared transaction id " 
				    + transactionId 
				    + " HLog seq " 
				    + txid
				    );
                       WALSync(tHLog, transactionId, txid);
#ifdef CDH5.7 APACHE1.2 CDH5.16	
		       if (writeEntry != null) {
		            this.t_Region.getMVCC().completeAndWait(writeEntry);
                            writeEntry = null;
		       }
#endif

                    }
                    catch (IOException exp) {
                       if (LOG.isWarnEnabled()) {
                           LOG.warn("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                             " transaction id " + transactionId
                             + " HLog seq " + txid + " Caught IOException in HLOG appendNoSync ", exp);
                       }
                       //throw exp;
                    }
#ifdef CDH5.7 APACHE1.2 CDH5.16    
		    finally {
			if (writeEntry != null) {
			    this.t_Region.getMVCC().completeAndWait(writeEntry);
			    writeEntry = null;
			}	  
		    } // finally
#endif                    
                    if (LOG.isTraceEnabled()) LOG.trace("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                               " rewrite to HLOG for in-doubt transaction " + transactionId);
                    int tmid = (int) state.getNodeId();
                    if (LOG.isTraceEnabled()) LOG.trace("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                               " reconstruct in-doubt transaction " + transactionId + " for TM " + tmid);
             } // for all txns in indoubt transcation list
            } // not reconstruct indoubtes yet
            // after reconstruct in-doubt txn by postOpen, init stale detection to post in-doubt to TM on ZK
            // the post will be done asap since the state is Recoverying (from abruptly region move)
            choreThreadDetectStaleTransactionBranch(); 	    
            reconstructIndoubts = 1;            
            if (this.configuredConflictReinstate) {
	        regionState.set(REGION_STATE_START); // set region state START , so new transaction can start with conflict re-established
            }
        } // synchronized
  }
 public void constructIndoubtTransactions(long seqid) {

#ifdef CDH5.7 APACHE1.2 CDH5.16
          MultiVersionConcurrencyControl.WriteEntry writeEntry = null;
          long mvccNum = 0;
          this.t_Region.getMVCC().advanceTo(seqid);
#endif

          synchronized (recoveryCheckLock) {
              if ((indoubtTransactionsById == null) || (indoubtTransactionsById.size() == 0)) {
                  if (LOG.isInfoEnabled()) LOG.info("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                          " has no in-doubt transaction, set region state REGION_STATE_START ");
                  if(regionState.intValue() != REGION_STATE_START) // M-18522, this region is not start yet, then do a start, other wise ,no need to redo the start
                  {
                      regionState.set(REGION_STATE_START); // region is started for transactional access
                      try {
                          startRegionAfterRecovery();
                      } catch (IOException exp1) {
                          if (LOG.isErrorEnabled()) LOG.error("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                                  " flush error during region start ", exp1);
                      }
                  }
                  reconstructIndoubts = 1;
                  return;
              }

              if ((m_isTrafodionMetadata) ||
                      (LOG.isTraceEnabled()) ||
                      (m_detailedLogging))
                  LOG.info("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                          " reconstruct in-doubt transaction with size " + indoubtTransactionsById.size());

              if (reconstructIndoubts == 0) {
                  //Retrieve (tid,Edits) from indoubt Transaction and construct/add into desired transaction data list
                  for (Entry<Long, List<WALEdit>> entry : indoubtTransactionsById.entrySet()) {
                      long txid = 0;
                      long transactionId = entry.getKey();
                      ArrayList<WALEdit> editList = (ArrayList<WALEdit>) entry.getValue();
                      //editList = (ArrayList<WALEdit>) indoubtTransactionsById.get(transactionId);
                      if ((m_isTrafodionMetadata) ||
                              (LOG.isTraceEnabled()) ||
                              (m_detailedLogging))
                          LOG.info("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                                  " process in-doubt transaction " + transactionId);
                      TrxTransactionState state = new TrxTransactionState(transactionId, /* 1L my_Region.getLog().getSequenceNumber()*/
                              nextLogSequenceId.getAndIncrement(),
                              nextLogSequenceId,
                              regionInfo,
                              m_Region.getTableDesc(),
                              tHLog,
                              #ifdef CDH5.7 CDH5.16 APACHE1.2
                      false, this.t_Region,
#else
                      false,
#endif
                              -1, m_regionName);  // don't worry about startId here

                      if ((m_isTrafodionMetadata) ||
                              (LOG.isTraceEnabled()) ||
                              (m_detailedLogging))
                          LOG.info("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                                  " create prepared transaction state for " + transactionId);

                      state.setFullEditInCommit(true);
                      state.setStartSequenceNumber(nextSequenceId.get());
                      state.setChoreMinSequenceNumber(state.getStartSequenceNumber());
                      synchronized (transactionsById) {
                          transactionsById.put(getTransactionalUniqueId(transactionId), state);
                      }

                      // Re-establish write ordering (put and get) for in-doubt transactional
                      int num  = editList.size();
                      if (LOG.isTraceEnabled()) LOG.trace("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                              " re-establish prepared transaction id " + transactionId + " with number of edit list kvs size " + num);
                      for (int i = 0; i < num; i++){
                          WALEdit b = editList.get(i);
                          if (LOG.isTraceEnabled()) LOG.trace("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                                  " re-establish prepared transaction id " + transactionId +
                                  " with " + b.size() + " kv in WALEdit " + i);
                          for (Cell kv : b.getCells()) {
                              Put put;
                              Delete del;
                              synchronized (editReplay) {
                                  if (LOG.isTraceEnabled()) LOG.trace("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                                          " re-establish prepared transaction id " + transactionId +
                                          " write ordering Op Code " + kv.getTypeByte());
                                  if (kv.getTypeByte() == KeyValue.Type.Put.getCode()) {
                                      put = new Put(CellUtil.cloneRow(kv)); // kv.getRow()
                                      put.addColumn(CellUtil.cloneFamily(kv), CellUtil.cloneQualifier(kv), kv.getTimestamp(), CellUtil.cloneValue(kv));
                                      try {

                                          if (LOG.isDebugEnabled()) LOG.debug("HAX - CALL addWrite, construct indoubt put: "
                                                  + Hex.encodeHexString(put.getRow())
                                                  + " trans id: " + transactionId
                                                  + " region info: " + m_regionDetails  );

                                          state.addWrite(put, TrxRegionEndpoint.useCommitIdInCells, true);
                                      }
                                      catch (IOException ioe) {
                                          LOG.error("constructIndoubtTransactions -- caught late checkin exception in addWrite " + transactionId + " in region " + m_regionDetails);
                                      }
                                  }
                                  else if (CellUtil.isDelete(kv))  {
                                      del = new Delete(CellUtil.cloneRow(kv));
                                      if (CellUtil.isDeleteFamily(kv)) {
                                          del.addFamily(CellUtil.cloneFamily(kv));
                                      } else if (CellUtil.isDeleteType(kv)) {
                                          del.addColumn(CellUtil.cloneFamily(kv), CellUtil.cloneQualifier(kv));
                                      }
                                      try {

                                          if (LOG.isDebugEnabled()) LOG.debug("HAX - CALL addDelete, construct indoubt delete: "
                                                  + Hex.encodeHexString(del.getRow())
                                                  + " trans id: " + transactionId
                                                  + " region info: " + m_regionDetails  );

                                          state.addDelete(del, TrxRegionEndpoint.useCommitIdInCells, true);
                                      }
                                      catch (IOException ioe) {
                                          LOG.error("constructIndoubtTransactions -- caught late checkin exception in addDelete " + transactionId + " in region " + m_regionDetails);
                                      }

                                  } // handle put/delete op code
                              } // sync editReplay
                          } // for all kv in edit b
                      } // for all edit b in ediList
                      state.setReinstated();
                      state.setStatus(Status.COMMIT_PENDING);
                      state.setSequenceNumber(nextSequenceId.get());
                      commitPendingTransactions.add(state);
                      nextSequenceId.getAndIncrement();
                      state.resetEdit(); // move edits from state.e to state.pe during prepare time
                      commitedTransactionsBySequenceNumber.put(state.getSequenceNumber(), state);
                      if ((m_isTrafodionMetadata) ||
                              (LOG.isInfoEnabled()) ||
                              (m_detailedLogging))
                          LOG.info("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                                  " re-establish prepared transaction id " + transactionId +
                                  " completed in prepared state");

                      // Rewrite HLOG for prepared edit (this method should be invoked in postOpen Observer ??
                      try {
                          //txid = this.tHLog.appendNoSync(this.regionInfo, this.regionInfo.getTable(),
                          //state.getEdit(), new ArrayList<UUID>(), TrxEnvironmentEdgeManager.currentTimeMillis(), this.m_Region.getTableDesc(),
                          //nextLogSequenceId, false, HConstants.NO_NONCE, HConstants.NO_NONCE);

#ifdef CDH5.7 CDH5.16 APACHE1.2
                          WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(),
                                  this.regionInfo.getTable(),
                                  WALKey.NO_SEQUENCE_ID,
                                  TrxEnvironmentEdgeManager.currentTime(),
                                  WALKey.EMPTY_UUIDS,
                                  HConstants.NO_NONCE,
                                  HConstants.NO_NONCE,
                                  this.t_Region.getMVCC());

                          txid = this.tHLog.append(this.m_Region.getTableDesc(), this.regionInfo, wk, state.getPreparedEdit(), false);

                          writeEntry = wk.getWriteEntry();
                          mvccNum = writeEntry.getWriteNumber();

#else
                          final WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(),
                                  this.regionInfo.getTable(),
                                  TrxEnvironmentEdgeManager.currentTime());

                          txid = this.tHLog.append(this.m_Region.getTableDesc(),
                                  this.regionInfo,
                                  wk ,
                                  state.getPreparedEdit(),
                                  this.m_Region.getSequenceId(),
                                  false,
                                  null);
#endif

                          if ((m_isTrafodionMetadata) ||
                                  (LOG.isTraceEnabled()) ||
                                  (m_detailedLogging))
                              LOG.info("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                                      "write WAL HLOG for prepared transaction id "
                                      + transactionId
                                      + " HLog seq "
                                      + txid
                              );
                          WALSync(tHLog, transactionId, txid);
#ifdef CDH5.7 CDH5.16 APACHE1.2
                          if (writeEntry != null) {
                              this.t_Region.getMVCC().completeAndWait(writeEntry);
                              writeEntry = null;
                          }
#endif

                      }
                      catch (IOException exp) {
                          LOG.warn("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                                  " transaction id " + transactionId
                                  + " HLog seq " + txid + " Caught IOException in HLOG appendNoSync ", exp);
                          //throw exp;
                      }
#ifdef CDH5.7 CDH5.16 APACHE1.2
		    finally {
                          if (writeEntry != null) {
                              this.t_Region.getMVCC().completeAndWait(writeEntry);
                              writeEntry = null;
                          }
                      } // finally
#endif
                      if (LOG.isTraceEnabled()) LOG.trace("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                              " rewrite to HLOG for in-doubt transaction " + transactionId);
                      int tmid = (int) state.getNodeId();
                      if (LOG.isTraceEnabled()) LOG.trace("Trafodion Endpoint Coprocessor: Trafodion Recovery Region " + m_regionDetails +
                              " reconstruct in-doubt transaction " + transactionId + " for TM " + tmid);
                  } // for all txns in indoubt transcation list
              } // not reconstruct indoubtes yet
              // after reconstruct in-doubt txn by postOpen, init stale detection to post in-doubt to TM on ZK
              // the post will be done asap since the state is Recoverying (from abruptly region move)
              choreThreadDetectStaleTransactionBranch();
              reconstructIndoubts = 1;
              if (this.configuredConflictReinstate) {
                  regionState.set(REGION_STATE_START); // set region state START , so new transaction can start with conflict re-established
              }
          } // synchronized
      }

  /**
   * Begin a transaction
   * @param long transactionId
   * @param long startId
   * @throws IOException
   */

  public void beginTransaction(final long transactionId, final long startId)
     throws IOException {
     beginTransaction(transactionId, startId, false, false);
  }
  
  /**
   * Begin a transaction
   * @param longtransactionId
   * @throws IOException
   */

  public void beginTransaction(final long transactionId, final long startId, final boolean regionTransaction, boolean skipcc)
     throws IOException {

    if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor: beginTransaction -- ENTRY txId: " + transactionId
                                +", startId " + startId
                                + " regionTransaction " + regionTransaction);

    checkBlockNonPhase2(transactionId);

    // TBD until integration with recovery 
    if (reconstructIndoubts == 0) {
       if (LOG.isTraceEnabled()) LOG.trace("RECOV beginTransaction -- ENTRY txId: " + transactionId);
       constructIndoubtTransactions();
    }
    
/*    
    if ((regionState.intValue() == REGION_STATE_START) //&& (configuredPITRecovery)
	                         && (mutationFlushed == 0)) {
	  try {
	         if (LOG.isTraceEnabled()) LOG.trace("PIT no exra Flush " + regionInfo.getTable().toString());
                 TBD-IBR mutationCapture.mutationBufferOp(PIT_MUTATION_CLOSE, null, null, 0, 0, -1, -1);
		 mutationFlushed = 1;
          } catch(IOException ioe) {
	         LOG.error("PIT Flush at the first begining transaction " + regionInfo.getTable().toString() + " exception " , ioe);
                 //TBD-IBR throw new IOException("Trafodion CDC Exception initial flush at beginning transcation ", ioe);
          }       
    }
*/

    if (regionState.intValue() != REGION_STATE_START) {
        //print out all the in-doubt transaction at this moment
        if ((indoubtTransactionsById == null) || (indoubtTransactionsById.size() == 0))
           regionState.set(REGION_STATE_START);
        else {
           IOException ioe = new IOException("NewTransactionStartedBeforeRecoveryCompleted");
           if (LOG.isWarnEnabled()) {
               LOG.warn("TRAF RCOV coprocessor: RECOVERY WARN beginTransaction while the region "
                 + m_regionDetails + " is still in recovering state "
                 +  regionState.intValue() + " indoubt tx size "
                 + indoubtTransactionsById.size() + " ", ioe );
           }
           synchronized(indoubtTransactionsById) {
           for (Entry<Long, List<WALEdit>> entry : indoubtTransactionsById.entrySet()) {
               long tid = entry.getKey();
               if (LOG.isTraceEnabled()) LOG.trace("Trafodion Recovery: region " + m_regionDetails + " still has in-doubt transaction " + tid + " when new transaction arrives ");
           } // for
           } // synchrinization
           throw ioe;
        }
    }

    TrxTransactionState state;
    synchronized (transactionsById) {
//      if (transactionsById.get(getTransactionalUniqueId(transactionId)) != null) {
//        TrxTransactionState alias = getTransactionState(transactionId);

//        LOG.error("beginTransaction - Ignoring - Existing transaction with id ["
//                   + transactionId + "] in region [" + m_regionName + "]");

//        if (LOG.isDebugEnabled()) LOG.debug("beginTransaction -- EXIT txId: " + transactionId);

//        return;
//      }

      if (LOG.isTraceEnabled()) LOG.trace("beginTransaction -- creating new TrxTransactionState without coprocessorHost txId: " + transactionId);

      state = new TrxTransactionState(transactionId,
				      nextLogSequenceId.getAndIncrement(),
				      nextLogSequenceId,
				      m_Region.getRegionInfo(),
				      m_Region.getTableDesc(), 
				      tHLog, 
#ifdef CDH5.7 APACHE1.2 CDH5.16
				      configuredEarlyLogging, this.t_Region,
#else					  
				      configuredEarlyLogging,
#endif									  				      
				      startId,
				      regionTransaction, false /* for IBR */,
                                      m_regionName);

      if(enableTmpWriterLock == true) state.setLockProtected(true);

      state.setFullEditInCommit(TrxRegionEndpoint.fullEditInCommit);
      if(TrxRegionEndpoint.useCommitIdInCells == false) {
         state.setStartSequenceNumber(nextSequenceId.get());
      }
      else {
         state.setStartSequenceNumber(state.getStartId());      
      }
    }
    
    state.setChoreMinSequenceNumber(state.getStartSequenceNumber());

if (! skipcc) { // if skipcc, then no need to add ts from cpl
    List<TrxTransactionState> commitPendingCopy = 
        new ArrayList<TrxTransactionState>(commitPendingTransactions);

    for (TrxTransactionState commitPending : commitPendingCopy) {
        state.addTransactionToCheck(commitPending);
        if (commitPending.getStartSequenceNumber() < state.getChoreMinSequenceNumber()){
           state.setChoreMinSequenceNumber(commitPending.getSequenceNumber());
        }
    }
}   

    Long key = getTransactionalUniqueId(transactionId);
    String leaseKey = getTransactionalLeaseId(transactionId);
    if (LOG.isTraceEnabled()) LOG.trace("beginTransaction -- new TrxTransactionState for txId: "
           + transactionId + " for key: " + key);
    synchronized (transactionsById) {
      transactionsById.put(key, state);
      if (LockConstants.ENABLE_ROW_LEVEL_LOCK && regionTransaction) {
          rsServer.addRegionTx(transactionId);
      }
    }

    if (LOG.isTraceEnabled()) LOG.trace("beginTransaction - Adding transaction: [" + transactionId + "] in region ["
                + m_regionDetails + "]" + " to list");
    try {
      transactionLeases.createLease(leaseKey, transactionLeaseTimeout, new TransactionLeaseListener(transactionId));
    } catch (LeaseStillHeldException e) {
      LOG.error("beginTransaction - Lease still held for [" + transactionId + "] in region ["
                + m_regionDetails + "]");
        throw new RuntimeException(e);
    }

    if (LOG.isDebugEnabled()) LOG.debug("beginTransaction -- EXIT txId: " + transactionId + " transactionsById size: " + transactionsById.size()
    		 + " region ID: " + this.regionInfo.getRegionId());
  }

  /**
   * Obtains a scanner lease id                            
   * @param long scannerId
   * @return String 
   */
  private String getScannerLeaseId(final long scannerId) {
    if (LOG.isTraceEnabled()) LOG.trace("getScannerLeaseId -- EXIT txId: " 
             + scannerId + " lease string " + m_regionName + scannerId);
    return m_regionName + scannerId;
  }
                                                             
  /**
   * Obtains a transactional lease id                            
   * @param long transactionId
   * @return String 
   */
  private String getTransactionalLeaseId(final long transactionId) {

    if (LOG.isTraceEnabled()) {
	LOG.trace("getTransactionalLeaseId -- EXIT txId: " 
             + transactionId + " transactionsById size: "
             + transactionsById.size() + " name " + m_regionName + transactionId);
    }
    return m_regionName + transactionId;
  }
  
  private Long getTransactionalUniqueId(final long transactionId) {

    return new Long(transactionId);
  }  
                                                             

  /**begin transaction if not yet
    * @param transactionId
    * @return true: begin; false: not necessary to begin
    * @throws IOException
   */
  private TrxTransactionState beginTransIfNotExist(final long transactionId, final long startId) throws RegionShieldedException, IOException{
     return beginTransIfNotExist(transactionId, startId, false, false);
  }

  /**begin transaction if not yet
    * @param transactionId
    * @return true: begin; false: not necessary to begin
    * @throws IOException
   */
  private TrxTransactionState beginTransIfNotExist(final long transactionId, final long startId, final boolean regionTx, 
                                                                boolean skipcc) throws RegionShieldedException, IOException{

    if (LOG.isTraceEnabled()) LOG.trace("Enter TrxRegionEndpoint coprocessor: beginTransIfNotExist, txid: "
            + transactionId + " startId: " + startId + ", regionTx: " + regionTx
            + ", regionName " + m_regionDetails
            + " transactionsById size: " + transactionsById.size());

    checkBlockNewTrans(transactionId);

    Long key = getTransactionalUniqueId(transactionId);
    synchronized (transactionsById) {
      TrxTransactionState state = transactionsById.get(key);

      if (state == null) {
        if (LOG.isTraceEnabled()) LOG.trace(": Begin transaction for txid: " + transactionId
                + " in beginTransIfNotExist beginning the transaction internally as state was null for key " + key);
        this.beginTransaction(transactionId, startId, regionTx, skipcc);
        state =  transactionsById.get(key);
        try {
           checkBlockForeignTransactions(transactionId);
        }
        catch (RegionShieldedException rse){
           // Region has been told to shield from new transactions.  We need to mark this TS
           // as SHIELDED so we don't let the commitRequest succeed
           state.setStatus(Status.SHIELDED);
           if (LOG.isTraceEnabled()) LOG.trace(": Begin transaction for txid: " + transactionId
                + " setting Status to SHIELDED because region is shielded ");
        }
      }
      else {
          if (LOG.isTraceEnabled()) LOG.trace("Exit beginTransIfNotExist with existing transaction for txid: " + transactionId);
      }
      return state;
    }
  }

  /**begin region transaction
    * @param transactionId
    * @return true: begin; false: not necessary to begin
    * @throws IOException
   */
  private TrxTransactionState beginRegionTransaction(final long transactionId, final long startId, boolean skipcc) throws RegionShieldedException, IOException{

    if (LOG.isTraceEnabled()) LOG.trace("Enter TrxRegionEndpoint coprocessor: beginRegionTransaction, txid: "
            + transactionId + " startId: " + startId
            + ", regionName " + m_regionDetails
            + " transactionsById size: " + transactionsById.size());

    checkBlockNewTrans(transactionId);

    // TBD until integration with recovery
    if (reconstructIndoubts == 0) {
       if (LOG.isTraceEnabled()) LOG.trace("RECOV beginTransaction -- ENTRY txId: " + transactionId);
       constructIndoubtTransactions();
    }

    if (regionState.intValue() != REGION_STATE_START) {
       //print out all the in-doubt transaction at this moment
       if ((indoubtTransactionsById == null) || (indoubtTransactionsById.size() == 0))
          regionState.set(REGION_STATE_START);
       else {
          IOException ioe = new IOException("NewTransactionStartedBeforeRecoveryCompleted");
          if (LOG.isWarnEnabled()) {
              LOG.warn("TRAF RCOV coprocessor: RECOVERY WARN beginRegionTransaction while the region "
                 + m_regionDetails + " is still in recovering state "
                 +  regionState.intValue() + " indoubt tx size "
                 + indoubtTransactionsById.size() + " ", ioe );
          }
          synchronized(indoubtTransactionsById) {
             for (Entry<Long, List<WALEdit>> entry : indoubtTransactionsById.entrySet()) {
                long tid = entry.getKey();
                if (LOG.isTraceEnabled()) LOG.trace("Trafodion Recovery: region " + m_regionDetails + " still has in-doubt transaction " + tid + " when new transaction arrives ");
             } // for
          } // synchrinization
          throw ioe;
       }
    }

    TrxTransactionState state;
    state = new TrxTransactionState(transactionId,
                                      nextLogSequenceId.getAndIncrement(),
                                      nextLogSequenceId,
                                      m_Region.getRegionInfo(),
                                      m_Region.getTableDesc(),
                                      tHLog,
#ifdef CDH5.7 APACHE1.2 CDH5.16
                                      configuredEarlyLogging, this.t_Region,
#else
                                      configuredEarlyLogging,
#endif
                                      startId,
                                      true /* Region Transaction */, false /* for IBR */,
                                      m_regionName);

    if(enableTmpWriterLock == true) state.setLockProtected(true);

    state.setFullEditInCommit(TrxRegionEndpoint.fullEditInCommit);
    if(TrxRegionEndpoint.useCommitIdInCells == false) {
       state.setStartSequenceNumber(nextSequenceId.get());
    }
    else {
       state.setStartSequenceNumber(state.getStartId());
    }
    
    state.setChoreMinSequenceNumber(state.getStartSequenceNumber());    

    if (! skipcc) { // if skipcc, then no need to add ts from cpl
       List<TrxTransactionState> commitPendingCopy =
          new ArrayList<TrxTransactionState>(commitPendingTransactions);

       for (TrxTransactionState commitPending : commitPendingCopy) {
            state.addTransactionToCheck(commitPending);
            if (commitPending.getStartSequenceNumber() < state.getChoreMinSequenceNumber()){
                state.setChoreMinSequenceNumber(commitPending.getSequenceNumber());
            }            
       }
    }

    Long key = getTransactionalUniqueId(transactionId);
    synchronized (transactionsById) {
      TrxTransactionState state1 = transactionsById.get(key);

      if (state1 == null) {
         transactionsById.put(key, state);
         if (LockConstants.ENABLE_ROW_LEVEL_LOCK) {
             rsServer.addRegionTx(transactionId);
         }
      }
      else {
         if (LOG.isWarnEnabled()) {
             LOG.warn("beginRegionTransaction found existing state with tid " + transactionId);
         }
         throw new IOException("beginRegionTransaction found existing state with tid " + transactionId);
      }
    }

    if (LOG.isDebugEnabled()) LOG.debug("beginRegionTransaction -- EXIT txId: " + transactionId + " transactionsById size: " + transactionsById.size()
            + " region ID: " + this.regionInfo.getRegionId());
    return state;
  }

  /**
   * Determines if this transaction has been committed previously
   * @param long TransactionId
   */
TrxTransactionState isTransactionOnCommittedList(final long transactionId)
{
    // unforunately we do not have the transaction state so we do 
    // not have the seqence number.  This should not be a common occurrence 
    // and therefore should not negatively affect performance
    synchronized (commitedTransactionsBySequenceNumber) {
        for(Map.Entry<Long, TrxTransactionState> entry :
            commitedTransactionsBySequenceNumber.entrySet()) {
                if (entry.getValue().getTransactionId() == transactionId)
                    return entry.getValue();
         }
    }

    return null;
}


  /**
   * Commits the transaction
   * @param long TransactionId
   * @throws IOException
   */
  public boolean commit(final long transactionId, final long commitId, final int participantNum, final int tmTableCDCAttr, final short totalNum, final int ddlNum) throws IOException {
     return commit(transactionId, commitId, participantNum, tmTableCDCAttr, false /* IgnoreUnknownTransactionException */, totalNum, ddlNum);
  }

  /**
   * Commits the transaction                        
   * @param long TransactionId
   * @param boolean ignoreUnknownTransactionException
   * @throws IOException 
   */
  public boolean commit(final long transactionId, final long commitId, final int participantNum, final int tmTableCDCAttr,
                           final boolean ignoreUnknownTransactionException, final short totalNum, final int ddlNum) throws IOException {
    if (ignoreUnknownTransactionException)
    {
       if (LOG.isInfoEnabled()) LOG.info("ignoring UnknownTransaction in commitTransaction: " + transactionId +
              " commitId " + commitId + " tmTableCDCAttr " + tmTableCDCAttr + " ignoreUnknownTransaction: " + ignoreUnknownTransactionException
              + " Region : " + m_regionDetails);
    }
    long time3 = 0, time2 = 0, time1 = 0, time4 = 0;
    long tmpTime = 0, preTime = 0, startTime = System.currentTimeMillis();
    CommitProgress commitProgress = CommitProgress.NONE;
    boolean walSync = false;
    TrxTransactionState state;

    checkBlockAll(transactionId);

    try {
      state = getTransactionState(transactionId);
      if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
        preTime = System.currentTimeMillis();
        time1 = preTime - startTime;
      }
    } catch (UnknownTransactionException e) {
      state = null;
      if ((state = isTransactionOnCommittedList(transactionId)) != null) {
          if (LOG.isWarnEnabled()) {
              LOG.warn("Participant " + participantNum
                + " commit [DUPLICATE] Asked to commit a committed transaction: " + transactionId
                + " state: " + state + " in region " + m_regionDetails);
          }
      }
      else {

         if ( (tmTableCDCAttr & TIMELINE) == TIMELINE ) { // tabel with TimeLine attr, ignore the undeleivery 
            if (LOG.isInfoEnabled()) LOG.info("ignoring UnknownTransaction for Timeline table in commitTransaction: " + transactionId +
              " commitId " + commitId + " tmTableCDCAttr " + tmTableCDCAttr + " ignoreUnknownTransaction: " + ignoreUnknownTransactionException
              + " Region : " + m_regionDetails);

            unLockRegionAll(transactionId);
            return walSync;
         }
          
         if (ignoreUnknownTransactionException) {
            if (LOG.isInfoEnabled()) LOG.info("ignoring UnknownTransaction in commitTransaction : " + transactionId
                + "Participant " + participantNum
                + " CPL " + commitPendingTransactions.size() + " IDT " + indoubtTransactionsById.size()
                + " region state " + regionState.intValue() + " in region " + m_regionDetails);
         
           if (regionState.intValue() == REGION_STATE_RECOVERING) {
              synchronized(indoubtTransactionsById) {
                  indoubtTransactionsById.remove(transactionId);
                  if (LOG.isInfoEnabled()) LOG.info("Trafodion Endpoint: remove indoubtTransactionsById " + transactionId 
                     + " CPL " + commitPendingTransactions.size() + " IDT " + indoubtTransactionsById.size()
                     + " region " + m_regionName);
               }
               if (indoubtTransactionsById.size() == 0) regionState.set(REGION_STATE_START); 
            }

            TrxTransactionState ts1 = null;
            synchronized(commitPendingTransactions) {
               for (TrxTransactionState commitPendingTS : commitPendingTransactions) {
                   if (commitPendingTS.getTransactionId() == transactionId) {
                       ts1 = commitPendingTS;
                       break;
                   }
               }
               if (ts1 != null) {
                 LOG.warn("Trafodion Endpoint: Find ts in CPL but not in TransactionsById " + transactionId
                                     + " ts " + ts1.toString());         
                 if (commitPendingTransactions.remove(ts1)) {
                     if (LOG.isInfoEnabled()) LOG.info("Trafodion Endpoint: remove commitPendingTransactions " + transactionId
                         + " CPL " + commitPendingTransactions.size() + " IDT " + indoubtTransactionsById.size()
                         + " region " + m_regionName);
                 }
                 else { 
                     if (LOG.isInfoEnabled()) LOG.info("Trafodion Endpoint: not remove commitPendingTransactions " + transactionId
                       + " CPL " + commitPendingTransactions.size() + " IDT " + indoubtTransactionsById.size()
                       + " region " + m_regionName);                       
                 }
                } // ts1 != null
            } // sync
            unLockRegionAll(transactionId);
            if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
              time2 = System.currentTimeMillis();
              if ((time2 - startTime) >= RSConstants.RECORD_TIME_COST_COPRO) {
                  if (LOG.isWarnEnabled()){
                      LOG.warn(m_regionName + " commit(txId) inner1 txID " + transactionId + " TC " + (time2 - startTime));
                  }
              }
            }
            return walSync;
         }
         if (LOG.isWarnEnabled()) {
             LOG.warn("Participant " + participantNum
               + " Asked to commit unknown transaction: " + transactionId
               + " in region " + m_regionDetails);
         }

         unLockRegionAll(transactionId);
         throw new IOException("UnknownTransactionException,  Participant "
                           + participantNum + " transId: " + transactionId);
      }
      unLockRegionAll(transactionId);
    }

    if (transactionId != state.getTransactionId())
        LOG.error("Participant " + participantNum
                   + " commit - transactionId parameter is different from state.getTransactionId, transid: "
                   + transactionId + " state: " + state + " in region " + m_regionDetails);

    state.setCommitId(commitId);
    state.setMutationClient(tmTableCDCAttr); // set mutation client from TM Table Attributes (e.g. SYNC or IBR)
/* TBD    
    if (tmTableCDCAttr && (commitId <= 2)) {
                 LOG.warn("Commit Transaction " + transactionId  + " with CatchupMutation " + generateCatchupMutations +
                   " but invalid commitId " + commitId + " state: " + state + " in region " + m_regionDetails);
         throw new IOException("Commit Transaction " + transactionId  + " with CatchupMutation " + generateCatchupMutations +
                   " but invalid commitId " + commitId + " state: " + state + " in region " + m_regionDetails);
    }
*/
    if (!state.getStatus().equals(Status.COMMIT_PENDING)) {
      if (state.getStatus().equals(Status.COMMITED) || state.getStatus().equals(Status.COMMIT_READONLY)) {
           if (LOG.isWarnEnabled()) {
               LOG.warn("Participant " + participantNum +
                   " commit [DUPLICATE]- Asked to commit a committed transaction, transid: " + transactionId +
                                " state: " + state + " in region " + m_regionDetails);
           }
//         throw new IOException("Participant " + participantNum + " commit [DUPLICATE] Asked to commit a non-pending transaction, transid: " + transactionId +
//                                " state: " + state + " in region " + m_regionDetails);
      }
      else {
         LOG.error("Participant " + participantNum +
                   " commit - Asked to commit a non pending transaction, transid: " + transactionId +
                                " state: " + state + " in region " + m_regionDetails);

         retireTransaction(state, true);
         unLockRegionAll(transactionId);
         throw new IOException("NonPendingTransactionException: Participant " + participantNum + " Asked to commit a non-pending transaction, transid: " + transactionId +
                                " state: " + state + " in region " + m_regionDetails);
      }
    }
    if (LOG.isTraceEnabled()) LOG.trace("commit(txId) -- EXIT txId: " + transactionId);

    // manage concurrent duplicate commit requests through TS.xaOperation object

    synchronized(state.getXaOperationObject()) {
        commitProgress = state.getCommitProgress();
        long transId = state.getTransactionId();
        //if (LOG.isTraceEnabled()) LOG.trace("commit HHH " + commitStatus);
        if (commitProgress.equals(CommitProgress.COMMITED)) {
            // already committed, this is likely unnecessary due to Status check above
            if (LOG.isWarnEnabled()) LOG.warn("commit - duplicate commit for committed transaction " + transId + " state is " + state);
        }
        else if (commitProgress.equals(CommitProgress.COMMITTING)) {
            if (LOG.isWarnEnabled()) LOG.warn("commit - sleeping 1 second for committing transaction" + transId + " state is " + state);
            try {
                Thread.sleep(1000);          ///1000 milliseconds is one second.
            } catch(InterruptedException ex) {
                  Thread.currentThread().interrupt();
            }
            CommitProgress tmpProgress = state.getCommitProgress();
            if (tmpProgress.equals(CommitProgress.COMMITTING)){
               if (LOG.isWarnEnabled()) LOG.warn("commit - transaction " + transId + " is still committing "
                        + " state is " + state);
            }
            else{
               if (LOG.isWarnEnabled()) LOG.warn("commit - transaction " + transId + " commitProgress is " + tmpProgress
                      + " state is " + state);
            }
            if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
              tmpTime = System.currentTimeMillis();
              time2 = tmpTime - preTime;
              preTime = tmpTime;
            }
        }
        else if (commitProgress.equals(CommitProgress.NONE)
                 || commitProgress.equals(CommitProgress.COMMIT_FAILED)) {
            if (LOG.isTraceEnabled()) LOG.trace("commit " + commitProgress);
            state.setCommitProgress(CommitProgress.COMMITTING);

            commit(state, totalNum, ddlNum);
            if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
              tmpTime = System.currentTimeMillis();
              time3 = tmpTime - preTime;
              preTime = tmpTime;
            }
        } else {
            if (LOG.isWarnEnabled()) {
                LOG.warn("unexpected CommitProgress status " + commitProgress + " tid " + transId
                     + " region " + m_regionDetails + " state is " + state);
            }
        }
    }
    walSync = (state.getStatus().equals(Status.COMMITED) && state.getCommitProgress().equals(CommitProgress.COMMITED)
               && (TrxRegionEndpoint.asyncWal == 2 || TrxRegionEndpoint.asyncWal == 4));
    if (LOG.isTraceEnabled()) LOG.trace("commit(txId) -- EXIT txId: " + transactionId
         + " commitId " + commitId);

    long sequenceNum = state.getSequenceNumber();
    if (sequenceNum >= 0) {
        state = commitedTransactionsBySequenceNumber.get(sequenceNum);
        if (state != null && state.getCommitProgress().equals(CommitProgress.COMMITED)) {
            unLockRegionAll(transactionId);
        }
    }
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      time4 = System.currentTimeMillis();
      if ((time4 - startTime) >= RSConstants.RECORD_TIME_COST_COPRO) {
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " commit(txId) inner2 txID " + transactionId + " TC " + (time4 - startTime) + " time1 " + time1 + " time2 " + time2 + " time3 " + time3);
          }
      }
    }
    return walSync;
  } 

  /**
   * Commits the savepoint
   * @param long TransactionId
   * @param long savepointId
   * @param int  participantNum
   * @param boolean ignoreUnknownTransactionException
   * @throws IOException
   */
  public void commitSavepoint(final long transactionId, final long savepointId,
                              final int participantNum, final boolean ignoreUnknownTransactionException) throws IOException {

    TrxTransactionState state;
    int error = INIT_SVPT_ERROR;
    
    if (savepointId < 0) { // illegal savepointId
            LOG.error("Commit savepoint checkin with invalid savepoint id for tid " + transactionId + " svpt " + savepointId
                                        + " in region " + m_regionDetails);
            throw new IOException("Commit savepoint checkin with invalid savepoint id for tid " + transactionId + " svpt " + savepointId
                                        + " in region " + m_regionDetails);                                        
    }

    checkBlockAll(transactionId);

    if (LOG.isTraceEnabled()) LOG.trace("commitSavepoint transactionId: " + transactionId
         + " savepointId: " + savepointId + " " + m_regionDetails);

    try {
      state = getTransactionState(transactionId);
    } catch (UnknownTransactionException e) {

      unLockRegionAll(transactionId, savepointId);

      if (ignoreUnknownTransactionException == true) {
         if (LOG.isDebugEnabled()) LOG.debug("Participant " + participantNum + " ignoring UnknownTransaction in commitSavepoint : "
                + transactionId + " savepointId " + savepointId + " in region " + m_regionDetails);
         return;
      }
      state = null;
      LOG.error("Participant " + participantNum
               + " Asked to commitSavepoint for unknown transaction: " + transactionId + " savepointId " + savepointId
               + " in region " + m_regionDetails);

      throw new IOException("UnknownTransactionException,  in commitSavepoint Participant "
                           + participantNum + " transId: " + transactionId + " savepointId " + savepointId );
    }
    
    // Savepoint Checkin  
    error = state.savepointCheckin(savepointId, SavepointOp.COMMIT_SVPT_OP);

    if (error < 0) {
         throw new IOException("Savepoint checkin error " + error + " on tid " + transactionId + " svpt " + savepointId + 
                    " op COMMIT_SVPT_OP " + SavepointOp.COMMIT_SVPT_OP + " in region " + m_regionDetails);
    }
    else if (error == OK_SVPT_ERROR) {
        try {
           // Extension: can do extra stuff here (e.g. pre-prepare a statement)
           state.editConstructSavepointIntoTS(savepointId);
           state.setSavepointContextState(savepointId, SavepointState.COMMIT_SVPT_STATE);
        }
        finally {
           //Savepoint Checkout
           state.savepointCheckout(savepointId, SavepointOp.COMMIT_SVPT_OP);
        }
    }
    
    // when error > 0, e.g. 1, implies duplicate commit savepoint req, likely from multiple ESP, just ignore since no checkin is made

    if (LOG.isTraceEnabled()) LOG.trace("commitSavepoint -- EXIT txId: " + transactionId
         + " savepointId " + savepointId);

    flushSvptToTx(transactionId, savepointId);    

  } 

  /**
   * @param transactionId
   * @return TransactionRegionInterface commit code
   * @throws IOException
   */
  public int commitRequest(final long transactionId, final boolean skipConflictDetection, final long startEpoch, final int participantNum) 
                                                 throws IOException,
                                                 CommitConflictException,
                                                 CommitDoomedException,
                                                 RegionShieldedException,
                                                 EpochViolationException,
                                                 UnknownTransactionException {
                return commitRequest(transactionId, skipConflictDetection, startEpoch, participantNum, true, false, false, null, (short)0);
  }

  public int commitRequest(final long transactionId, final boolean skipConflictDetection, final long startEpoch, final int participantNum,
                                           final boolean dropTableRecorded)
                                                 throws IOException,
                                                 CommitConflictException,
                                                 CommitDoomedException,                                                 
                                                 RegionShieldedException,
                                                 EpochViolationException,
                                                 UnknownTransactionException {
      return commitRequest(transactionId, skipConflictDetection, startEpoch, participantNum, true, dropTableRecorded, false, null, (short)0);
  }      
  
  public int commitRequest(final long transactionId, final boolean skipConflictDetection, final long startEpoch, final int participantNum,
                                           final boolean dropTableRecorded, boolean ignoreUnknownTransactionTimelineException, final String query, short totalNum)
                                                 throws IOException,
                                                 CommitConflictException,
                                                 CommitDoomedException,                                                 
                                                 RegionShieldedException,
                                                 EpochViolationException,
                                                 UnknownTransactionException {
      return commitRequest(transactionId, skipConflictDetection, startEpoch, participantNum, true, dropTableRecorded, ignoreUnknownTransactionTimelineException, query, totalNum);
  }
  
  public int commitRequest(final long transactionId, final boolean skipConflictDetection, final long startEpoch, final int participantNum, boolean flushHLOG,
                                        boolean dropTableRecorded, boolean ignoreUnknownTransactionTimelineException,
                                                               final String query, short totalNum)

                                                 throws IOException,
                                                 CommitConflictException,
                                                 CommitDoomedException,                                                 
                                                 RegionShieldedException,
                                                 EpochViolationException,
                                                 UnknownTransactionException {
    long txid = 0;
    if (LOG.isDebugEnabled()) LOG.debug("commitRequest(transId) -- ENTRY txId: "
               + transactionId + " skipConflictDetection " + skipConflictDetection
               + " ignoreUnknownTransactionTimeline " + ignoreUnknownTransactionTimelineException               
               + " participantNum " + participantNum + " totalNum " + totalNum + " region " + m_regionDetails
               + " start key: " + ((regionInfo.getStartKey() != null) ?
                                (Bytes.equals(regionInfo.getStartKey(), HConstants.EMPTY_START_ROW) ? "INFINITE" : Hex.encodeHexString(regionInfo.getStartKey())) : "NULL")
               + " end key: " + ((regionInfo.getEndKey() != null) ?
                                (Bytes.equals(regionInfo.getEndKey(), HConstants.EMPTY_END_ROW) ? "INFINITE" : Hex.encodeHexString(regionInfo.getEndKey())) : "NULL"));

    if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
        printMemoryUsage("commitRequest() - start commitRequest txid: " + transactionId);

    TrxTransactionState state;
    int lv_totalCommits = 0;
    int lv_timeIndex = 0;
    if (this.txnStatisticsCollection > 0) { //(LOG.isInfoEnabled()) {
      synchronized (totalCommits){
         lv_totalCommits = totalCommits.incrementAndGet();
         lv_timeIndex = (timeIndex.getAndIncrement() % 50 );
      }
    }

    boolean sleepForDuplicate = false;
    boolean returnPending = false;
    long commitCheckEndTime = 0;
    long hasConflictStartTime = 0;
    long hasConflictEndTime = 0;
    long putBySequenceStartTime = 0;
    long putBySequenceEndTime = 0;
    long writeToLogEndTime = 0;
    long commitCheckStartTime = System.nanoTime();
    long tmpTime = 0, preTime = 0, startTime = System.currentTimeMillis();
    long time1 = 0, time2 = 0, time3 = 0, time4 = 0, time5 = 0, time6 = 0;
    long time3_1 = 0, time3_2 = 0, time3_3 = 0, time3_4 = 0, time3_5 = 0, time3_6 = 0, time3_7 = 0, time3_8 = 0, time3_9 = 0, time3_10 = 0;

    TransactionMutationMsg.Builder tmBuilder =  null;

#ifdef CDH5.7 APACHE1.2 CDH5.16	    
    MultiVersionConcurrencyControl.WriteEntry writeEntry = null;
    long mvccNum = 0;
#endif

    try {
      state = getTransactionState(transactionId);
    } catch (UnknownTransactionException e) {

/*       if (startEpoch < onlineEpoch) {
          LOG.error("commitRequest txId: "
               + transactionId + ", participantNum " + participantNum
               + " startEpoch " + startEpoch + " is less than region's onlineEpoch " + onlineEpoch
               + " for regionName " + m_regionDetails
               + " must return COMMIT_UNSUCCESSFUL_FROM_COPROCESSOR ");
               state = null;
               return COMMIT_UNSUCCESSFUL_FROM_COPROCESSOR;
       }
*/

       // can only ignore UTE in commitRequest for timeline mode
       if (ignoreUnknownTransactionTimelineException) {
            if (LOG.isInfoEnabled()) LOG.info("ignoring UnknownTransaction in commitRequest with Timeline Consistency mode: "
                + " TransactionId " + transactionId
                + " Participant " + participantNum
                + " region state " + regionState.intValue() + " in region " + m_regionDetails);
                return COMMIT_OK;
       }

       int clusterid = (int) TransactionState.getClusterId(transactionId);
       if ((onlineEpoch <= startEpoch) && 
              (    (clusterid == pSTRConfig.getTrafClusterIdInt()) || 
                     ((clusterid == 1) && (pSTRConfig.getConfiguredPeerCount() == 0))    )                ){
          if (LOG.isInfoEnabled()) {
              LOG.info("commitRequest txId: "
               + transactionId + ", participantNum " + participantNum
               + " startEpoch " + startEpoch + " is greater than region's onlineEpoch " + onlineEpoch
               + " for non-participating region regionName " + m_regionDetails);
          }
          state = null;
          try {unLockRegionAll(transactionId);} catch (Exception ex) {}
          return COMMIT_UNSUCCESSFUL_FROM_COPROCESSOR;
       }

       if (LOG.isWarnEnabled()) LOG.warn("commitRequest Unknown transaction ["
               + transactionId + " in regionName " + m_regionDetails
               + ", participantNum " + participantNum
               + ", startEpoch " + startEpoch + ", onlineEpoch " + onlineEpoch);
               //+ " must return COMMIT_UNSUCCESSFUL_FROM_COPROCESSOR ");
        state = null;
        try {unLockRegionAll(transactionId);} catch (Exception ex) {}
        return COMMIT_UNSUCCESSFUL_FROM_COPROCESSOR;
    }

    // We allow regionTX to commit regardless of online epoch
    if ((startEpoch < onlineEpoch) && (! state.getIsRegionTx())) {
        
        // ignore epoch issue if in timeline mode (since it is read only)
        if (ignoreUnknownTransactionTimelineException) {
            if (LOG.isInfoEnabled()) LOG.info("ignoring starting epoch in commitRequest with Timeline Consistency mode: "
                + " TransactionId " + transactionId + " Participant " + participantNum
                + " startEpoch " + startEpoch + " region's onlineEpoch " + onlineEpoch
                + " region state " + regionState.intValue() + " in region " + m_regionDetails);
                return COMMIT_OK;
        }        
        
        state.setStatus(Status.ABORTED);
        retireTransaction(state, true);
        try {unLockRegionAll(transactionId);} catch (Exception e) {}
        LOG.error("commitRequest txId: "
               + transactionId + ", participantNum " + participantNum
               + " startEpoch " + startEpoch + " is less than region's onlineEpoch " + onlineEpoch
               + " for regionName " + m_regionDetails
               + " must return EPOCH_VIOLATION ");
        throw new EpochViolationException("commitRequest txId: "
               + transactionId + ", participantNum " + participantNum
               + " startEpoch " + startEpoch + " is less than region's onlineEpoch " + onlineEpoch
               + " for regionName " + m_regionDetails);
    }  

    if (state.getStatus().equals(Status.SHIELDED)){
      if (LOG.isDebugEnabled()) LOG.debug("SHIELDED transactionState" + state + " found in region " + m_regionName
                       + ". Participant " + participantNum + " must abort");
      state.setStatus(Status.ABORTED);
      retireTransaction(state, true);
      try {unLockRegionAll(transactionId);} catch (Exception e) {}
      if (LOG.isTraceEnabled()) LOG.trace("commitRequest encountered shielded txId: "
                 + transactionId + " returning COMMIT_SHIELDED ");

      throw new RegionShieldedException("Transaction " + state.getTransactionId() + " is SHIELDED ");
    }

    if (! state.getIsRegionTx()) {
       // if this is the 1st time the region receives a prepare request from a TMnn,
       // ask TMnn to refresh the region map and redrive
       int tmid = TransactionState.getNodeId(transactionId);
       if (!tmPrepareRefresh[tmid]) { // the init value of boolean array is false
          tmPrepareRefresh[tmid] = true;
          if (LOG.isDebugEnabled()) LOG.debug("TM Prepare Refresh txId: " + transactionId + " in Region " + m_regionDetails);
          return PREPARE_REFRESH;
       }
    }
    else {
       if (LOG.isDebugEnabled()) LOG.debug("TM Prepare Refresh skipping region tx: " + state);
    }

    if (this.txnStatisticsCollection > 0) // LOG.isInfoEnabled()) 
      hasConflictStartTime = System.nanoTime();

    state.setQueryContext(query);

    if (LOG.isDebugEnabled()) LOG.debug("HBX transaction " + transactionId
                       + " regionTx: " + state.getIsRegionTx() + " Query Context: " + state.getQueryContext());

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      preTime = System.currentTimeMillis();
      time1 = preTime - startTime;
    }

    
    while (true) {
      if (sleepForDuplicate) {
         try {
            Thread.sleep(20);
         } catch (InterruptedException e) {
         }
      }
      sleepForDuplicate = false;
      synchronized (commitCheckLock) {
      
        checkBlockNonPhase2(transactionId);

        if (state.getStatus().equals(Status.DOOMED)) { // doomed transaction
            state.setStatus(Status.ABORTED);
            retireTransaction(state, true);
            try {unLockRegionAll(transactionId);} catch (Exception e) {}
            if (LOG.isInfoEnabled()) LOG.info("commitRequest encountered doomed txId: "
                   + transactionId + " returning COMMIT_DOOMED due to active scanner during split/balance ");
            throw new CommitDoomedException("commitRequest encountered conflict txId: "
                   + transactionId + " returning COMMIT_DOOMED due to active scanner during split/balance ");
        }
      
        if (state.getStatus().equals(Status.ABORTED)) { // has been aborted by region unilaterally
            if (LOG.isInfoEnabled()) LOG.info("commitRequest encountered aborted txId: "
                   + transactionId + " returning COMMIT_DOOMED ");
            retireTransaction(state, true);
            try {unLockRegionAll(transactionId);} catch (Exception e) {}
            throw new CommitDoomedException("commitRequest encountered aborted txId: "
                   + transactionId + " returning COMMIT_DOOMED ");
        }	

        if (state.getStatus().equals(Status.START_COMMIT)) {
            sleepForDuplicate = true;
            continue;
        }

        if (state.getStatus().equals(Status.COMMIT_PENDING)) { // duplicate prepare message
            if (LOG.isInfoEnabled()) LOG.info("duplicate commitRequest received txId: "
                   + transactionId + " vote COMMIT_OK and wait for Phase 2 ");
            if(state.hasWrite() )
              return COMMIT_OK;
            else
              return COMMIT_OK_READ_ONLY;
        } else if (false == state.getStatus().equals(Status.PENDING)) {
            if (LOG.isInfoEnabled()) LOG.info("duplicate commitRequest received txId: "
                   + transactionId + " with status " + state.getStatus());
            retireTransaction(state, true);
            try {unLockRegionAll(transactionId);} catch (Exception e) {}
            return COMMIT_UNSUCCESSFUL_FROM_COPROCESSOR;
        }

        if (onlineBalance.get() == true) {
          LOG.warn("commitRequest txId: " + transactionId + ", region is closing and regionName is " + m_regionDetails);
          state.setStatus(Status.ABORTED);
          retireTransaction(state, true);
          try {
            unLockRegionAll(transactionId);
          } catch (Exception e) {}
          return COMMIT_UNSUCCESSFUL_FROM_COPROCESSOR;
        }
    
        if (!LockConstants.ENABLE_ROW_LEVEL_LOCK && skipConflictDetection == false && noConflictCheckForIndex == false){
          try{
            checkConflict(state);
          } catch (IOException e) {
            if (this.txnStatisticsCollection > 0) { // LOG.isInfoEnabled()) {
              hasConflictEndTime = System.nanoTime();
              hasConflictTimes[lv_timeIndex] = hasConflictEndTime - hasConflictStartTime;
              totalConflictTime += hasConflictTimes[lv_timeIndex];
            }
            state.setStatus(Status.ABORTED);
            retireTransaction(state, true);
            if (LOG.isDebugEnabled()) LOG.debug("commitRequest encountered conflict txId: "
                     + transactionId + "returning COMMIT_CONFLICT", e);
            throw new CommitConflictException(e);
          }
        }
      //LOG.info("BB3" +skipConflictDetection); 
        if (this.txnStatisticsCollection > 0) // LOG.isInfoEnabled()) 
            hasConflictEndTime = System.nanoTime();

        // No conflicts, we can commit.
        if (LOG.isDebugEnabled()) LOG.debug("No conflicts for transaction " + transactionId
                         + " regionTx: " + state.getIsRegionTx() + " found in region " + m_regionDetails
                         + ". Participant " + participantNum + " votes to commit");

        // If there are writes we must keep record of the transaction
        putBySequenceStartTime = System.nanoTime();
           if (this.txnStatisticsCollection > 0) { // LOG.isInfoEnabled()) {
              // Only increment this counter if we are logging the statistics
              putBySequenceOperations.getAndIncrement();
           }
           state.setStatus(Status.START_COMMIT);
           if (LOG.isDebugEnabled()) LOG.debug("Transaction " + transactionId
                 + " found in region " + m_regionDetails
                 + ". Adding to commitedTransactionsBySequenceNumber for sequence number " + state.getSequenceNumber());
        commitCheckEndTime = putBySequenceEndTime = System.nanoTime();
      } // exit sync block of commitCheckLock
      break;
    } //end block of while 
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      tmpTime = System.currentTimeMillis();
      time2 = tmpTime - preTime;
      preTime = tmpTime;
   }

   boolean readonlyparticipate = false;            
   if (state.hasWrite()) {
      if (LOG.isDebugEnabled()) LOG.debug("write commitRequest edit to HLOG trans id " + transactionId +
                " with put size: " + (state.writeSize()-state.deleteSize()) + " delete size: " +  state.deleteSize() +
                " region details " + m_regionDetails);

      //call HLog by passing tagged WALEdits and associated fields
      try {

        // Once we append edit into HLOG during DML operation, there is no need to do any HLOG write in phase 1.
        // Likely all the edits have been synced, so just do a sync(state.getLargestFlushTxId()) --> most likely,
        // it is a no-op. This is to leverage the time between last DML and phase 1, so there is no need to do any
        // logging (and waited) in phase 1.  And there is no need to write "prepared" record since we try to optimize
        // normal running mode (99.99% commit).  We can append "commit" or "abort" into HLOG in phase 2 in a no-sync
        // mode, but it can also be eliminated if necessary.  All the transaction reinstated during recovery will be
        // treated as "in-doubt" and need to use TLOG to resolve.  So TLOG must be kept for a while (likely a few CP),
        // besides, HRegion chore thread can perform ~ CP action by writing the smallest sequenceId (not logSeqid),
        // so we don't need to deal with commit case (but we did write abort edit since the number of abort is
        // < 0.1% -- we can set this as a configurable property).

        if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
  	    tmpTime = System.currentTimeMillis();
  	    time3_1 = tmpTime - preTime;
         }
            if (!state.getEarlyLogging()) {

               // Rebuild the edit list if needed
               //TODO: apply memory point +4
               if(state.isSavepointActiviated() || state.getUpdatedSameRow()) {
                   if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
                       printMemoryUsage("commitRequest() - before rebuild the edit list txid: " + transactionId);
                   //check for prevent region down
                   checkWriteActionMemSize(transactionId, state, RSConstants.MEMORY_ALLOC_AMPLIFICATION_FACTOR);
                  // Need to rebuild the edit list.
                  state.clearEdit();
                  if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
  		    tmpTime = System.currentTimeMillis();
	    	    time3_2 = tmpTime - preTime;
                  }
                  state.rebuildEdits();
                  if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
		    tmpTime = System.currentTimeMillis();
	    	    time3_3 = tmpTime - preTime;
                  }
                  if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
                      printMemoryUsage("commitRequest() - after Rebuild the edit list txid: " + transactionId);

               } else
                   checkWriteActionMemSize(transactionId, state, RSConstants.MEMORY_ALLOC_AMPLIFICATION_FACTOR - 1); // -1 for no copy WALEdit
                //txid = this.tHLog.appendNoSync(this.regionInfo, this.regionInfo.getTable(),
                //state.getEdit(), new ArrayList<UUID>(), TrxEnvironmentEdgeManager.currentTimeMillis(), this.m_Region.getTableDesc(),
                //nextLogSequenceId, false, HConstants.NO_NONCE, HConstants.NO_NONCE);

                if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0) {
                    printMemoryUsage("commitRequest() - before new WALKey, WALEdit size in state: "
                        + state.getEdit().heapSize() + " txid: " + transactionId);
                }

#ifdef CDH5.7 APACHE1.2 CDH5.16 
                WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(), 
                                             this.regionInfo.getTable(), 
                                             WALKey.NO_SEQUENCE_ID,
                                             TrxEnvironmentEdgeManager.currentTime(),
                                             WALKey.EMPTY_UUIDS,
                                             HConstants.NO_NONCE,
                                             HConstants.NO_NONCE,
                                             this.t_Region.getMVCC());                                       
#else
                final WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(),
                                          this.regionInfo.getTable(),
                                          TrxEnvironmentEdgeManager.currentTime());

#endif
                if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
                    printMemoryUsage("commitRequest() - after new WALKey txid: " + transactionId);
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
		  tmpTime = System.currentTimeMillis();
	    	  time3_4 = tmpTime - preTime;
                }

/* comment out after DWE fix, now the state.getEdit().getCells().size() should be 0 if there is no late checkin which generate edits after phase 1
        if (state.prepareEditSize != 0){
           if (LOG.isInfoEnabled()) LOG.info("commitRequest duplicate request for: " + state);
        }
        else {
           state.prepareEditSize = state.getEdit().getCells().size();
        }
*/        
        
        if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
  	  tmpTime = System.currentTimeMillis();
	  time3_5 = tmpTime - preTime;
        }
        state.resetEdit();
        WALEdit e2 = state.getPreparedEdit();
        //for each kv append a new binlog tag
        int myBinlogSalt = 0;

        if (useMC2) {
           if (mutationCapture2 == null) {
              mutationCapture2 = MutationCapture2.MC2_getInstance(this.config,
                           this.fs,
                           context,
                           regionInfo,
                           0, 1);
           }
           myBinlogSalt = mutationCapture2.getBinlogSaltNum();
        }

        //this is a good place to gen binlog
        //check the mode if it is max protection mode
        boolean doBinlogAppend = false;
        if(mutationCapture2.binlogIsMaxProtectionMode() && totalNum != -3)
        {
            if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
                printMemoryUsage("commitRequest() - before new tmBuilder txid: " + transactionId);
            if (LOG.isDebugEnabled()) LOG.debug("HBaseBinlog: it is maxProtectioMode for commit id " + state.getCommitId());
            doBinlogAppend = true;
            tmBuilder =  TransactionMutationMsg.newBuilder();
            tmBuilder.setTxId(transactionId);
            tmBuilder.setTableName(regionInfo.getTable().getNameAsString());
            tmBuilder.setStartId(0);
            tmBuilder.setCommitId(state.getCommitId());
            tmBuilder.setTableCDCAttr(0);
            tmBuilder.setTotalNum(totalNum);
            tmBuilder.setSplitSeq(1);
            if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
                printMemoryUsage("commitRequest() - after new tmBuilder txid: " + transactionId);
        }

        List<Tag> newTagList = new ArrayList<Tag>();

        int iPut = 0;
        int iDelete = 0;
        Tag binlogTag = null;
        Tag isUpsertTag = null;
        byte[] tagArray = null;

       long splitSeq = 0L;
       int msgCounter = 0;
       int msgSize = 0;
       if( doBinlogAppend == true ) {
          if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
              printMemoryUsage("commitRequest() - before doBinlogAppend txid: " + transactionId);
          for (WriteAction wa : state.getWriteOrdering()) {
            //TODO change the MAX_MSG_PER_MUTATION_MSG into a configurable param
            //TOOD instead of check number of rows, check the size of msg
            if(msgCounter >= 1000 || msgSize >= MutationCapture2.MAX_MSG_PER_MUTATION_MSG) {
               tmBuilder.setIsMsgComplete(false);
               mutationCapture2.binlog_append(tmBuilder, ATRConfig.SYNC_MODE_MAX_PROTECTION);
               tmBuilder =  TransactionMutationMsg.newBuilder();

               tmBuilder.setTxId(transactionId);
               tmBuilder.setTableName(regionInfo.getTable().getNameAsString());
               tmBuilder.setStartId(0);
               tmBuilder.setCommitId(state.getCommitId());
               tmBuilder.setTableCDCAttr(0);
               tmBuilder.setTotalNum(totalNum);

               splitSeq++;
               tmBuilder.setSplitSeq(splitSeq);

               //reset counter and continue loop
               iPut = 0;
               iDelete = 0;
               msgCounter = 0;
               msgSize = 0;
             }
             if (wa.getPut() != null) {
                 tmBuilder.addPutOrDel(true);
                 tmBuilder.addPut(ProtobufUtil.toMutation(MutationType.PUT, new Put(wa.getPut())));
                 iPut++;
             }
             else {
                if (! wa.getIgnoreDelete()){  // Don't apply delete if we subsequently have a put for the same key
                   tmBuilder.addPutOrDel(false);
                   tmBuilder.addDelete(ProtobufUtil.toMutation(MutationType.DELETE, new Delete(wa.getDelete())));
                   iDelete++;
                }
             }
             msgCounter++;
             msgSize += wa.getCellsMemSize();
          }// for wa

          try {
            if (LOG.isDebugEnabled()) {
                LOG.debug("HBaseBinlog: do binlogAppend in prepare phase");
            }
            splitSeq++;
            tmBuilder.setSplitSeq(splitSeq);
            mutationCapture2.binlog_append(tmBuilder, ATRConfig.SYNC_MODE_MAX_PROTECTION);
          }
          catch(IOException e) {
            state.setStatus(Status.ABORTED);
            retireTransaction(state, true);
            unLockRegionAll(transactionId);
            if (LOG.isInfoEnabled()) LOG.info("HBaseBinlog: commitRequest cannot append binlog for txId: "
                 + transactionId + " returning COMMIT_DOOMED due to binlog append failure");
            throw new CommitDoomedException("commitRequest encountered error txId: "
                 + transactionId + " returning COMMIT_DOOMED due to binlog append failure");
          }
          if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
              printMemoryUsage("commitRequest() - after doBinlogAppend txid: " + transactionId);
        }

        if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
	  tmpTime = System.currentTimeMillis();
	  time3_6 = tmpTime - preTime;
        }
        if (LOG.isDebugEnabled()) LOG.debug("commitRequest reconstruct WAL edit from ts, WALEdit size = " + e2.size());

/*      
                ArrayList<Cell> wkvs = state.getEdit().getCells();
                LOG.info("PH1 number of cells " + wkvs.size() + " for tid " + transactionId);
                 int wkvi = 0;
                 for (Cell wkv : state.getEdit().getCells()) {
                     LOG.info("PH1 cell " + wkvi +
                          " tag hex dump " + Hex.encodeHexString(wkv.getTagsArray()) + " tag offset " + wkv.getTagsOffset() + " tag len " + wkv.getTagsLength() +
                          " row hex dump " + Hex.encodeHexString(wkv.getRowArray()) + " row offset " + wkv.getRowOffset() + " row len " + wkv.getRowLength() +
                          " value hex dump " + Hex.encodeHexString(wkv.getValueArray()) + " value offset " + wkv.getValueOffset() + " value len " + wkv.getValueLength());                        
                     wkvi++;
                 }
*/              

                //TODO: apply memory point +6
                if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
                    printMemoryUsage("commitRequest() - before reconstruct WAL txid: " + transactionId);
#ifdef CDH5.7 APACHE1.2 CDH5.16
                //txid = this.tHLog.append(this.m_Region.getTableDesc(), this.regionInfo, wk, state.getEdit(), false);
                txid = this.tHLog.append(this.m_Region.getTableDesc(), this.regionInfo, wk, e2, false);
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
		  tmpTime = System.currentTimeMillis();
		  time3_7 = tmpTime - preTime;
                }
                writeEntry = wk.getWriteEntry();
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
		  tmpTime = System.currentTimeMillis();
		  time3_8 = tmpTime - preTime;
                }
                mvccNum = writeEntry.getWriteNumber();
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
		  tmpTime = System.currentTimeMillis();
		  time3_9 = tmpTime - preTime;
                }
        
                if ((m_isTrafodionMetadata) || 
                    (LOG.isTraceEnabled())) LOG.info("PH1 commitRequest COMMIT_OK -- EXIT "
                                                     + m_regionDetails
                                                     + " isTrafodionMD: " + m_isTrafodionMetadata
                                                     + " txId: " + transactionId
                                                     + " HLog seq: " + txid 
                                                     + " regionTx: " + state.getIsRegionTx()
                                                     + " flushHLOG: " + flushHLOG
                                                     );
#else
                AtomicLong lv_seqid = this.m_Region.getSequenceId();
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
		  tmpTime = System.currentTimeMillis();
		  time3_10 = tmpTime - preTime;
                }
                txid = this.tHLog.append(this.m_Region.getTableDesc(),
                                         this.regionInfo, 
                                         wk,
//                                       state.getEdit(),
                                         e2,
                                         lv_seqid,
                                         false,
                                         null);
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
		  tmpTime = System.currentTimeMillis();
		  time3_7 = tmpTime - preTime;
                }
                if ((m_isTrafodionMetadata) || 
                    (LOG.isTraceEnabled())) LOG.info("PH1 commitRequest COMMIT_OK -- EXIT "
                                                     + m_regionDetails
                                                     + " isTrafodionMD: " + m_isTrafodionMetadata
                                                     + " txId: " + transactionId
                                                     + " seqId: " + lv_seqid
                                                     + " HLog seq: " + txid 
                                                     + " regionTx: " + state.getIsRegionTx()
                                                     + " flushHLOG: " + flushHLOG
                                                     );
#endif
                if (flushHLOG) WALSync(tHLog, transactionId, txid);
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                  tmpTime = System.currentTimeMillis();
  		  time3 = tmpTime - preTime;
                  preTime = tmpTime;
                }
            if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
                printMemoryUsage("commitRequest() - after reconstruct WAL txid: " + transactionId);
            }
            else {
                if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
                    printMemoryUsage("commitRequest() - before WALSync txid: " + transactionId);
                 if (flushHLOG) WALSync(tHLog, transactionId, state.getFlushTxId());
                 if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                   tmpTime = System.currentTimeMillis();
                   time4 = tmpTime - preTime;
                   preTime = tmpTime;
                 }
                if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
                    printMemoryUsage("commitRequest() - after WALSync txid: " + transactionId);
            }

#ifdef CDH5.7 APACHE1.2 CDH5.16
           if (writeEntry != null) {
               this.t_Region.getMVCC().completeAndWait(writeEntry);
               writeEntry = null;
           }
#endif
        
            if (this.txnStatisticsCollection > 0) { //LOG.isInfoEnabled()) {
                     writeToLogEndTime = System.nanoTime();
                     writeToLogTimes[lv_timeIndex] = writeToLogEndTime - commitCheckEndTime;
                    writeToLogOperations.getAndIncrement();
            }
            //if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor:commitRequest COMMIT_OK -- EXIT txId: "
            // + transactionId + " regionTx: " + state.getIsRegionTx() + " HLog seq " + txid);
      } catch (IOException exp) {
          exp.fillInStackTrace();
          LOG.error("commitRequest txId: " + transactionId + " HLog seq " + txid + " Caught IOException in HLOG operations", exp );
#ifdef CDH5.7 APACHE1.2 CDH5.16
          if (writeEntry != null) {
              this.t_Region.getMVCC().completeAndWait(writeEntry);
              writeEntry = null;
          }
#endif
          synchronized (commitCheckLock) {
            state.setStatus(Status.ABORTED);
            retireTransactionAndWriteAbortWal(state);
          }
          try {unLockRegionAll(transactionId);} catch (Exception e) {}
          throw exp;
      }
 
#ifdef CDH5.7 APACHE1.2 CDH5.16
      finally {
               if (writeEntry != null) {
                   this.t_Region.getMVCC().completeAndWait(writeEntry);
                   writeEntry = null;
               }          
      } // finally
#endif

      if (LOG.isDebugEnabled()) LOG.debug("commitRequest COMMIT_OK -- EXIT txId: "
            + transactionId + " regionTx " + state.getIsRegionTx()
            + " Participant " + participantNum);

      if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
        tmpTime = System.currentTimeMillis();
        time5 = tmpTime - preTime;
        preTime = tmpTime;
      }
    }
    // No write pending
    else {
      readonlyparticipate = true;
      if (this.txnStatisticsCollection > 0) // LOG.isInfoEnabled())
        writeToLogTimes[lv_timeIndex] = 0;
    }

    //check for prevent region down
    try {
      checkWriteActionMemSize(transactionId, state, RSConstants.MEMORY_ALLOC_AMPLIFICATION_FACTOR);
    } catch (IOException exp) {
      LOG.error("commitRequest() - end commitRequest txId: " + transactionId + " Caught IOException in memory-check operations", exp );
      synchronized (commitCheckLock) {
        state.setStatus(Status.ABORTED);
        retireTransactionAndWriteAbortWal(state);
      }
      try {unLockRegionAll(transactionId);} catch (Exception e) {}
      throw exp;
    }

    if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
      printMemoryUsage("commitRequest() - end commitRequest txid: " + transactionId);

    synchronized (commitCheckLock) {
      if (onlineBalance.get() == true) {
        state.setStatus(Status.ABORTED);
        retireTransactionAndWriteAbortWal(state);
        try {
          unLockRegionAll(transactionId);
        } catch (Exception e) {}
        return COMMIT_UNSUCCESSFUL_FROM_COPROCESSOR;
      } else {
        // Order is important
        state.setDropTableRecorded(dropTableRecorded);
        state.setStatus(Status.COMMIT_PENDING);
        state.setCPEpoch(controlPointEpoch.get());
        // Must set the sequence in the state before adding to CPL
        state.setSequenceNumber(nextSequenceId.get());
        commitPendingTransactions.add(state);
        nextSequenceId.getAndIncrement();
        commitedTransactionsBySequenceNumber.put(state.getSequenceNumber(), state);
        recordCommitPendingTxForLock(transactionId);
        returnPending = true;
      }
    }

    if (this.txnStatisticsCollection > 0) { // LOG.isInfoEnabled()) {
      commitCheckTimes[lv_timeIndex] = commitCheckEndTime - commitCheckStartTime;
      hasConflictTimes[lv_timeIndex] = hasConflictEndTime - hasConflictStartTime;
      putBySequenceTimes[lv_timeIndex] = putBySequenceEndTime - putBySequenceStartTime;
      totalCommitCheckTime += commitCheckTimes[lv_timeIndex];
      totalConflictTime += hasConflictTimes[lv_timeIndex];
      totalPutTime += putBySequenceTimes[lv_timeIndex];
      totalWriteToLogTime += writeToLogTimes[lv_timeIndex];
      if (commitCheckTimes[lv_timeIndex] > maxCommitCheckTime) {
         maxCommitCheckTime = commitCheckTimes[lv_timeIndex];
      }
      if (commitCheckTimes[lv_timeIndex] < minCommitCheckTime) {
         minCommitCheckTime = commitCheckTimes[lv_timeIndex];
      }
      if (hasConflictTimes[lv_timeIndex] > maxConflictTime) {
         maxConflictTime = hasConflictTimes[lv_timeIndex];
      }
      if (hasConflictTimes[lv_timeIndex] < minConflictTime) {
         minConflictTime = hasConflictTimes[lv_timeIndex];
      }
      if (putBySequenceTimes[lv_timeIndex] > maxPutTime) {
         maxPutTime = putBySequenceTimes[lv_timeIndex];
      }
      if (putBySequenceTimes[lv_timeIndex] < minPutTime) {
         minPutTime = putBySequenceTimes[lv_timeIndex];
      }
      if (writeToLogTimes[lv_timeIndex] > maxWriteToLogTime) {
         maxWriteToLogTime = writeToLogTimes[lv_timeIndex];
      }
      if (writeToLogTimes[lv_timeIndex] < minWriteToLogTime) {
         minWriteToLogTime = writeToLogTimes[lv_timeIndex];
      }

      if (lv_timeIndex == 49) {
         timeIndex.set(1);  // Start over so we do not exceed the array size
      }

      if (lv_totalCommits == 9999) {
       avgCommitCheckTime = (double) (totalCommitCheckTime/lv_totalCommits);
       avgConflictTime = (double) (totalConflictTime/lv_totalCommits);
       avgPutTime = (double) (totalPutTime/lv_totalCommits);
       avgWriteToLogTime = (double) ((double)totalWriteToLogTime/(double)lv_totalCommits);
       if(LOG.isDebugEnabled()) LOG.debug("commitRequest Report\n" +
                      "  Region: " + m_regionDetails + "\n" +
                      "                        Total commits: "
                         + lv_totalCommits + "\n" +
                      "                        commitCheckLock time:\n" +
                      "                                     Min:  "
                         + minCommitCheckTime / 1000 + " microseconds\n" +
                      "                                     Max:  "
                         + maxCommitCheckTime / 1000 + " microseconds\n" +
                      "                                     Avg:  "
                         + avgCommitCheckTime / 1000 + " microseconds\n" +
                      "                        hasConflict time:\n" +
                      "                                     Min:  "
                         + minConflictTime / 1000 + " microseconds\n" +
                      "                                     Max:  "
                         + maxConflictTime / 1000 + " microseconds\n" +
                      "                                     Avg:  "
                         + avgConflictTime / 1000 + " microseconds\n" +
                      "                        putBySequence time:\n" +
                      "                                     Min:  "
                         + minPutTime / 1000 + " microseconds\n" +
                      "                                     Max:  "
                         + maxPutTime / 1000 + " microseconds\n" +
                      "                                     Avg:  "
                         + avgPutTime / 1000 + " microseconds\n" +
                      "                                     Ops:  "
                         + putBySequenceOperations.get() + "\n" +
                      "                        writeToLog time:\n" +
                      "                                     Min:  "
                         + minWriteToLogTime / 1000 + " microseconds\n" +
                      "                                     Max:  "
                         + maxWriteToLogTime / 1000 + " microseconds\n" +
                      "                                     Avg:  "
                         + avgWriteToLogTime / 1000 + " microseconds\n" +
                      "                                     Ops:  "
                         + writeToLogOperations.get() + "\n\n");
                   totalCommits.set(0);
                   writeToLogOperations.set(0);
                   putBySequenceOperations.set(0);
                   totalCommitCheckTime    =    0;
                   totalConflictTime =    0;
                   totalPutTime      =    0;
                   totalWriteToLogTime     =    0;
                   minCommitCheckTime      =    1000000000;
                   maxCommitCheckTime      =    0;
                   avgCommitCheckTime      =    0;
                   minConflictTime   =    1000000000;
                   maxConflictTime   =    0;
                   avgConflictTime   =    0;
                   minPutTime        =    1000000000;
                   maxPutTime        =    0;
                   avgPutTime        =    0;
                   minWriteToLogTime =    1000000000;
                   maxWriteToLogTime =    0;
                   avgWriteToLogTime =    0;
                }
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                  tmpTime = System.currentTimeMillis();
                  time6 = tmpTime - preTime;
                  preTime = tmpTime;
                }
    } // end of LOG.Info

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      tmpTime = System.currentTimeMillis();
      if ((tmpTime - startTime) >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " commitRequest inner txID " + transactionId + " TC " + (tmpTime - startTime)
            + " time1 " + time1 + " time2 " + time2 + " time3 " + time3
      	    + " time4 " + time4 + " time5 " + time5 + " time6 " + time6
	    + " time3 [" + time3_1 + ", " + time3_2 + ", " + time3_3 + ", " 
	    + time3_4 + ", " + time3_5 + ",, " + time3_6 + ", " 
	    + time3_7 + ", " + time3_8 + ", " + time3_9 + ", " + time3_10 + "]");
	      }
    }
    if (returnPending || state.getNeverReadOnly()) {
      if (LOG.isDebugEnabled()) LOG.debug("commitRequest write complete for participant "
           + participantNum + " -- EXIT txId: " + transactionId + ", regionName " + m_regionDetails);

    if( readonlyparticipate == false )
      return COMMIT_OK;
    else
      return COMMIT_OK_READ_ONLY;
    }

    if (LOG.isDebugEnabled()) LOG.debug("commitRequest COMMIT_OK with no write order for participant "
       + participantNum + " -- EXIT txId: " + transactionId + ", regionName " + m_regionDetails);

    if( readonlyparticipate == false ) 
      return COMMIT_OK;
    else
      return COMMIT_OK_READ_ONLY;
  }

  /**
   * Determines if the transaction has any conflicts
   * @param TrxTransactionState state
   * @return boolean
   */
  private void checkConflict(final TrxTransactionState state)
                                        throws IOException {
    // Check transactions that were committed while we were running
      
    synchronized (commitedTransactionsBySequenceNumber) {
      for (long i = state.getStartSequenceNumber(); i < nextSequenceId.get(); i++)
      {
        TrxTransactionState other = commitedTransactionsBySequenceNumber.get(i);
        if (other == null) {
          continue;
        }

        if (LOG.isTraceEnabled()) LOG.trace("hasConflict state.getStartSequenceNumber  is " + i + ", nextSequenceId.get() is " + nextSequenceId.get() + ", state object is " + state.toString() + ", calling addTransactionToCheck");
        state.addTransactionToCheck(other);
      }
    }
    state.checkConflict();
    return;
  }

  /**
   * Abort the savepoint statement.
   *
   * @param transactionId
   * @param savepointId
   * @throws IOException
   * @throws UnknownTransactionException
   */
  public void abortSavepoint(final long transactionId, final long savepointId, final boolean ignoreUnknownTransaction) throws IOException, UnknownTransactionException {

    if (LOG.isTraceEnabled()) LOG.trace("abortSavepoint transactionId: " + transactionId
         + " savepointId: " + savepointId + " " + m_regionDetails);
    
    if (savepointId < 0) { // illegal savepointId
            LOG.error("Abort savepoint checkin with invalid savepoint id for tid " + transactionId + " svpt " + savepointId
                                        + " in region " + m_regionDetails);
            throw new IOException("Abort savepoint checkin with invalid savepoint id for tid " + transactionId + " svpt "
                    + savepointId + " in region " + m_regionDetails);                                        
    }    
    
    TrxTransactionState state;
    int error = INIT_SVPT_ERROR;
    
    try {
      state = getTransactionState(transactionId);
    } catch (UnknownTransactionException e) {

      unLockRegionAll(transactionId, savepointId);

      if (ignoreUnknownTransaction){
         if (LOG.isDebugEnabled()) LOG.debug("ignoring UnknownTransaction in abortSavepoint : " + transactionId
                + " savepointId: " + savepointId + " in region " + m_regionDetails);
         return;
      }
      IOException ioe = new IOException("UnknownTransactionException Unknown transaction [" + transactionId
                 + "] in region [" + m_regionDetails + "] ");
      LOG.error("abortSavepoint", ioe);
      throw ioe;
    }
    
    // intend Savepoint Checkin  
    error = state.savepointCheckin(savepointId, SavepointOp.ABORT_SVPT_OP);
    
    if (error < 0) {
         throw new IOException("Savepoint checkin error " + error + " on tid " + transactionId + " svpt " + savepointId + 
                    " op ABORT_SVPT_OP " + SavepointOp.ABORT_SVPT_OP + " in region " + m_regionDetails);
    }                        
    else if (error == OK_SVPT_ERROR) { // successful Savepoint Checkin
        try {
           // Extension: can do extra stuff here (e.g. pre-prepare a statement)
           state.rollbackSavepoint(savepointId);
           state.setSavepointContextState(savepointId, SavepointState.ACTIVE_SVPT_STATE);
        }
        finally {
           //Savepoint Checkout
           state.savepointCheckout(savepointId, SavepointOp.ABORT_SVPT_OP);  
        }
    }
        
    // when error > 0, e.g. 1, implies duplicate abort savepoint req, likely from multiple ESP, just ignore since no checkin is made
    
    if (LOG.isTraceEnabled()) LOG.trace("abortSavepoint -- EXIT txId: " + transactionId + " savepointId " + savepointId);
    unLockRegionAll(transactionId, savepointId);

  }

  public void abortTransaction(final long transactionId) throws IOException, UnknownTransactionException {
      abortTransaction(transactionId, false, false);
  }

  /**
   * Abort the transaction.
   * 
   * @param transactionId
   * @throws IOException
   * @throws UnknownTransactionException
   */
  public void abortTransaction(final long transactionId, final boolean dropTableRecorded, final boolean ignoreUnknownTransaction) throws IOException, UnknownTransactionException {
    long txid = 0;
    long time1 = 0, time2 = 0, time3 = 0, time4 = 0, time5 = 0, time6 = 0, time7 = 0, time8 = 0, time9 = 0, time10 = 0;
    long tmpTime = 0, preTime = 0, startTime = System.currentTimeMillis();
#ifdef CDH5.7 APACHE1.2 CDH5.16
    MultiVersionConcurrencyControl.WriteEntry writeEntry = null;
    long mvccNum = 0;
#endif
    
    if (LOG.isTraceEnabled()) LOG.trace("abort transactionId: " + transactionId + " " + m_regionDetails);

    if (ignoreUnknownTransaction){
       if (LOG.isDebugEnabled()) LOG.debug("ignoring UnknownTransaction in abortTransaction : " + transactionId
              + " in region " + m_regionDetails);
    }

    TrxTransactionState state;
    try {
      state = getTransactionState(transactionId);

      //early release of for-update lock
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK) {
        List<ByteArrayKey> locksToRemove = state.listOfLockedRowsSelForUpdate;

        synchronized(selectForUpdateLockHashmap){
          for(int i=0; i< locksToRemove.size(); i++)
          {
            ByteArrayKey rowInHex = locksToRemove.get(i);

            selectForUpdateLockHashmap.remove(rowInHex);
            if(selectForUpdateLockWaitQueue.containsKey(rowInHex) && enableUseWaitQueue == true)
            {
               List<Long> waitTrxList = selectForUpdateLockWaitQueue.get(rowInHex);
               if(waitTrxList.size() == 0)
                 selectForUpdateLockWaitQueue.remove(rowInHex);
            }
          }
        }
        state.clearSelForUpdLocks();
        state.clearInsRowsForUpdate();
      }
    } catch (UnknownTransactionException e) {

      unLockRegionAll(transactionId);

      if (ignoreUnknownTransaction) {        
            if (LOG.isInfoEnabled()) LOG.info("ignoring UnknownTransaction in abortTransaction : " + transactionId
                + " CPL " + commitPendingTransactions.size() + " IDT " + indoubtTransactionsById.size()
                + " region state " + regionState.intValue() + " in region " + m_regionDetails);
         
           if (regionState.intValue() == REGION_STATE_RECOVERING) {
              synchronized(indoubtTransactionsById) {
                  indoubtTransactionsById.remove(transactionId);
                  if (LOG.isInfoEnabled()) LOG.info("Trafodion Endpoint: remove indoubtTransactionsById " + transactionId 
                     + " CPL " + commitPendingTransactions.size() + " IDT " + indoubtTransactionsById.size()
                     + " region " + m_regionName);
               }
               if (indoubtTransactionsById.size() == 0) regionState.set(REGION_STATE_START); 
            }

         TrxTransactionState ts1 = null;
         synchronized(commitPendingTransactions) {
            for (TrxTransactionState commitPendingTS : commitPendingTransactions) {
                   if (commitPendingTS.getTransactionId() == transactionId) {
                       ts1 = commitPendingTS;
                       break;
                   }
            }
            if (ts1 != null) {
               if (LOG.isWarnEnabled()) {
                   LOG.warn("Trafodion Endpoint: Find ts in CPL but not in TransactionsById " + transactionId
                                     + " ts " + ts1.toString());
               }
               if (commitPendingTransactions.remove(ts1)) {
                     if (LOG.isInfoEnabled()) LOG.info("Trafodion Endpoint: remove commitPendingTransactions " + transactionId
                         + " CPL " + commitPendingTransactions.size() + " IDT " + indoubtTransactionsById.size()
                         + " region " + m_regionName);
               }
               else { 
                     if (LOG.isInfoEnabled()) LOG.info("Trafodion Endpoint: not remove commitPendingTransactions " + transactionId
                       + " CPL " + commitPendingTransactions.size() + " IDT " + indoubtTransactionsById.size()
                       + " region " + m_regionName);
               }
            } // ts1 != null
         } // sync
         return;
      }
      IOException ioe = new IOException("UnknownTransactionException Unknown transaction [" + transactionId
                 + "] in region [" + m_regionDetails + "] ");
      LOG.error("abortTransaction", ioe);
      throw ioe;
    }

    synchronized(state.getXaOperationObject()) {
        if (state.getStatus().equals(Status.ABORTED)) { // already aborted, duplicate abort requested
            LOG.warn("abortTransaction - DUPLICATE abort transaction Id: " + transactionId + " " + m_regionDetails);
            return;
        }
    state.setStatus(Status.ABORTED);
    }

    if(dropTableRecorded)
        state.resetDropTableRecorded();

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      preTime = System.currentTimeMillis();
      time1 = preTime - startTime;
    }
    if (state.hasWrite()) {
    // TODO log
    //  this.transactionLog.writeAbortToLog(m_Region.getRegionInfo(),
    //                                      state.getTransactionId(),
    //                                    m_Region.getTableDesc());
       if (LOG.isTraceEnabled()) LOG.trace("abortTransaction - abort write to HLOG");
       Tag abortTag = state.formTransactionalContextTag(TS_ABORT, state.getStartId());
       List<Tag> tagList = new ArrayList<Tag>();
       tagList.add(abortTag);

      if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
          printMemoryUsage("abortTransaction() - before Hlog append txid: " + transactionId);

      WALEdit e1 = state.getEdit(); // don't use getPreparedEdit() since ABORT could hit active transaction
      WALEdit e = new WALEdit();

      if (state.endEditSize != 0){
         if (LOG.isInfoEnabled()) LOG.info("abort duplicate request for: " + state);
      }
      else {
         state.endEditSize = 1;
      }

      if (e1.getCells().size() <= 0) { // construct a fake edit for ABORT RM branch state record
         if (LOG.isDebugEnabled()) LOG.debug("Savepoint Info: transaction with wa but no edit detected, abort w/o prev abortSavepoint caused: tid " + transactionId);
         e1 = state.editConstructFirstWriteAction();
      }

      if (e1.getCells().size() > 0) {
         // get 1st Cell to associated with the abort record as a workaround through HLOG async append
         Cell c = e1.getCells().get(0);
         KeyValue kv = new KeyValue(c.getRowArray(), c.getRowOffset(), (int)c.getRowLength(),
         c.getFamilyArray(), c.getFamilyOffset(), (int)c.getFamilyLength(),
         c.getQualifierArray(), c.getQualifierOffset(), (int) c.getQualifierLength(),
         c.getTimestamp(), Type.codeToType(c.getTypeByte()), c.getValueArray(), c.getValueOffset(),
         c.getValueLength(), tagList);
      
         e.add(kv);
         if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
           tmpTime = System.currentTimeMillis();
           time2 = tmpTime - preTime;
           preTime = tmpTime;
         }
         try {
             //txid = this.tHLog.appendNoSync(this.regionInfo, this.regionInfo.getTable(),
             //     e, new ArrayList<UUID>(), TrxEnvironmentEdgeManager.currentTimeMillis(), this.m_Region.getTableDesc(),
             //     nextLogSequenceId, false, HConstants.NO_NONCE, HConstants.NO_NONCE);

#ifdef CDH5.7 APACHE1.2 CDH5.16	
		WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(), 
					     this.regionInfo.getTable(), 
					     WALKey.NO_SEQUENCE_ID,
					     TrxEnvironmentEdgeManager.currentTime(),
					     WALKey.EMPTY_UUIDS,
					     HConstants.NO_NONCE,
					     HConstants.NO_NONCE,
					     this.t_Region.getMVCC());	
					     
                 txid = this.tHLog.append(this.m_Region.getTableDesc(), this.regionInfo, wk, e, false);
		 writeEntry = wk.getWriteEntry();
		 mvccNum = writeEntry.getWriteNumber();					     
#else
		final WALKey wk = new WALKey(this.regionInfo.getEncodedNameAsBytes(),
					  this.regionInfo.getTable(),
					  TrxEnvironmentEdgeManager.currentTime());

       	 	 txid = this.tHLog.append(this.m_Region.getTableDesc(),
					  this.regionInfo, 
					  wk , 
					  e,
					  this.m_Region.getSequenceId(), 
					  false,
					  null);
#endif
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                  tmpTime = System.currentTimeMillis();
                  time3 = tmpTime - preTime;
                  preTime = tmpTime;
                }
                WALSync(tHLog, transactionId, txid);
                if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
                  tmpTime = System.currentTimeMillis();
                  time4 = tmpTime - preTime;
                  preTime = tmpTime;
                }
        WALSync(tHLog, transactionId, txid);

#ifdef CDH5.7 APACHE1.2 CDH5.16
		if (writeEntry != null) {
		    this.t_Region.getMVCC().completeAndWait(writeEntry);
		    writeEntry = null;
		}
#endif
             if (LOG.isTraceEnabled()) LOG.trace("write abort HLOG " + transactionId + " HLog seq " + txid);
         
             if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0) {
                 printMemoryUsage("abortTransaction() - before Hlog append 3 txid: " + transactionId);
                 LOG.info("[MEM] abortTransaction() - before Hlog append 3 WALEdit size " + e.heapSize() + " txid: " + transactionId);
             }
         }
         catch (IOException exp1) {
           LOG.error("abortTransaction - abort writing to HLOG : Caught an exception ", exp1);
           state.setStatus(Status.DOOMED);
           throw exp1;
          }
#ifdef CDH5.7 APACHE1.2 CDH5.16
	  finally {
	       if (writeEntry != null) {
                   this.t_Region.getMVCC().completeAndWait(writeEntry);
                   writeEntry = null;
	       }	  
	  } // finally
#endif
          if (LOG.isTraceEnabled()) LOG.trace("abortTransaction -- EXIT txId: " + transactionId + " HLog seq " + txid);
          if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
            tmpTime = System.currentTimeMillis();
            time5 = tmpTime - preTime;
            preTime = tmpTime;
          }
      }
    }

    synchronized (commitPendingTransactions) {
     //commitPendingTransactions.remove(state);
         if (!commitPendingTransactions.remove(state)) {
            if (LOG.isDebugEnabled()) LOG.debug("abort -" + " txid: " + transactionId
                + " regionTx: " + state.getIsRegionTx() + ", Aborting a non-prepared transaction branch in region "
                + m_regionDetails);
         }                           
         if (drainMC2Request) {
             drainCPL.remove(state); // remove the state from drain list, when it is empty, the wait completes
             if (LOG.isDebugEnabled()) LOG.debug("PIT CDC: remain waiting-to-drain CPL size " + drainCPL.size());
         } // only when there is a pending flush-close MC (backup or restore) req waiting on draing all the prepared branches		 
    }
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      tmpTime = System.currentTimeMillis();
      time6 = tmpTime - preTime;
      preTime = tmpTime;
    }

    if (state.isReinstated()) {
      synchronized(indoubtTransactionsById) {
        if (LOG.isTraceEnabled()) LOG.trace("Trafodion Recovery: abort reinstated indoubt transactions " + transactionId);
        indoubtTransactionsById.remove(state.getTransactionId());
        int clusterid = (int) state.getClusterId();
        int tmid = (int) state.getNodeId();

        if (  (clusterid != pSTRConfig.getTrafClusterIdInt())  ) tmid = -2; // for any peer

        int count = 0;

        // indoubtTransactionsCountByTmid protected by 
        // indoubtTransactionsById synchronization
        if (indoubtTransactionsCountByTmid.containsKey(tmid)) {
            count =  (int) indoubtTransactionsCountByTmid.get(tmid) - 1;
            if (count > 0) indoubtTransactionsCountByTmid.put(tmid, count);
        }

        if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
          tmpTime = System.currentTimeMillis();
          time7 = tmpTime - preTime;
          preTime = tmpTime;
        }
        // if all reinstated txns are resolved from a TM, remove it and delete associated zNode
        if (count == 0) {
          indoubtTransactionsCountByTmid.remove(tmid);
          String lv_encoded = m_Region.getRegionInfo().getEncodedName();
          try {
            if (LOG.isTraceEnabled()) LOG.trace("Trafodion Recovery: delete in abort recovery zNode TM " + tmid + " region encoded name " + lv_encoded + " for 0 in-doubt transaction");
            deleteRecoveryzNode(tmid, lv_encoded);
          } catch (IOException e) {
             LOG.error("Trafodion Recovery: delete recovery zNode failed ", e);
          }
         }

         if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
           tmpTime = System.currentTimeMillis();
           time8 = tmpTime - preTime;
           preTime = tmpTime;
         }
         if ((indoubtTransactionsById == null) || 
             (indoubtTransactionsById.size() == 0)) {
           // change region state to STARTED, and archive the split-thlog

           if (indoubtTransactionsById == null)
             if (LOG.isTraceEnabled()) LOG.trace("Trafodion Recovery: start region in abort with indoubtTransactionsById null");
            else
              if (LOG.isTraceEnabled()) LOG.trace("Trafodion Recovery: start region in abort with indoubtTransactionsById size " + indoubtTransactionsById.size());
            startRegionAfterRecovery();
         }
         if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
           tmpTime = System.currentTimeMillis();
           time9 = tmpTime - preTime;
           preTime = tmpTime;
         }
       }
     }

   retireTransaction(state, true);
   if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
     tmpTime = System.currentTimeMillis();
     time10 = tmpTime - preTime;
     if ((tmpTime - startTime) >= RSConstants.RECORD_TIME_COST_COPRO)
         if (LOG.isWarnEnabled()) {
             LOG.warn(m_regionName + " abortTransaction inner txID " + transactionId + " TC " + (tmpTime - startTime) + " time1 " + time1 + " time2 " + time2 + " time3 " + time3 + " time4 " + time4 + " time5 " + time5
              + " time6 " + time6 + " time7 " + time7 + " time8 " + time8 + " time9 " + time9 + " time10 " + time10);
         }
   }

   if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & ABORT_LOG_MARK) > 0) 
       LOG.info("abortTransaction looking for abort transaction " + transactionId + ", transactionsById " + transactionsById.size() + ", commitedTransactionsBySequenceNumber " + commitedTransactionsBySequenceNumber.size() + ", commitPendingTransactions" + commitPendingTransactions.size());

   unLockRegionAll(transactionId);
   }

  /**
   * Determines if the transaction can be committed, and if possible commits the transaction.
   * @param long transactionId
   * @return boolean
   * @throws IOException
   */
  public boolean commitIfPossible(final long transactionId, final long startEpoch, final long commitId, final int participantNum, final int tmTableCDCAttr, final short totalNum)
                 throws IOException {

     return commitIfPossible(transactionId, startEpoch, commitId, participantNum, tmTableCDCAttr,
            /* regionTx */ false, /* autoCommit */ true, false, totalNum);
  }
  /**
   * Determines if the transaction can be committed, and if possible commits the transaction.
   * @param long transactionId
   * @return boolean
   * @throws IOException
   */
  public boolean commitIfPossible(final long transactionId, final long startEpoch, final long commitId, final int participantNum,
                                  final int tmTableCDCAttr, final boolean regionTx, final boolean autoCommit, boolean skipcc, final short totalNum) throws IOException {

    long time1 = System.currentTimeMillis(), time2 = 0, time3 = 0;
    if (LOG.isTraceEnabled()) LOG.trace("commitIfPossible -- ENTRY txId: "
               + transactionId);

    checkBlockNonPhase2(transactionId);

    int status = commitRequest(transactionId, skipcc, startEpoch, participantNum);
    
    if (! autoCommit) {
       boolean result = ( status == COMMIT_OK || status == COMMIT_OK_READ_ONLY) ? true : false;
       if (LOG.isTraceEnabled()) LOG.trace("commitIfPossible -- autoCommit is false, returning early with result " + result);
       return result;
    }
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0)
      time2 = System.currentTimeMillis(); 
    if (status == COMMIT_OK) {

       // Process local memory
       try {
         commit(transactionId, commitId, participantNum, tmTableCDCAttr, totalNum, 0);
         if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor: commitIfPossible -- EXIT txId: " + transactionId + " COMMIT_OK");
         if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
           time3 = System.currentTimeMillis();
           if ((time3 - time1) >= RSConstants.RECORD_TIME_COST_COPRO) {
               if (LOG.isWarnEnabled()) {
                   LOG.warn(m_regionName + " commitIfPossible inner TC " + (time3 - time1) + " time1 " + (time2 - time1) + " time2 " + (time3 - time2));
               }
           }
         }
         return true;
       } catch (Throwable e) {
        if (LOG.isWarnEnabled()) LOG.warn("commitIfPossible - txId " + transactionId
               + ", Caught exception ", e);
        throw new IOException(e.toString());
       }
    } else if (status == COMMIT_OK_READ_ONLY) {
            if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor: commitIfPossible -- EXIT txId: " 
            + transactionId + " COMMIT_OK_READ_ONLY");
            return true;
    }
    if (LOG.isTraceEnabled()) LOG.trace("TrxRegionEndpoint coprocessor: commitIfPossible -- EXIT txId: " 
              + transactionId + " Commit Unsuccessful");
    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      time3 = System.currentTimeMillis();
      if ((time3 - time1) >= RSConstants.RECORD_TIME_COST_COPRO) {
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " commitIfPossible inner txID " + transactionId + " TC " + (time3 - time1) + " time1 " + (time2 - time1) + " time2 " + (time3 - time2));
          }
      }
    }
    return false;
  }
  
  /**
   * Formats a cleanup message for a Throwable
   * @param Throwable t
   * @param String msg
   * @return Throwable
   */
  private Throwable cleanup(final Throwable t, final String msg) {
    if (t instanceof NotServingRegionException) {
      if (LOG.isTraceEnabled()) LOG.trace("cleanup - NotServingRegionException; " +  t.getMessage());
      return t;
    }
    if (msg == null) {
      LOG.error("cleanup - cleanup message was null");
    } else {
      LOG.error("cleanup - cleanup message was " + msg);
    }
    return t;
  }

  private IOException convertThrowableToIOE(final Throwable t) {
    return convertThrowableToIOE(t, null);
  }

  /*
   * @param t
   *
   * @param msg Message to put in new IOE if passed <code>t</code>
   * is not an IOE
   *
   * @return Make <code>t</code> an IOE if it isn't already.
   */
   private IOException convertThrowableToIOE(final Throwable t, final String msg) {
     return (t instanceof IOException ? (IOException) t : msg == null
      || msg.length() == 0 ? new IOException(t) : new IOException(msg, t));
  }

  /**
   * Checks if the file system is available       
   * @return boolean
   */
  public boolean checkFileSystem() {
    if (this.fs != null) {
      try {
        FSUtils.checkFileSystemAvailable(this.fs);
      } catch (IOException e) {
        LOG.error("checkFileSystemAvailable - File System not available threw IOException ", e);
        return false;
      }
    }
    return true;
  }

  /**
   * Prepares the family keys if the scan has no families defined
   * @param Scan scan
   * @throws IOException
   */
  public void prepareScanner(Scan scan) throws IOException {
    if(!scan.hasFamilies()) {
      for(byte[] family: this.m_Region.getTableDesc().getFamiliesKeys()){
           scan.addFamily(family);
      }
    }
  }

  /**
   * Checks if the row is within this region's row range
   * @param byte[] row  
   * @param String op
   * @throws IOException
   */
  public void checkRow(final byte [] row, String op) throws IOException {
#ifdef APACHE1.2 CDH5.7 CDH5.16
    if(!rowIsInRange(this.regionInfo, row)) {
#else
    if(!this.m_Region.rowIsInRange(this.regionInfo, row)) {
#endif
       throw new WrongRegionException("Requested row out of range for " +
       op + " on HRegion " + this + ", startKey='" +
       Bytes.toStringBinary(this.regionInfo.getStartKey()) + "', getEndKey()='" +
       Bytes.toStringBinary(this.regionInfo.getEndKey()) + "', row='" +
       Bytes.toStringBinary(row) + "'");
    }
  }

  /**
   * Returns the scanner associated with the specified ID.
   *
   * @param long scannerId
   * @param long nextCallSeq
   * @return a Scanner or throws UnknownScannerException
   * @throws NotServingRegionException
   * @throws OutOfOrderscannerNextException
   * @throws UnknownScannerException
   */
    protected synchronized RegionScanner getScanner(long scannerId,
                                                    long nextCallSeq)  
      throws NotServingRegionException,
             OutOfOrderScannerNextException,
             UnknownScannerException {

      RegionScanner scanner = null;

      if (LOG.isTraceEnabled()) LOG.trace("getScanner - scanner id " + scannerId + ", count is "  + scanners.size());

      TransactionalRegionScannerHolder rsh = 
        scanners.get(scannerId);

      if (rsh != null)
      {
        if (LOG.isTraceEnabled()) LOG.trace(" getScanner - rsh is " + rsh + "rsh.s is "  + rsh.s );
      } else if (scannerId == -1) {
          return scanner;
      } else
      {
        if (LOG.isTraceEnabled()) LOG.trace(" getScanner - rsh is null");
          throw new UnknownScannerException(
            "TrxRegionEndpoint getScanner - scanner id " + scannerId + " nextCallSeq " + nextCallSeq + ", already closed? in region " + m_regionDetails);
      }

      scanner = rsh.s;
      if (scanner != null) {
        if (this.m_Region != rsh.r) { // Yes, should be the same instance
          HRegionInfo hri = scanner.getRegionInfo();
          throw new NotServingRegionException("Region was re-opened after the scannerId"
            + scannerId + " was created: " + hri.getRegionNameAsString());
        }
      }

      if (nextCallSeq != rsh.nextCallSeq) {
        if (LOG.isTraceEnabled()) LOG.trace("getScanner - scanner id " + scannerId + ", calling OutOfOrderScannerNextException, nextCallSeq is " + nextCallSeq + " rsh.nextCallSeq is " + rsh.nextCallSeq);
        throw new OutOfOrderScannerNextException(
        "TrxRegionEndpoint coprocessor: getScanner - scanner id " + scannerId + ", Expected nextCallSeq: " + rsh.nextCallSeq +
        ", But the nextCallSeq received from client: " + nextCallSeq + " in region " + m_regionDetails);
      }

      return scanner;
    }

  /**
   * Removes the scanner associated with the specified ID from the internal
   * id->scanner TransactionalRegionScannerHolder map
   *
   * @param long scannerId
   * @return a Scanner or throws UnknownScannerException
   * @throws UnknownScannerException
   */
    protected synchronized RegionScanner removeScanner(long scannerId) 
      throws UnknownScannerException {

      if (LOG.isTraceEnabled()) LOG.trace("removeScanner - scanner id " + scannerId + ", before count is "  + scanners.size() + " in region " + m_regionDetails);
      if (scannerId < 0) {
          return null;
      }
      TransactionalRegionScannerHolder rsh = 
        scanners.remove(scannerId);
      if (LOG.isTraceEnabled()) LOG.trace("removeScanner - scanner id " + scannerId + ", after count is "  + scanners.size());
      if (rsh != null)
      {
        if (LOG.isTraceEnabled()) LOG.trace("removeScanner - scanner id " + scannerId + ", rsh is " + rsh + ", rsh.s is " + rsh.s );
        RegionScanner s = rsh.s;
        rsh.cleanHolder();
        return s;
      }
      else
      {
        if (LOG.isTraceEnabled()) LOG.trace("removeScanner - scanner id " + scannerId + ", rsh is null");
          throw new UnknownScannerException(
            "ScannerId: " + scannerId + ", already closed? in region " + m_regionDetails);
      }
    }

  /**
   * Adds a region scanner to the TransactionalRegionScannerHolder map
   * @param RegionScanner s
   * @param HRegion r       
   * @return long 
   * @throws LeaseStillHeldException 
   */
#ifdef APACHE1.2 CDH5.7 CDH5.16 
  protected synchronized long addScanner(long transId, RegionScanner s, Region r,  Object[] checkResult)
#else 
  protected synchronized long addScanner(long transId, RegionScanner s, HRegion r,  Object[] checkResult)
#endif
     throws LeaseStillHeldException {
    long scannerId = performScannerId.getAndIncrement();

    TransactionalRegionScannerHolder rsh = 
      new TransactionalRegionScannerHolder(transId, scannerId, s, r, ((Boolean)checkResult[1]).booleanValue());

    if (rsh != null) {
      rsh.scanType = ((Integer)checkResult[0]).intValue();
      rsh.ok_locked = ((Boolean)checkResult[2]).booleanValue();
      if (LOG.isTraceEnabled()) LOG.trace("addScanner - scanner id " + scannerId + " in region " + m_regionDetails
             + ", rsh is " + rsh);
    }
    else {
      if (LOG.isTraceEnabled()) LOG.trace("addScanner - scanner id " + scannerId + " in region " + m_regionDetails
             + ", rsh is null");
    }
    TransactionalRegionScannerHolder existing =
      scanners.putIfAbsent(scannerId, rsh);

    if (LOG.isTraceEnabled()) LOG.trace("addScanner - scanner id " + scannerId + " transId " + transId
                   + ", count is " + scanners.size() + " in region " + m_regionDetails);

/*
    scannerLeases.createLease(getScannerLeaseId(scannerId),
                              TrxRegionEndpoint.scannerLeaseTimeoutPeriod,
                              new TransactionalScannerListener(scannerId));
*/

    return scannerId;
  }

/**
 *    * Instantiated as a scanner lease. If the lease times out, the scanner is
 *       * closed
 *          */
/*
  private class TransactionalScannerListener implements LeaseListener {
    private final long scannerId;

    TransactionalScannerListener(final long id) {
      this.scannerId = id;
    }

    @Override
    public void leaseExpired() {
      TransactionalRegionScannerHolder rsh = scanners.remove(this.scannerId);
      if (rsh != null) {
        RegionScanner s = rsh.s;
        if (LOG.isWarnEnabled()) LOG.warn("Scanner " + this.scannerId + " lease expired on region "
            + s.getRegionInfo().getRegionNameAsString());
        try {
          HRegion region = rsh.r;

          s.close();
        } catch (IOException e) {
          LOG.error("Closing scanner for "
              + s.getRegionInfo().getRegionNameAsString(), e);
        }
      } else {
        if (LOG.isTraceEnabled()) LOG.trace("Scanner " + this.scannerId + " lease expired");
      }
    }
  }
*/

  /**
   * Formats the throwable stacktrace to a string
   * @param Throwable e
   * @return String 
   */
  public String stackTraceToString(Throwable e) {
    StringBuilder sb = new StringBuilder();
    for (StackTraceElement element : e.getStackTrace()) {
        sb.append(element.toString());
        sb.append("\n");
    }
    return sb.toString();
  }

  /**
   * Returns the Scanner Leases for this coprocessor                       
   * @return Leases 
   */
     //synchronized protected Leases getScannerLeases() {
      //  return this.scannerLeases;
    //}

  /**
   * Returns the Leases for this coprocessor                               
   * @return Leases 
   */
     synchronized protected Leases getTransactionalLeases() {
        return TrxRegionEndpoint.transactionLeases;
    }

  synchronized public void removeInDoubtForUpdateLocks() {
    //compare the previous locks with current locks 
    // any lock still there will be removed
    List<Long> prevTrans = new ArrayList<Long> (prevSelectForUpdateLockHashmap.values());
    List<Long> currTrans = new ArrayList<Long> (selectForUpdateLockHashmap.values());
    TrxTransactionState state = null;

    prevTrans = new ArrayList<>(new HashSet<>(prevTrans));
    currTrans = new ArrayList<>(new HashSet<>(currTrans));
   
    for(long pv : prevTrans) {
      if(currTrans.contains(pv) == true) //it is still there
      {
         int j=0;
         int howlong = 0;
         for (Map.Entry<Long, Integer> item : longTransHavingLocks.entrySet()){
            j++;
            if(pv == item.getKey()) 
            {
              howlong = item.getValue();
              howlong++;
              break;
            }
        }

        if(howlong > 0)
          longTransHavingLocks.put(pv,howlong);
        else
        {
           longTransHavingLocks.put(pv,1);
        }
      }
    } 

    //go through the longTransHavingLocks

    for (Iterator<Map.Entry<Long, Integer>> it = longTransHavingLocks.entrySet().iterator(); it.hasNext();){
      Map.Entry<Long, Integer> entry = it.next();
      long tid = entry.getKey();
      if(currTrans.contains(tid) == false)
      {
        it.remove();
        continue;
      }
      if (LOG.isWarnEnabled()) {
          LOG.warn("LOCKDBG: long time lock, tid " + tid + " hold lock for " + entry.getValue() + " times");
      }
      if( entry.getValue() > maxForUpdLockCheckTime )
      {
        //get the TrxTransactionState
        Long key = getTransactionalUniqueId(tid);
        TrxTransactionState state1 = null;
        synchronized (transactionsById) {
           state1 = transactionsById.get(key);
        }
        if (LOG.isWarnEnabled()) {
            LOG.warn("LOCKDBG: remove lock as GC operation for tid " + state1.getTransactionId() + ". Clear " +
                  state1.listOfLockedRowsSelForUpdate.size() + " row locks.");
        }
        for(int ii = 0; ii < state1.listOfLockedRowsSelForUpdate.size(); ii++)
        { 
          if (LOG.isDebugEnabled()) LOG.debug("LOCKDBG: in state lock list " + state1.listOfLockedRowsSelForUpdate.get(ii) + " now remove it as GC operation for tid " + state1.getTransactionId());
          synchronized(selectForUpdateLockHashmap){
             selectForUpdateLockHashmap.remove(state1.listOfLockedRowsSelForUpdate.get(ii));
             if(selectForUpdateLockWaitQueue.containsKey(state1.listOfLockedRowsSelForUpdate.get(ii)) && enableUseWaitQueue == true)
             {
               List<Long> waitTrxList = selectForUpdateLockWaitQueue.get(state1.listOfLockedRowsSelForUpdate.get(ii));
               if(waitTrxList.size() == 0) 
                 selectForUpdateLockWaitQueue.remove(state1.listOfLockedRowsSelForUpdate.get(ii));
              }
          } 
        }
        state1.clearSelForUpdLocks();
        it.remove();
      }
    }

    //clear prev
    prevSelectForUpdateLockHashmap.clear();    
    synchronized(selectForUpdateLockHashmap){
      for (Iterator<Map.Entry<ByteArrayKey, Long>> it = selectForUpdateLockHashmap.entrySet().iterator(); it.hasNext();) {
        Map.Entry<ByteArrayKey, Long> entry = it.next();
        prevSelectForUpdateLockHashmap.put(entry.getKey(), entry.getValue());
      }
    }
    long currentts = TrxEnvironmentEdgeManager.currentTime();

    Iterator iter = tmpWriteLockHashmap.entrySet().iterator();
    while(iter.hasNext())
    {
      Map.Entry<ByteArrayKey, trafLockInfo> entry = (Map.Entry<ByteArrayKey, trafLockInfo>) iter.next();
      trafLockInfo ti = entry.getValue();
      if( (currentts - ti.getTs() ) > MAX_TMP_WRITE_LOCK_LIVE_TIME * maxForUpdLockCheckTime )
      {
         if(maxWriteLockFreeTs < currentts) maxWriteLockFreeTs = currentts;
         Long tk = ti.getTid();
         if(tmpRangeLockTime.containsKey(tk))
           tmpRangeLockTime.remove( tk );
         iter.remove();
         long diff=currentts - ti.getTs();
         if (LOG.isWarnEnabled()) {
             LOG.warn("LOCKDBG: remove write lock for long time locking transaction id is " + tk + " time diff is " + diff + " greater than " + MAX_TMP_WRITE_LOCK_LIVE_TIME * maxForUpdLockCheckTime);
         }
        Long key = getTransactionalUniqueId(ti.getTid());
        TrxTransactionState state1 = null;
        synchronized (transactionsById) {
           state1 = transactionsById.get(key);
        }
        state1.setLockProtected(false);
      }
    }

    synchronized(tmpRangeLock) {
       Iterator<trafLockInfo> it = tmpRangeLock.iterator();
       while(it.hasNext()) {
           trafLockInfo tli = it.next();
           if( (currentts - tli.getTs() ) > MAX_TMP_WRITE_LOCK_LIVE_TIME * maxForUpdLockCheckTime )
           {
               if (LOG.isWarnEnabled()) {
                   LOG.warn("LOCKDBG: remove range lock for long time locking transaction id is " + tli.getTid());
               }
               it.remove();
           }
       }
    }

  }

  /**
   * Removes unneeded committed transactions                               
   */
  synchronized public void removeUnNeededCommitedTransactions(Long sequenceNum) {

      Long minStartSeqNumber = 0L;
      TrxTransactionState state = null;
      int numRemoved = 0;
      long key = 0;
      boolean toSync = false;
      LinkedList<Entry<Long, TrxTransactionState>> ctbsnList = null;
      if (LOG.isTraceEnabled()) {
	            LOG.trace("Region Cleanup " + m_regionDetails
	                 + " Chore removeUnNeededCommittedTransactions: Iteration "
	                 + choreCount + " size " + commitedTransactionsBySequenceNumber.size());
      }

      if (sequenceNum >= 0) {
        state = commitedTransactionsBySequenceNumber.remove(sequenceNum);
        try {
          if (state != null)
            unLockRegionAll(state.getTransactionId());
        } catch (Exception e) {
          throw new RuntimeException(e);
        }
        return;
      }

      synchronized (commitedTransactionsBySequenceNumber) {
          ctbsnList = new LinkedList<Entry<Long, TrxTransactionState>>(
                         commitedTransactionsBySequenceNumber.entrySet());
      }

      if (sequenceNum == -1L) {
        minStartSeqNumber = getMinStartSequenceNumber();
        if (minStartSeqNumber == null)
          minStartSeqNumber = Long.MAX_VALUE;  
        else
          minStartSeqNumber = Math.max( 0L,(minStartSeqNumber.longValue() - 50L));
      }
      
      if (((choreCount % 101) == 0) &&
          (totalCheckAndDeleteRegionTx.get() > 0) ||
          (totalCheckAndPutRegionTx.get() > 0) ||
          (totalDeleteRegionTx.get() > 0) ||
          (totalPutRegionTx.get() > 0)){
         if (LOG.isInfoEnabled()) {
             LOG.info("Region Transaction details " + m_regionDetails + " Request Statistics: Chore " + choreCount
                      + " CheckAndDeleteRegionTx " + totalCheckAndDeleteRegionTx.get()
                      + " CheckAndPutRegionTx " + totalCheckAndPutRegionTx.get()
                      + " DeleteRegionTx " + totalDeleteRegionTx.get()
                      + " PutRegionTx " + totalPutRegionTx.get());
         }
         totalCheckAndDeleteRegionTx.set(0);
         totalCheckAndPutRegionTx.set(0);
         totalDeleteRegionTx.set(0);
         totalPutRegionTx.set(0);
      }            

      synchronized (choreFlushLock) {
          if (choreCount > choreFlush) {
              toSync = true;
              choreFlush = choreCount;
          }
      }

      synchronized (commitedTransactionsBySequenceNumber) {
      choreCount++;
      try{
         if (toSync) {
            WALSync(tHLog, -1, 0);
            if (LOG.isInfoEnabled() && ((choreCount % 101) == 1)) {
                    LOG.info("Region Chore Flush exercised, " + " Chore count " + choreCount + " Flush count " + choreFlush);
            }                    
         }
         else {
             if (LOG.isTraceEnabled()) {
                    LOG.trace("Region Chore Flush skipped, " + " Chore count " + choreCount + " Flush count " + choreFlush);             
             }                    
         }
      } catch (IOException ioe) {
         LOG.error("chore removeUnNeededCommitedTransactions Cleanup " + m_regionDetails + " exception: ", ioe);
      }

      if ((commitedTransactionsBySequenceNumber.size() != 0) && ((choreCount % 101) == 1)) {
          if (LOG.isInfoEnabled()) {
              LOG.info("Region Cleanup " + m_regionDetails + "Chore removeUnNeededCommittedTransactions: Iteration "
                      + choreCount + " commitedSize " + commitedTransactionsBySequenceNumber.size()
                      + " transById size " + transactionsById.size() + " commitPending size " + commitPendingTransactions.size()
                      + " minStartSeqNumber " + minStartSeqNumber + " nextSequenceId " + nextSequenceId.get());
          }
      }

      for (Entry<Long, TrxTransactionState> entry : ctbsnList) {
          TrxTransactionState curState = entry.getValue();
          key = entry.getKey();
          if (key >= minStartSeqNumber) {
            break;
          }
          if (curState != null && transactionsById.containsKey(getTransactionalUniqueId(curState.getTransactionId()))
              && curState.getStatus().equals(Status.COMMIT_PENDING)
              && curState.getCommitProgress() != CommitProgress.COMMITED) {
              continue;
          }

          state = commitedTransactionsBySequenceNumber.remove(key);
          if (state == null)
             continue;
          long tid = state.getTransactionId();//removeUnNeededCommitedTransactions release transaction
          if (!LockConstants.ENABLE_ROW_LEVEL_LOCK) {
            synchronized(selectForUpdateLockHashmap) {
              for(Map.Entry<ByteArrayKey, Long> en: selectForUpdateLockHashmap.entrySet()) {
                if(en.getValue() == tid)
                {
                  selectForUpdateLockHashmap.remove(en.getKey());
                  if(selectForUpdateLockWaitQueue.containsKey( en.getKey() ) && enableUseWaitQueue == true)
                  {
                    List<Long> waitTrxList = selectForUpdateLockWaitQueue.get( en.getKey() );
                    if(waitTrxList.size() == 0)
                      selectForUpdateLockWaitQueue.remove(en.getKey());
                  }
                }
              }
            }
          }
          try {
              unLockRegionAll(tid);
          } catch (Exception e) {
              throw new RuntimeException(e);
          }
          state.clearState();
          numRemoved++;
        }
      }

      if (LOG.isTraceEnabled()) {
         StringBuilder traceMessage = new StringBuilder();
         if (numRemoved > 0) {
            traceMessage.append("removeUnNeededCommitedTransactions: Removed [").append(numRemoved).append("] commited transactions");

            if (minStartSeqNumber == Long.MAX_VALUE) {
              traceMessage.append(" with any sequence number.");
            } else {
               traceMessage.append(" with sequence lower than [").append(minStartSeqNumber).append("].");
            }

             if (!commitedTransactionsBySequenceNumber.isEmpty()) {
                traceMessage.append(" Still have [").append(commitedTransactionsBySequenceNumber.size())
                          .append("] left.");
             } else {
                traceMessage.append(" None left.");
             }
             LOG.trace(traceMessage.toString());
         } else if (commitedTransactionsBySequenceNumber.size() > 0) {
            traceMessage.append("Could not remove any transactions, and still have ")
                         .append(commitedTransactionsBySequenceNumber.size())
                         .append(" left");
            LOG.trace(traceMessage.toString());
         }
      }
  }

  /**
   * Removes unneeded TransactionalRegionScannerHolder objects             
   */

  synchronized public void removeUnNeededStaleScanners() {

    long scannerId = 0L;
    long transId = 0L;
    long listSize = 0L;
    long scannerSize = 0L;
    Long transactionId = 0L;
    TransactionalRegionScannerHolder rsh = null;
    Iterator<Long> transIter = null;
    Iterator<Map.Entry<Long, TransactionalRegionScannerHolder>> scannerIter = null;
    synchronized (cleanScannersForTransactions) {

      listSize = cleanScannersForTransactions.size();
      if (LOG.isTraceEnabled()) LOG.trace("removeUnNeededStaleScanners - listSize is " + listSize + " in region " + m_regionDetails);

      if (listSize == 0)
        return;

      if (scanners == null || scanners.isEmpty()) {
        if (LOG.isTraceEnabled()) LOG.trace("removeUnNeededStaleScanners - scanners is empty, clearing cleanScannersForTransactions in region " + m_regionDetails);
        cleanScannersForTransactions.clear();
        return;
      }

      scannerSize = scanners.size();

      if (LOG.isTraceEnabled()) LOG.trace("removeUnNeededStaleScanners - transactions list count is " + listSize + ", scanners size is " + scannerSize);

      for (transIter = cleanScannersForTransactions.iterator(); transIter.hasNext();) {

        transactionId = transIter.next();
        scannerIter = scanners.entrySet().iterator();

        while(scannerIter.hasNext()){

          Map.Entry<Long, TransactionalRegionScannerHolder> entry = scannerIter.next();
          rsh = entry.getValue();

          if (rsh != null) {
            transId = rsh.transId;
            scannerId = rsh.scannerId;

            if (transId == transactionId) {

              if (LOG.isTraceEnabled()) LOG.trace("removeUnNeededStaleScanners - txId " + transactionId + ", scannerId " + scannerId
                     + ", Removing stale scanner in region " + m_regionDetails);

              try {
                if (rsh.s != null) {
                  if (LOG.isTraceEnabled()) LOG.trace("removeUnNeededStaleScanners - txId " + transactionId
                       + ", scannerId " + scannerId + ", Scanner was not previously closed in region " + m_regionDetails);
                  rsh.s.close();
                }
                rsh.s = null;
                rsh.r = null;
                scannerIter.remove();
              }
              catch (Exception e) {
                  if (LOG.isWarnEnabled()) {
                      LOG.warn("removeUnNeededStaleScanners - txId " + transactionId + ", scannerId " + scannerId + ", Caught exception ", e);
                  }
              }
            }
          }
        } // End of while loop
      }  // End of for loop

      cleanScannersForTransactions.clear();

    }  // End of synchronization

  }

  /**
   * Returns the minimum start sequence number
   * @return Integer
   */
  private Long getMinStartSequenceNumber() {

    List<TrxTransactionState> transactionStates;

    // Make a copy of the active transactions states
    synchronized (transactionsById) {
      transactionStates = new ArrayList<TrxTransactionState>(transactionsById.values());
    }

    Long min = null;

    for (TrxTransactionState transactionState : transactionStates) {
      try {
         if ((! transactionState.getStatus().equals(Status.DOOMED)) &&
                                  (! transactionState.getStatus().equals(Status.ABORTED)) ) {
             if (min == null || transactionState.getChoreMinSequenceNumber() < min) {
                 min = transactionState.getChoreMinSequenceNumber();
             }
          }
      }
      catch(NullPointerException npe){
         if (LOG.isTraceEnabled()) LOG.trace("getChoreMinSequenceNumber ignoring NullPointerException ");
      }
    }

    // Min now has the lowest sequence number of all active states
    return min;
  }

  /**
   * Returns the region name as a string
   * @return String 
   */
  public String getRegionNameAsString() {
    return m_regionName;
  }

/**
 * Simple helper class that just keeps track of whether or not its stopped.
 */
   private static class StoppableImplementation implements Stoppable {
     private volatile boolean stop = false;

     @Override
     public void stop(String why) {
       if (LOG.isInfoEnabled()) {
           LOG.info("Cleanup Chore thread has stopped: Reason:" + why);
       }
       this.stop = true;
     }

     @Override
     public boolean isStopped() {
       return this.stop;
     }
  }

  private static class trafLockInfo {
      long tid;
      long ts;
      boolean isRead;
      byte[] startKey;
      byte[] endKey;
      trafLockInfo(long tidi, long tsi)
      {
         tid = tidi;
         ts = tsi;
         isRead = false; //by default it is a write lock
      }
      long getTid() {return tid; }
      long getTs() {return ts; }
      void setStartKey(byte[] s) {startKey = s; }
      void setEndKey(byte[] e) {endKey = e; }
      byte[] getStartKey() {return startKey;}
      byte[] getEndKey() {return endKey;}
      void setIsRead() { isRead = true; }
      void setIsWrite() { isRead = false; }
      boolean isRead() { return isRead; }
  }


  private static class RegionServerStoppable implements Stoppable {
     private volatile Integer regionNum = -1;

     @Override
     public void stop(String why) {
       LOG.info("RegionServerStoppable thread has stopped: Reason:" + why + " " + this.regionNum);
       synchronized (regionNum) {
           this.regionNum -= 1;
       }
     }

     @Override
     public boolean isStopped() {
       synchronized (regionNum) {
           return (regionNum == 0);
       }
     }

     public void inCreaseRegionNum() {
       synchronized (regionNum) {
           if (this.regionNum == -1) {
               this.regionNum = 1;
           } else {
               this.regionNum += 1;
           }
       }
     }
  }

  synchronized public void checkMemoryUsage() {

    long memUsed = 0L;
    long memMax = 0L;

    if (memoryUsageThreshold < DEFAULT_MEMORY_THRESHOLD &&
        memoryBean != null) {
      memUsed = memoryBean.getHeapMemoryUsage().getUsed();
      memMax = memoryBean.getHeapMemoryUsage().getMax();

      memoryPercentage = 0L;

      if (memMax != 0) {
        memoryPercentage = (memUsed * 100) / memMax;
      }

      memoryThrottle = false;
      if (memoryPercentage > memoryUsageThreshold) {
        // If configured to perform a garbage collection,
        // try to release memory before throttling the queries.
        if (memoryUsagePerformGC == true) {
          if (LOG.isTraceEnabled()) LOG.trace("checkMemoryUsage - before GC, memoryPercentage is " + memoryPercentage);
          System.gc();
          // Calculate the memory usage again before
          // setting the throttle value or post a warning.
          memUsed = memoryBean.getHeapMemoryUsage().getUsed();
          memMax = memoryBean.getHeapMemoryUsage().getMax();
          memoryPercentage = 0L;

          if (memMax != 0) {
            memoryPercentage = (memUsed * 100) / memMax;
          }

          if (LOG.isTraceEnabled()) LOG.trace("checkMemoryUsage - after GC, memoryPercentage is " + memoryPercentage);

      if (memoryPercentage > memoryUsageThreshold) {
        if(memoryUsageWarnOnly == false)  
          memoryThrottle = true;
        if (LOG.isTraceEnabled()) LOG.trace("checkMemoryUsage - memoryPercentage is " + memoryPercentage + ", memoryThrottle is "+ memoryThrottle);
      }   
        } else {
          if(memoryUsageWarnOnly == false)
            memoryThrottle = true;
          if (LOG.isTraceEnabled()) LOG.trace("checkMemoryUsage - memoryPercentage is " + memoryPercentage + ", memoryThrottle is "+ memoryThrottle);
        }
      }
    }
  }
  
  synchronized public void checkImportJobs() {

    if (LOG.isTraceEnabled()) LOG.trace("checkImportJobs - number of import jobs: " + importJobs.size());
    
    synchronized (importJobs) {
      for(SnapshotImportJob sij : importJobs.values()) {
        if(sij.isExpired()) {
         File implog = new File(sij.getLog());
         if(implog != null) {
          implog.delete();
          importJobs.remove(implog);
          if (LOG.isDebugEnabled()) LOG.debug("checkImportJobs - removing Import job: " + sij.getLog());
         }
        }
      }
     }
    }
  
    public void broadcastRequest(RpcController controller,
                            BroadcastRequest request,
                            RpcCallback<BroadcastResponse> done) {

// The default response seems redundant
//    BroadcastResponse response = BroadcastResponse.getDefaultInstance();

    int status = 0;
    IOException ioe = null;
    int requestType = request.getRequestType();
    boolean lv_bool = request.getRequestBool();
    long startTime = System.currentTimeMillis();

    if (LOG.isInfoEnabled()) LOG.info("broadcastRequest - requestType "
         + requestType + ", lv_bool " + lv_bool + ", regionName " + m_regionDetails);

    // Process local memory
    try {
       switch (requestType) {

          case GENERIC_SHIELD:
             shieldFromRemote = lv_bool;
             status = GENERIC_OK;
             if (LOG.isTraceEnabled()) LOG.trace("broadcastRequest shieldFromRemote " + shieldFromRemote);
             break;

          case GENERIC_FLUSH_MUTATION_FILES:
             if (LOG.isTraceEnabled()) LOG.trace("broadcastRequest closing mutation file and reset cached skip CDC flags");
             regionLockForCDCFlushClose();
             //mutationCapture.mutationBufferOp(PIT_MUTATION_CLOSE_STOP, null, null, 0, 0, 5000, 15000);
             //mutationCapture.setSkipCDC(false); // reset cached skip_CDC flag, from initial mutations
             status = GENERIC_OK;
             break;

          case GENERIC_RECOVERY_COMPLETE:
             if ((indoubtTransactionsById == null) || (indoubtTransactionsById.size() == 0)){
                status = GENERIC_OK;
             }
             else {
                status = GENERIC_WAIT;
             }
             if (LOG.isTraceEnabled()) LOG.trace("broadcastRequest GENERIC_RECOVERY_COMPLETE returning " + status);
             break;
             
          case GENERIC_DEFER_SPLIT:
             deferRegionSplit.set(lv_bool);
             status = GENERIC_OK;
             if (LOG.isInfoEnabled()) LOG.info("broadcastRequest deferRegionSplit " + deferRegionSplit.get());
             break;

          case GENERIC_BLOCK_PHASE1:
             if (LOG.isTraceEnabled()) LOG.trace("broadcastRequest block phase1 and drain phase2");
             regionBlockPhase1();
             status = GENERIC_OK;
             break;

          case GENERIC_UNBLOCK_PHASE1:
             regionUnblockPhase1();
             status = GENERIC_OK;
             break;

          default:
             throw new IOException("Unknown broadcast request type " + requestType);

       }
    } catch (IOException e) {
       LOG.error("broadcastRequest - requestType " + requestType + " , Caught IOException", e);
       ioe = new IOException(e);
       status = GENERIC_ERROR;
    }

    if (LOG.isInfoEnabled()) LOG.info("broadcastRequest - requestType "
         + requestType + " complete in region " + m_regionDetails);

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.BroadcastResponse.Builder broadcastResponseBuilder = BroadcastResponse.newBuilder();

    broadcastResponseBuilder.setHasException(false);

    if (ioe != null)
    {
      broadcastResponseBuilder.setHasException(true);
      broadcastResponseBuilder.setException(ioe.toString());
    }

    broadcastResponseBuilder.setResult(status);

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      long timeCost = System.currentTimeMillis();
      broadcastResponseBuilder.setCoproSTime(startTime);
      broadcastResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[32] += timeCost;
      callCount[32]++;
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " broadcastRequest CC " + callCount[32] + " ATC " + (costSum[32] / callCount[32]) + " TC " + timeCost);
          }
    }

    BroadcastResponse bresponse = broadcastResponseBuilder.build();
    done.run(bresponse);
  }
  
  public void importLaunch(RpcController controller,
                           ImportLaunchRequest request,
                           RpcCallback<ImportLaunchResponse> done) {
                           
    int status = 0;
    IOException ioe = null;
    
    String snapshotName = request.getSnapshotName().toStringUtf8();
    String copyTo = request.getCopyTo().toStringUtf8();
    String copyFrom = request.getCopyFrom().toStringUtf8();
    String mappers = request.getMappers().toStringUtf8();
    String tag = request.getTag().toStringUtf8();
    
    if (LOG.isInfoEnabled()) LOG.info("importLaunch - Tag " + tag + ", SnapshotName "
         + snapshotName + ", copyTo " + copyTo + ", copyFrom " + copyFrom +
         ", mappers " + mappers);

    String rcStr = null;
    Process process = null;
    
    try {
        String hadoopType = System.getenv("HADOOP_TYPE");
        String hbaseExe; 
        if ( hadoopType != null) {
          //if null, it is generally cluster env, use default hbase exe
          hbaseExe = "hbase";
        } else {
          //if null, then work station env.
          hbaseExe = System.getenv("HBASE_HOME");
          hbaseExe = hbaseExe + "/" + "bin" + "/" + "hbase";
        }
            
        ProcessBuilder pb;
        pb = new ProcessBuilder( hbaseExe,
                                 "org.apache.hadoop.hbase.snapshot.ExportSnapshot",
                                 "-snapshot", snapshotName ,
                                 "-copy-to", copyTo,
                                 "-copy-from", copyFrom,
                                 "-mappers", mappers);
        
        //redirect child process error output to stdout.  
        pb.redirectErrorStream(true);
        
        //redirect child process stdout to a log file. 
        String importLog = tag + "_" + snapshotName + "_.log";
        File implog = new File(importLog);
        if(implog.exists()) implog.delete();
        implog.createNewFile();
        //redirect stdout to log.
        pb.redirectOutput(implog);
        
        process = pb.start();
        SnapshotImportJob sij = new SnapshotImportJob(process, importLog);
        
        //use importLog as key since already constructed
        importJobs.put(importLog, sij);
        
        status = GENERIC_OK;
    
    } catch (IOException e) {
       LOG.error("importLaunch - Tag " + tag + " snapshotName " + snapshotName + " , Caught IOException", e);
       ioe = new IOException(e);
       status = GENERIC_ERROR;
    } finally {
    }
  
    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.ImportLaunchResponse.Builder importResponseBuilder = ImportLaunchResponse.newBuilder();

    importResponseBuilder.setHasException(false);

    if (ioe != null)
    {
      importResponseBuilder.setHasException(true);
      importResponseBuilder.setException(ioe.toString());
    }
    
    importResponseBuilder.setResult(status);

    ImportLaunchResponse eiresponse = importResponseBuilder.build();
    done.run(eiresponse);
                           
  }
  
  public void importStatus(RpcController controller,
                           ImportStatusRequest request,
                           RpcCallback<ImportStatusResponse> done) {
    int status = 0;
    IOException ioe = null;
    SnapshotImportJob sij = null;
    String snapshotName = request.getSnapshotName().toStringUtf8();
    String tag = request.getTag().toStringUtf8();
    
    if (LOG.isDebugEnabled()) LOG.debug("importStaus - Tag " + tag + ", SnapshotName "
         + snapshotName);

    String rcStr = null;
    Process process = null;
    File implog = null;
    FileReader fr = null;
    BufferedReader reader = null;
    
    try {
        String importLog = tag + "_" + snapshotName + "_.log";
        sij = importJobs.get(importLog);
        if(sij == null) {
          throw new IOException("importJob not found. importLog:" + importLog);
        }
        
        process = sij.getProcess();
        if(process.isAlive()) {
          //import in progress. Just renew timeout.
          sij.renewTimeout();
          status = GENERIC_WAIT;
        }
        else {
          //import process might have exited. 
          //read the log and check for errors.
          implog = new File(sij.getLog());
          
          fr = new FileReader(implog);
          reader = new BufferedReader(fr);
    
          StringBuilder builder = new StringBuilder();
          String line = null;
          while ( (line = reader.readLine()) != null) {
            builder.append(line);
            builder.append(System.getProperty("line.separator"));
          }
          rcStr = builder.toString();
          
          if(LOG.isDebugEnabled())
            LOG.debug("importStaus Tag " + tag + ", SnapshotName " + snapshotName + ", importLog: " + rcStr);
      
          //if success or error, remove importJob entry.
          importJobs.remove(implog);
          
          if(rcStr.contains("ERROR") || rcStr.contains("FATAL")) {
            throw new IOException("importStaus Tag " + tag + ", SnapshotName " + snapshotName + ", importLog: " + rcStr);
          }
          status = GENERIC_OK;
        }
    } catch (IOException e) {
       LOG.error("importStatus - Tag " + tag + " snapshotName " + snapshotName + " , Caught IOException", e);
       
       try {
        if(reader != null) reader.close();
        if(fr != null) fr.close();
        if(implog != null) implog.delete();
        } catch (IOException ie) {
          LOG.error("importStatus cleanup - Tag " + tag + " snapshotName " + snapshotName + " , Caught IOException", ie);
          e.addSuppressed(ie);
        }
       ioe = new IOException(e);
       status = GENERIC_ERROR;
    } finally {
    }
  
    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.ImportStatusResponse.Builder importResponseBuilder = ImportStatusResponse.newBuilder();

    importResponseBuilder.setHasException(false);

    if (ioe != null)
    {
      importResponseBuilder.setHasException(true);
      importResponseBuilder.setException(ioe.toString());
    }
    
    importResponseBuilder.setResult(status);

    ImportStatusResponse eiresponse = importResponseBuilder.build();
    done.run(eiresponse);
                           
  }

  public void regionBlockPhase1() throws IOException{

     int retryCount = 0;
     try {
        blockPhase1.set(true);
        do {
           try {
              boolean keepPolling = true;
              while (keepPolling) {
                 try {
                    Thread.sleep(20); // sleep 0.02 second or until interrupted
                    keepPolling = false;
                 }
                 catch (InterruptedException e) {
                    // ignore the interruption and keep going
                 }
              }
              int count = 1;
              while (!checkPendingListClear(commitPendingTransactions)) {
                 try {
                    if (LOG.isDebugEnabled()) LOG.debug("regionBlockPhase1() delay, count " + count++ + " on: " + m_regionDetails);
                    Thread.sleep(200); // sleep 0.2 second
                 } catch (InterruptedException e) {
//                    if (LOG.isErrorEnabled()) LOG.error("regionBlockPhase1 - Problem while calling sleep() in regionBlockPhase1 delay. ", e);
//                    throw new IOException("Problem while calling sleep() in regionBlockPhase1 delay. ", e);
                    // ignore the interruption and keep going
                 }
              }
              retryCount = 3;
	       }  // try block
	       catch(IOException ioe) {
              retryCount++;
	          if (LOG.isErrorEnabled()) LOG.error("Encountered exception on attempt " + retryCount
	                           + " when calling regionBlockPhase1.  blockAll " + blockAll.get() + ": ", ioe);
	          if (blockAll.get()) { blockAll.set(false); }
	          if (retryCount >= 3) {
                 if (LOG.isErrorEnabled()) LOG.error("retryCount " + retryCount + " exceeded when calling broadcast CDC flush and close: ", ioe);
                 throw ioe;
		      }
	       }  // catch block
        } while (retryCount < 3);
     } //  method try block
     catch (IOException e1) {
        if (LOG.isErrorEnabled()) LOG.error("Encountered exception in regionBlockPhase1.  blockAll " + blockAll.get() + ": ", e1);
        throw new IOException(e1);
     }
  }

  public void regionUnblockPhase1(){

     if (LOG.isDebugEnabled()) LOG.debug("regionUnblockPhase1() in region: " + m_regionDetails);
     blockPhase1.set(false);
  }

  public void regionLockForCDCFlushClose() throws IOException{

      int retryCount = 0;
      drainCPL = new HashSet<TrxTransactionState>();
      try {
        synchronized(commitPendingTransactions) {		  
           blockNonPhase2.set(true);
           drainCPL.addAll(commitPendingTransactions);
           drainMC2Request = true;
        }
        if (LOG.isDebugEnabled()) LOG.debug("PIT CDC: size of prepared branches to be drained before CDC Flush/Close " + drainCPL.size());
        blockNonPhase2.set(false);
        do {
              try {
                     boolean keepPolling = true;
                     while (keepPolling) {
                          try {
                          Thread.sleep(10); // sleep 0.01 second or until interrupted
                          keepPolling = false;
                           }
                           catch (InterruptedException e) {
                                       // ignore the interruption and keep going
                            }
                      }
                      int count = 1;
                      while (!checkPendingListClear(drainCPL)) {
                             try {
                                     if (LOG.isDebugEnabled()) LOG.debug("regionLockForCDCFlushClose() delay, count " + count++ + " on: " + m_regionName);
                                     if (LOG.isDebugEnabled()) LOG.debug("PIT CDC: size of prepared branches to be drained before CDC Flush/Close "
                                                                                                      + drainCPL.size());
                                     Thread.sleep(200); // sleep 0.2 second
                              } catch (InterruptedException e) {
                              if (LOG.isErrorEnabled()) LOG.error("regionLockForCDCFlushClose - Problem while calling sleep() in regionLockForCDCFlushClose delay. ", e);
                              throw new IOException("Problem while calling sleep() in regionLockForCDCFlushClose delay. ", e);
                              }
                      }                      
                      retryCount = 5;
	      }  // try block		      
	      catch(IOException ioe) {
	               retryCount++;
	               LOG.error("Encountered exception on attempt " + retryCount
	                           + " when calling broadcast CDC flush and close.  blockAll " + blockAll.get() + ": ", ioe);
	               if (blockAll.get()) { blockAll.set(false); }
	               if (retryCount >= 5) {
                             LOG.error("retryCount " + retryCount + " exceeded when calling broadcast CDC flush and close: ", ioe);
                             throw ioe;
		       }
	        }  // catch block
          } while (retryCount < 5);      
	  // doing CDC task
          // mutationCapture.mutationBufferOp(PIT_MUTATION_CLOSE_STOP, null, null, 0, 0, 5000, 15000, 0);
          if (useMC2) {
              if (mutationCapture2 != null) {
                  mutationCapture2.MC2_doWriterOperation(PIT2_MUTATION_WRITER_CLOSE);
              }
          }
          else {
              mutationCapture.mutationBufferOp(PIT_MUTATION_CLOSE_STOP, null, null, 0, 0, 5000, 15000, 0);  
           }
	} //  method try block
	catch (IOException e1) {
	    LOG.error("Encountered exception on when calling broadcast CDC flush and close.  blockAll " + blockAll.get() + ": ", e1);
	    throw new IOException(e1);
	}
	finally {
        if (LOG.isDebugEnabled()) LOG.debug("PIT CDC: finally start");

             if (useMC2) {
                 if (mutationCapture2 != null) {
                     mutationCapture2.setSkipCDC(false); // reset cached skip_CDC flag, from initial mutations			
                 }
             }
             else {
                 mutationCapture.setSkipCDC(false); // reset cached skip_CDC flag, from initial mutations
             }
             drainMC2Request = false; // reset, so commit/abort won't need to remove tx objects from drainCPL
             blockNonPhase2.set(false);
        if (LOG.isDebugEnabled()) LOG.debug("PIT CDC: finally END");
    }
  }
  
     protected boolean checkPendingListClear(Set<TrxTransactionState> commitPendingTransactions) throws IOException {
        if (commitPendingTransactions.isEmpty()) {
            if (LOG.isDebugEnabled())
                LOG.debug("checkPendingListClear is true because commitPendingTransactions is empty " + m_regionName);
            return true;
        } else {
            // Check to see if all of the TrxTransaction state objects
            // have dropTable Recorded, in which case the pending list is
            // considered clear of pending list.
            for (TrxTransactionState transactionState : commitPendingTransactions) {
                // if even one transaction state does not have drop table recorded
                // then pendingList is not yet clear.
                if (!transactionState.dropTableRecorded()) {
                   if (LOG.isInfoEnabled()) LOG.info("checkPendingListClear is false,  commitPendingTransactions is not empty "
                                + "transaction " + transactionState.getTransactionId()
                                + " from node " + transactionState.getNodeId() + " is pending "
                                + "commitPendingTransactions size : " + commitPendingTransactions.size()
                                + " Region : " + m_regionName);
                    return false;
                }
            }
            // Reaching here means pendingListClear.
            if (LOG.isInfoEnabled()) {
                LOG.info("checkPendingListClear is true because dropTableRecorded is true " + m_regionName);
            }
            return true;
        }
    }

  public void pushOnlineEpoch(RpcController controller,
          PushEpochRequest request, RpcCallback<PushEpochResponse> done){

    long transId  = request.getTransactionId();
    long tmpEpoch = request.getEpoch();
    IOException ioe = null;
    long startTime = System.currentTimeMillis();

    if(LOG.isInfoEnabled()) LOG.info("pushOnlineEpoch -- ENTRY, transId: " + transId
          + " current onlineEpoch " + this.onlineEpoch + " new onlineEpoch " + tmpEpoch
          + " in region: " + m_regionDetails);

    if (this.onlineEpoch < tmpEpoch){
       if(LOG.isWarnEnabled()) LOG.warn("pushOnlineEpoch -- Warning: current onlineEpoch " + this.onlineEpoch
          + " is less than new onlineEpoch " + tmpEpoch + ", transId: " + transId
          + " in region: " + m_regionDetails + "\nEnsure the time is synchronized between nodes in your cluster");
//       ioe = new IOException("pushOnlineEpoch -- Error: current onlineEpoch " + this.onlineEpoch
//          + " is less than new onlineEpoch " + tmpEpoch + ", transId: " + transId
//          + " in region: " + m_regionDetails);
    }

    // Even if the current onlineEpoch is less than the transaction's, we will overwrite it and use the value from the transaction
    this.onlineEpoch = tmpEpoch;

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.PushEpochResponse.Builder pushEpochResponseBuilder = PushEpochResponse.newBuilder();

    if (ioe != null){
       pushEpochResponseBuilder.setHasException(true);
       pushEpochResponseBuilder.setException(ioe.toString());
    }
    else{
       pushEpochResponseBuilder.setHasException(false);
    }

    if (RSConstants.RECORD_TIME_COST_COPRO >= 0) {
      EndpointCostStats costStats = getEndpointCostStats(transId, false);
      long timeCost = System.currentTimeMillis();
      pushEpochResponseBuilder.setCoproSTime(startTime);
      pushEpochResponseBuilder.setCoproETime(timeCost);
      timeCost -= startTime;
      costSum[33] += timeCost;
      callCount[33]++;
      costStats.callCountPlus(31L);
      costStats.sumCostPlus(31L, timeCost);
      if (timeCost >= RSConstants.RECORD_TIME_COST_COPRO)
          if (LOG.isWarnEnabled()) {
              LOG.warn(m_regionName + " pushOnlineEpoch tid: " + transId + " CC " + callCount[33] + " ATC " + (costSum[33] / callCount[33]) + " TC " + timeCost);
          }
    }

    PushEpochResponse epochResponse = pushEpochResponseBuilder.build();
    done.run(epochResponse);
 }
 
 public void doomTransactionWithScanner() {
     
          HRegionInfo hri = regionInfo;
          if (scanners == null) return;
          
          if(scanners.isEmpty()) 
          {
                if (LOG.isDebugEnabled()) LOG.debug("scannersListClear - Scanners is empty: " + hri.getRegionNameAsString());
                return;
          }

          if (LOG.isDebugEnabled()) LOG.debug("scannersListClear - Scanners is not empty: " + hri.getRegionNameAsString());
          Iterator<Map.Entry<Long, TransactionalRegionScannerHolder>> scannerIter = scanners.entrySet().iterator();
          TransactionalRegionScannerHolder rsh = null;
          Map.Entry<Long, TransactionalRegionScannerHolder> entry;
          while(scannerIter.hasNext()) {
                      entry = scannerIter.next();
                      rsh = entry.getValue();
                      if (rsh != null) {
                             if (LOG.isDebugEnabled()) LOG.debug("scannersListClear Active Scanner is: "+ rsh.scannerId +
                             " Txid: "+ rsh.transId + " Region: " + m_regionDetails);
                             Long key = new Long(rsh.transId);
                             TrxTransactionState trxState = null;
                             synchronized (transactionsById) {
                                trxState = transactionsById.get(key);
                             }
                             //if trxState is present means there is activity with this region.
                             if(trxState != null) {
                                    if (LOG.isInfoEnabled()) {
                                        LOG.info("Active Transaction with Scanner found, to be doomed, ScannerId: " +
                                    rsh.scannerId + " Txid: "+ rsh.transId + " state: " + trxState + " Region: " + m_regionDetails);
                                    }
                                    if (trxState.getStatus().equals(Status.PENDING)) { // active transaction
                                        trxState.setStatus(Status.DOOMED); // doom, this status will be migrated
                                    }
                             }
                      }
          } // while
          return;
 }

  public void flushLockToFS(Path flushPath, String regionName, boolean isSplit) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return;
      }
      checkAndCreateLockManager();
      try {
          lockManager.flushToFS(regionName, context, fs, config, flushPath, isSplit);
      } catch (Exception e) {
          LOG.error("failed to flush lock to file", e);
      }
      rsServer.removeLockManager(regionName);
  }

  public void readLockInfo(Path flushPath) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return;
      }
      checkAndCreateLockManager();
      try {
#ifdef CDH5.7 APACHE1.2 CDH5.16
      lockManager.readLockInfo(fs, config,flushPath, this, null, regionInfo);
#else
      lockManager.readLockInfo(fs, config,flushPath, this, m_Region, regionInfo);
#endif
      } catch (Exception e) {
          LOG.error("failed to read lock info", e);
      }
  }
 
  /** 
  public boolean isInRegionServer(String regionName) {
      RegionServerServices rss = env.getRegionServerServices();
      if (rss == null) {
          return false;
      }
      List<Region> regions = rss.getRegions();
      if (regions == null) {
          return false;
      }
      for (Region region : regions) {
          if (region.getRegionInfo().getRegionNameAsString().equals(regionName)) {
              return true;
          }
      }
      return false;
  }
  */

  public void flushToFS(Path flushPath) throws IOException {

    if(LOG.isDebugEnabled()) LOG.debug("flushToFS -- ENTRY, region " + m_regionDetails + " Path: " + flushPath.toString()
          + " onlineEpoch " + this.onlineEpoch + " transactionsById (" + transactionsById.size()
           + "), commitedTransactionsBySequenceNumber (" + commitedTransactionsBySequenceNumber.size() + ")");
   
    try {

    TransactionPersist.Builder txnPersistBuilder = TransactionPersist.newBuilder();
    fs.delete(flushPath, true);

    HFileWriterV2 w =
        (HFileWriterV2)
        HFile.getWriterFactory(config, new CacheConfig(config))
        .withPath(fs, flushPath).withFileContext(context).create();
        
    // doom all the active transactions which have active scanners (since preClose no longer wait for active scanners
    doomTransactionWithScanner();

    Map<Long, TrxTransactionState> transactionMap = new HashMap<Long, TrxTransactionState>();

    synchronized (transactionsById) {
        for(TrxTransactionState ts : transactionsById.values()) {
            transactionMap.put(ts.getTransactionId(), ts);
            txnPersistBuilder.addTxById(ts.getTransactionId());
        }
    }

    synchronized (commitedTransactionsBySequenceNumber) {
        for(Map.Entry<Long, TrxTransactionState> entry :
            commitedTransactionsBySequenceNumber.entrySet()) {
                transactionMap.put(entry.getValue().getTransactionId(), entry.getValue());
                txnPersistBuilder.addSeqNoListSeq(entry.getKey());
                txnPersistBuilder.addSeqNoListTxn(entry.getValue().getTransactionId());
         }
    }

    Map<Long, TrxTransactionState> transactionMap1 = new HashMap<Long, TrxTransactionState> (transactionMap);
    for(TrxTransactionState ts : transactionMap1.values()) {
      for(TrxTransactionState ts2 : ts.getTransactionsToCheck()) {
        transactionMap.put(ts2.getTransactionId(), ts2);
      }
    }
    txnPersistBuilder.setNextSeqId(nextSequenceId.get());
    txnPersistBuilder.setOnlineEpoch(this.onlineEpoch);
    txnPersistBuilder.setShieldFromRemote(this.shieldFromRemote);

    ByteArrayOutputStream output = new ByteArrayOutputStream();

    for(TrxTransactionState ts : transactionMap.values()) {

//         if (ts.getStatus().equals(Status.PENDING)) { // active transaction
//             ts.setStatus(Status.DOOMED); // doom, this status will be migrated
//             LOG.info("AAB Transaction txid " + ts.getTransactionId()  + " is doomed during split/balance for consistency ");           
//         }
                                    
        TransactionStateMsg.Builder tsBuilder =  TransactionStateMsg.newBuilder();
        tsBuilder.setTxId(ts.getTransactionId());
        tsBuilder.setStartSeqNum(ts.getStartSequenceNumber());
        tsBuilder.setSeqNum(ts.getHLogStartSequenceId());
        tsBuilder.setLogSeqId(ts.getLogSeqId());
        tsBuilder.setReinstated(ts.isReinstated());
        String locklist="";
        boolean hasLocks = false;
        for(int ii = 0; ii < ts.listOfLockedRowsSelForUpdate.size(); ii++)
        {
          locklist += Hex.encodeHexString(ts.listOfLockedRowsSelForUpdate.get(ii).getBytesArray());
          if(ii+1 < ts.listOfLockedRowsSelForUpdate.size())
           locklist += ":";
          hasLocks = true;
        }
        if(hasLocks == true)
          tsBuilder.setSelForUpdLocks(locklist);

        if(ts.getCommitProgress() == null)
            tsBuilder.setCommitProgress(-1);
        else
            tsBuilder.setCommitProgress(ts.getCommitProgress().ordinal());

        tsBuilder.setStatus(ts.getStatus().ordinal());
        for (WriteAction wa : ts.getWriteOrdering()) {
          if(wa.getPut() != null) {
            tsBuilder.addPutOrDel(true);
            tsBuilder.addPut(ProtobufUtil.toMutation(MutationType.PUT, wa.getPut()));
            if(LOG.isDebugEnabled()) LOG.debug("TRAF_SB_FLUSHTOFS Migrate mutation: txid " + ts.getTransactionId()  + " put " + wa.getPut().toString());
          }
          else {
            tsBuilder.addPutOrDel(false);
            tsBuilder.addDelete(ProtobufUtil.toMutation(MutationType.DELETE, wa.getDelete()));
            if(LOG.isDebugEnabled()) LOG.debug("TRAF_SB_FLUSHTOFS Migrate mutation: txid " + ts.getTransactionId()  + " put " + wa.getDelete().toString());
          }
          tsBuilder.addSavepointId(wa.getSavepoint());
          tsBuilder.addPSavepointId(wa.getPSavepoint());
        }
        String sstart, send;
        for (ScanRange sr : ts.getScans()) {
           if (sr != null && sr.getScMigrate()) { // this is a scan range coming from Get or Scan
               if ((sr.getStartRow() == null) || (sr.getStartRow().length <= 0)) //Bytes.equals(sr.getStartRow(), HConstants.EMPTY_START_ROW)))
                  tsBuilder.addSrStartRow(com.google.protobuf.ByteString.EMPTY);
               else     
                  tsBuilder.addSrStartRow(ByteString.copyFrom(sr.getStartRow()));
               if ((sr.getEndRow() == null) || (sr.getEndRow().length <= 0)) //Bytes.equals(sr.getEndRow(), HConstants.EMPTY_END_ROW)))
                  tsBuilder.addSrEndRow(com.google.protobuf.ByteString.EMPTY);                 
               else                  
                  tsBuilder.addSrEndRow(ByteString.copyFrom(sr.getEndRow()));
               tsBuilder.addSrSvpt(sr.getSavepoint());
               tsBuilder.addSrPsvpt(sr.getPSavepoint());

               sstart = ((sr.getStartRow() == null) || (sr.getStartRow().length <= 0)) ? "NULL" : sr.getStartRow().toString();
               send = ((sr.getEndRow() == null) || (sr.getEndRow().length <= 0)) ? "NULL" : sr.getEndRow().toString();
            /*   if ((sr.getStartRow() == null) || (sr.getStartRow().length <= 0)) //Bytes.equals(sr.getStartRow(), HConstants.EMPTY_START_ROW)))
                  sstart = " NULL ";
               else     
                  sstart = sr.getStartRow().toString() ;
               if ((sr.getEndRow() == null) || (sr.getEndRow().length <= 0)) //Bytes.equals(sr.getEndRow(), HConstants.EMPTY_END_ROW)))
                  send = " NULL ";                 
               else                  
                  send = sr.getEndRow().toString();
             */
               if(LOG.isDebugEnabled()) LOG.debug("TRAF_SB_FLUSHTOFS Migrate scan range: tid " + ts.getTransactionId() + 
                                   " row " + sstart + " " + send  + " " + sr.getSavepoint());
           }
        }
        
        // Note. two groups of txn for check against:
        //           1 is from CPL at begin, 2 is from CommittedSeq after startSeqNumber in preparing time
        //           For online txn migration, only 1 is valid since only active txn will get migrated
        for (TrxTransactionState tsToCheckFromCPL: ts.getTransactionsToCheck() ) {
            tsBuilder.addTxnsToCheck(tsToCheckFromCPL.getTransactionId());
        }
      
        tsBuilder.build().writeDelimitedTo(output);
    }
    byte [] firstByte = output.toByteArray();

    w.append(new KeyValue(Bytes.toBytes(COMMITTED_TXNS_KEY), Bytes.toBytes("cf"), Bytes.toBytes("qual"),
      firstByte));

    byte [] persistByte = txnPersistBuilder.build().toByteArray();
    TransactionPersist persistMsg = TransactionPersist.parseFrom(persistByte);
    long persistEpoch = persistMsg.getOnlineEpoch();
    if (this.onlineEpoch == persistEpoch){
       if(LOG.isDebugEnabled()) LOG.debug("flushToFS onlineEpoch read from persistMsg matches our own " + persistEpoch
                    + " in region: " + m_regionDetails);
    }
    else{
       if(LOG.isErrorEnabled()) LOG.error("flushToFS onlineEpoch read from persistMsg " + persistEpoch
                    + " differs from our own " + this.onlineEpoch + " in region: " + m_regionDetails);
    }
    w.append(new KeyValue(Bytes.toBytes(TXNS_BY_ID_KEY), Bytes.toBytes("cf"), Bytes.toBytes("qual"),
      persistByte));
    w.close();
    
    } catch(IOException e) {
       LOG.error("flushToFS exception: ", e);
    }
    if(LOG.isTraceEnabled()) LOG.trace("flushToFS -- EXIT");
  }

  public void readTxnInfo(Path flushPath) { 
    readTxnInfo(flushPath, false);
  }

  public void readTxnInfo(Path flushPath, boolean setRetry) { 
      
          byte[] sr_start, sr_end;
          String sstart, send;   

          if(LOG.isInfoEnabled()) LOG.info("readTxnInfo -- ENTRY, region " + m_regionDetails + ", Path: " + flushPath.toString());

          try {
              HColumnDescriptor family = new HColumnDescriptor();
              family.setBlockCacheEnabled(false);
              HFile.Reader reader = HFile.createReader(fs, flushPath, new CacheConfig(config, family), config);
              HFileScanner scanner = reader.getScanner(true, false);
              if (scanner == null){
                 if(LOG.isInfoEnabled()) LOG.info("readTxnInfo -- scanner is null for region region " + m_regionDetails);
                 return;
              }
              scanner.seekTo();
              //KeyValue firstVal = scanner.getKeyValue();
              Cell firstVal = scanner.getKeyValue();
              scanner.next();
              //KeyValue persistKV = scanner.getKeyValue();
              Cell persistKV = scanner.getKeyValue();

              if(firstVal == null || persistKV == null) {
                throw new IOException("Invalid values read from HFile in readTxnInfo");
              }

              Map<Long, TrxTransactionState> txnMap = new HashMap<Long, TrxTransactionState>();
              Map<Long, List<Long>> txnsToCheckMap = new HashMap<Long, List<Long>>();
              ByteArrayInputStream input = new ByteArrayInputStream(CellUtil.cloneValue(firstVal));

              TransactionStateMsg tsm  = TransactionStateMsg.parseDelimitedFrom(input);
              while (tsm != null) {
                TrxTransactionState ts = new TrxTransactionState(tsm.getTxId(),
                                                                 tsm.getSeqNum(),
                                                                 new AtomicLong(tsm.getLogSeqId()),
                                                                 m_Region.getRegionInfo(),
                                                                 m_Region.getTableDesc(),
                                                                 tHLog,
#ifdef CDH5.7 APACHE1.2 CDH5.16
								 configuredEarlyLogging, this.t_Region,
#else					  
								 configuredEarlyLogging,
#endif									  									 
                                                                 -1, m_regionName);  // do not worry about startId here
                ts.setStartSequenceNumber(tsm.getStartSeqNum()); 
                ts.setChoreMinSequenceNumber(ts.getStartSequenceNumber());  
                ts.setStatus(Status.values[tsm.getStatus()]);
                ts.setNeverReadOnly(true);
                if (RSConstants.ONLINE_BALANCE_ENABLED)
                  ts.setReadFromHdfs(true);
                List<Boolean> putOrDel = tsm.getPutOrDelList();
                List<MutationProto> puts = tsm.getPutList();
                List<MutationProto> deletes = tsm.getDeleteList();
                List<Long> savepointIds = tsm.getSavepointIdList();
                List<Long> pSavepointIds = tsm.getPSavepointIdList();

                int putIndex = 0;
                int deleteIndex = 0;
                int svptIndex = 0;
                if (LOG.isDebugEnabled()) LOG.debug("readTxnInfo -- size of list putOrDel : " + putOrDel.size());
                for (Boolean put : putOrDel) {
                  long svpt = savepointIds.get(svptIndex);
                  long psvpt = pSavepointIds.get(svptIndex);
                  svptIndex++;
                  if(put) {
                    Put writePut = ProtobufUtil.toPut(puts.get(putIndex++));
#ifdef APACHE1.2 CDH5.7 CDH5.16
                    if(rowIsInRange(regionInfo, writePut.getRow())) {
#else
                    if(m_Region.rowIsInRange(regionInfo, writePut.getRow())) {
#endif

                         if (LOG.isDebugEnabled()) LOG.debug("HAX - CALL addWrite, readTxInfo 1: "
                          + Hex.encodeHexString(writePut.getRow()) 
                          + " trans id: " + tsm.getTxId()
                          + " svpt id: " + svpt + ", psvpt id: " + psvpt
                          + " region info: " + m_regionDetails  );    
            
                         ts.addWrite(writePut, TrxRegionEndpoint.useCommitIdInCells, true, svpt, psvpt);
                    }
                    if(LOG.isDebugEnabled()) LOG.debug("TRAF_SB_READTXN Reinstate mutation: txid " + tsm.getTxId() + " put " + writePut.toString());
                  }
                  else {
                    Delete writeDelete = ProtobufUtil.toDelete(deletes.get(deleteIndex++));
#ifdef APACHE1.2 CDH5.7 CDH5.16
                    if(rowIsInRange(regionInfo, writeDelete.getRow())) {
#else
                    if(m_Region.rowIsInRange(regionInfo, writeDelete.getRow())) {
#endif                        
                        if (LOG.isDebugEnabled()) LOG.debug("HAX - CALL addDelete, readTxInfo 1: "
                          + Hex.encodeHexString(writeDelete.getRow()) 
                          + " trans id: " + tsm.getTxId()
                          + " svpt id: " + svpt + ", psvpt id: " + psvpt
                          + " region info: " + m_regionDetails  );  
                        
                        ts.addDelete(writeDelete, TrxRegionEndpoint.useCommitIdInCells, true, svpt, psvpt);
                    }
                    if(LOG.isDebugEnabled()) LOG.debug("TRAF_SB_READTXN Reinstate mutation: txid " + tsm.getTxId() + " delete " + writeDelete.toString());
                  }
                }
                
                List<ByteString> startRows = tsm.getSrStartRowList();
                List<ByteString> endRows = tsm.getSrEndRowList();
                List<Long> svpts = tsm.getSrSvptList();
                List<Long> psvpts = tsm.getSrPsvptList();
                int srIndex = 0;
                if ((startRows != null) && (startRows.size() > 0)) {
                     for (srIndex = 0; srIndex < startRows.size(); srIndex++) {
                         if (startRows.get(srIndex).isEmpty()) 
                             sr_start = null; //HConstants.EMPTY_START_ROW;
                         else
                             sr_start = startRows.get(srIndex).toByteArray();
                         if (endRows.get(srIndex).isEmpty()) 
                             sr_end = null; //HConstants.EMPTY_END_ROW;
                         else                         
                             sr_end = endRows.get(srIndex).toByteArray();
                         long sv = svpts.get(srIndex);
                         long psv = psvpts.get(srIndex);
                         ts.reinstateScan(sr_start, sr_end, sv, psv);
                         sstart = (sr_start == null) ? "NULL" : sr_start.toString();
                         send = (sr_end == null) ? "NULL" : sr_end.toString();                         
                   /*      if (sr_start == null)
                              sstart = " NULL ";
                         else     
                              sstart = sr_start.toString();
                         if (sr_end == null)
                              send = " NULL ";                 
                         else                  
                              send = sr_end.toString();
                   */
                         if(LOG.isDebugEnabled()) LOG.debug("TRAF_SB_READTXN Reinstate scan range: tid " + tsm.getTxId() + 
                                          " row " + sstart + " " + send + " " + sv);
                     }
                }                      
                
                txnsToCheckMap.put(tsm.getTxId(), tsm.getTxnsToCheckList());
                if(setRetry)
                  ts.setSplitRetry(true);
                txnMap.put(ts.getTransactionId(), ts);
                tsm  = TransactionStateMsg.parseDelimitedFrom(input);
              }

              for(TrxTransactionState ts : txnMap.values()) {
                for (Long txid : txnsToCheckMap.get(ts.getTransactionId())) {
                  TrxTransactionState mapTS = txnMap.get(txid);
                  if (RSConstants.ONLINE_BALANCE_ENABLED)
                    mapTS.setReadFromHdfs(true);
                  if(mapTS != null)
                    ts.addTransactionToCheck(mapTS);
                }
              }
              TransactionPersist txnPersistMsg = TransactionPersist.parseFrom(CellUtil.cloneValue(persistKV));

              if(txnPersistMsg == null) {
                throw new IOException("Invalid protobuf, message is null.");
              }
              for (Long txid : txnPersistMsg.getTxByIdList()) {
                Long key = getTransactionalUniqueId(txid);
		String leaseKey = getTransactionalLeaseId(txid);
                TrxTransactionState ts = txnMap.get(txid);
                if (ts != null) {
                  TrxTransactionState existingTs = transactionsById.get(key);
                  if(existingTs != null) {
                    for(WriteAction wa : existingTs.getWriteOrdering()) {
                      if(wa.getPut() != null) {

                        if (LOG.isDebugEnabled()) LOG.debug("HAX - CALL addWrite, readTxInfo 2: "
                          + Hex.encodeHexString(wa.getPut().getRow()) 
                          + " trans id: " + txid
                          + " region info: " + m_regionDetails  );                             
                                       
                        ts.addWrite(wa.getPut(), TrxRegionEndpoint.useCommitIdInCells, true);
                      }
                      else {
                          
                       if (LOG.isDebugEnabled()) LOG.debug("HAX - CALL addDelete, readTxInfo 2: "
                          + Hex.encodeHexString(wa.getDelete().getRow()) 
                          + " trans id: " + txid
                          + " region info: " + m_regionDetails  );      
                                     
                        ts.addDelete(wa.getDelete(), TrxRegionEndpoint.useCommitIdInCells, true);
                      }
                    }
                  }
                  synchronized (transactionsById) {
                      transactionsById.put(key, ts);
                  }
                  if (LockConstants.ENABLE_ROW_LEVEL_LOCK && ts.getIsRegionTx()) {
                      rsServer.addRegionTx(txid);
                  }

                  try {
                      transactionLeases.createLease(leaseKey, transactionLeaseTimeout, new TransactionLeaseListener(txid));
                  } catch (LeaseStillHeldException e) {
                      transactionLeases.renewLease(leaseKey);
                  }

                }
                else {
                  TrxTransactionState tsEntry = new TrxTransactionState(txid,
                                                 0,
                                                 new AtomicLong(0),
                                                 regionInfo,
                                                 m_Region.getTableDesc(),
                                                 tHLog,
#ifdef CDH5.7 APACHE1.2 CDH5.16
						 configuredEarlyLogging, this.t_Region,
#else					  
						 configuredEarlyLogging,
#endif									  										
                                                 -1, m_regionName);  // do not worry about startId here
                  if (RSConstants.ONLINE_BALANCE_ENABLED)
                      tsEntry.setReadFromHdfs(true);
                  synchronized (transactionsById) {
                      transactionsById.putIfAbsent(key, tsEntry);
                  }
                  if (LockConstants.ENABLE_ROW_LEVEL_LOCK && ts.getIsRegionTx()) {
                      rsServer.addRegionTx(txid);
                  }
                }
              }

              for (int i = 0; i < txnPersistMsg.getSeqNoListSeqCount(); i++) {
                TrxTransactionState ts = txnMap.get(txnPersistMsg.getSeqNoListTxn(i));
                if (ts!=null)
                  commitedTransactionsBySequenceNumber.put(txnPersistMsg.getSeqNoListSeq(i), ts);
              }

              this.nextSequenceId = new AtomicLong(txnPersistMsg.getNextSeqId());
              if (RSConstants.ONLINE_BALANCE_ENABLED)
                  this.onlineEpoch = TrxEnvironmentEdgeManager.currentTime();
              else
                  this.onlineEpoch = txnPersistMsg.getOnlineEpoch();
              if (LOG.isInfoEnabled()) {
                  LOG.info("Setting onlineEpoch after split to " + this.onlineEpoch + " in region " + m_regionDetails);
              }
            }
            catch (FileNotFoundException e1) {
                 if (LOG.isWarnEnabled()) {
                     LOG.warn("readTxnInfo: FileNotFound: Table " + regionInfo.getTable().getNameAsString() +
                        ", Path: " + flushPath.toString() + ", likely table is restored, call cleanup ");
                 }
               cleanupTRX(regionInfo.getTable().getNameAsString());
            }
            catch(IOException e) {
               LOG.error("readTxnInfo: IOexception: ", e);
               cleanupTRX(regionInfo.getTable().getNameAsString());
            }
          if(LOG.isTraceEnabled()) LOG.trace("readTxnInfo -- EXIT");

  }
  
  public void cleanupTRX(String regionName) {     
         if (LOG.isInfoEnabled()) {
             LOG.info("cleanup transactional context in TRX endpoint for region " + regionName);
         }
         this.transactionsById.clear();
         this.commitPendingTransactions.clear();
         this.commitedTransactionsBySequenceNumber.clear();
         this.nextSequenceId = new AtomicLong(0);
         this.onlineEpoch = TrxEnvironmentEdgeManager.currentTime();
         if (LOG.isInfoEnabled()) {
             LOG.info("cleanup transactional context in EPCP completes. ");
         }
  }

  public void setBlockAll(boolean value) {
    if (LockConstants.ENABLE_ROW_LEVEL_LOCK) {
       checkAndCreateLockManager();
       lockManager.setBlockAll(value); 
    }
    blockAll.set(value);

    // for safety
    if (value == true) {
        blockNewTrans.set(value);
        blockNonPhase2.set(value);
    }
 }

  public void setBlockNonPhase2(boolean value) {
    blockNonPhase2.set(value);

    // for safety
    if (value == true)
        blockNewTrans.set(value);
  }

  public void setNewTrans(boolean value) {
    blockNewTrans.set(value);
   }
   
  public void setClosing(boolean value) {
    closing.set(value);
  }

  // The following are methods for the Trafodion SQL coprocessors.

  // compares two qualifiers as unsigned, lexicographically ordered byte strings

  static private boolean isQualifierLessThanOrEqual(Cell nextKv, Cell currKv) {
    int currLength = currKv.getQualifierLength(); 
    int currOffset = currKv.getQualifierOffset();
    byte [] currQual = currKv.getQualifierArray();
    int nextLength = nextKv.getQualifierLength(); 
    int nextOffset = nextKv.getQualifierOffset();
    byte [] nextQual = nextKv.getQualifierArray();   

    int minLength = nextLength;
    if (currLength < nextLength)
      minLength = currLength;

    for (int i = 0; i < minLength; i++) {
      // ugh... have to do some gymnastics to make this an
      // unsigned comparison
      int nextQualI = nextQual[i+nextOffset];
      if (nextQualI < 0)
        nextQualI = nextQualI + 256;
      int currQualI = currQual[i+currOffset];
      if (currQualI < 0)
        currQualI = currQualI + 256;

      if (nextQualI < currQualI)
        return true;
      else if (nextQualI > currQualI)
        return false;
      // else equal, move on to next byte
    }

    // the first minLength bytes are the same; the shorter array
    // is regarded as less

    boolean rc = (nextLength <= currLength);      

    return rc;
  }

  
  // debugging function

  private static String bytesToHex(byte[] in) {
    final StringBuilder builder = new StringBuilder();
    for(byte b : in) {
        builder.append(String.format("%02x", b));
    }
    return builder.toString();
  }

  // Returns data needed to estimate the row count in the table.
  // Entry counts and total size in bytes are extracted from HFiles.
  // For non-aligned tables (numCols > 1), sampling is done in order
  // to estimate how many entries make up a row on average.

  @Override
  public void trafEstimateRowCount(RpcController controller,
			           TrafEstimateRowCountRequest request,
			           RpcCallback<TrafEstimateRowCountResponse> done) {

    TrafEstimateRowCountResponse response = null;
    Throwable t = null;

    int numCols = request.getNumCols();

    // To estimate incidence of nulls, read the first 500 rows worth
    // of KeyValues.
    final int ROWS_TO_SAMPLE = 500;
    int putKVsSampled = 0;
    int nonPutKVsSampled = 0;
    int missingKVsCount = 0;
    int sampleRowCount = 0;
    long totalEntries = 0;   // KeyValues in all HFiles for table
    long totalSizeBytes = 0; // Size of all HFiles for table 
    long estimatedTotalPuts = 0;
    boolean more = true;
    long estimatedRowCount = 0;

    // Access the file system to go directly to the table's HFiles.
    // Create a reader for the file to access the KV entry count and
    // size in bytes stored in the trailer block.
    
    // For aligned format tables, the number of rows equals the
    // number of KeyValue entries. For non-aligned format, it's
    // more complicated. There is a KeyValue entry for each 
    // column value, except the KeyValue may be missing because
    // the column has a null value or because the column has a
    // default value that has not been materialized.

    // For non-aligned format tables, we sample some rows and
    // count how many entries there are per row, so our caller
    // can estimate the average number of missing values per row.
    // Once our caller has that estimate, it can estimate the
    // number of rows.

    // We only do the sampling for non-aligned tables (numCols > 1),
    // and we only do it on the first HFile of the first Region.
    // The first Region is detected by having a null start key.

    CacheConfig cacheConf = new CacheConfig(config);
    byte[] startKey = regionInfo.getStartKey();

    // Get the list of store files in column family '#1'. There might
    // not be any. For example, a new Trafodion table might be entirely
    // in memstore with nothing written out yet. Or we may be accessing
    // a native HBase table which lacks the '#1' colum family.
    List<String> storeFileList = null;
    try {
      byte[] familyName = "#1".getBytes();
      byte[][] familyNames = { familyName };
      storeFileList = m_Region.getStoreFileList(familyNames);
    }
    catch (IllegalArgumentException iae) {
      // this gets thrown when the column family doesn't exist;
      // we'll just use an empty list instead
      storeFileList = new ArrayList<String>();
    }

    if (LOG.isDebugEnabled()) {
      LOG.debug("Trafodion estimate row count sees " + storeFileList.size() + " files.");
      for (String sfn : storeFileList) {
        LOG.debug("*** " + sfn);
      }
      if (startKey == null)
        LOG.debug("startKey is null.");
      else
        LOG.debug("startKey.length is " + startKey.length + ", startKey is hex " + bytesToHex(startKey));
    }
 
    try {
      FileSystem fileSystem = FileSystem.get(config);

      for (String storeFileName : storeFileList) {
        Path path = new Path(storeFileName);
        // Make sure the file name conforms to HFile name pattern.
        if (!StoreFileInfo.isHFile(path)) {
          if (LOG.isDebugEnabled()) LOG.debug("Trafodion estimate row count file name " + path + " is not an HFile.");
          continue;
        }
        HFile.Reader reader = HFile.createReader(fileSystem, path, cacheConf, config);
        try {
          totalEntries += reader.getEntries();
          totalSizeBytes += reader.length();        
          if (ROWS_TO_SAMPLE > 0 &&
              numCols > 1 &&  // only need to do this for non-aligned format
              (startKey == null || startKey.length == 0) &&  // first region only
              totalEntries == reader.getEntries()) {  // first file only

            // Trafodion column qualifiers are ordinal numbers, but are represented
            // as varying length unsigned little-endian integers in lexicographical
            // order. So, for example, in a table with 260 columns, the column
            // qualifiers (if present) will be read in this order: 
            // 1 (x'01'), 257 (x'0101'), 2 (x'02'), 258 (x'0201'), 3 (x'03'),
            // 259 (x'0301'), 4 (x'04'), 260 (x'0401'), 5 (x'05'), 6 (x'06'), 
            // 7 (x'07'), ...
            // We have crossed the boundary to the next row if and only if the
            // next qualifier read is less than or equal to the previous, 
            // compared unsigned, lexicographically.

            HFileScanner scanner = reader.getScanner(false, false, false);
            scanner.seekTo();  //position at beginning of first data block

            // the next line should succeed, as we know the HFile is non-empty
            Cell currKv = scanner.getKeyValue();
            while ((more) && (currKv.getTypeByte() != KeyValue.Type.Put.getCode())) {
              nonPutKVsSampled++;
              more = scanner.next();
              currKv = scanner.getKeyValue();
            }
            if (more) {
              // now we have the first KeyValue in the HFile

              int putKVsThisRow = 1;
              putKVsSampled++;
              sampleRowCount++;  // we have at least one row
              more = scanner.next();
    
              while ((more) && (sampleRowCount <= ROWS_TO_SAMPLE)) {
                Cell nextKv = scanner.getKeyValue();
                if (nextKv.getTypeByte() == KeyValue.Type.Put.getCode()) {
                  if (isQualifierLessThanOrEqual(nextKv,currKv)) {
                    // we have crossed a row boundary
                    sampleRowCount++;
                    missingKVsCount += (numCols - putKVsThisRow);
                    putKVsThisRow = 1;
                  } else {
                    putKVsThisRow++;
                  }
                  currKv = nextKv;
                  putKVsSampled++;
                } else {
                  nonPutKVsSampled++;  // don't count these toward the number
                }
              more = scanner.next();
              }
            }
            //scanner.close();  This API is not available until HBase 2.0
  
            if (sampleRowCount > ROWS_TO_SAMPLE) {
              // we read one KeyValue beyond the ROWS_TO_SAMPLE-eth row, so
              // adjust counts for that
              putKVsSampled--;
              sampleRowCount--;
            }
          }  // code for first file
        } catch (IOException exp1) {
          if (LOG.isErrorEnabled()) LOG.error("Trafodion estimate row count encountered exception ", exp1);
          t = exp1;
        } finally {
          reader.close(false);
        }
      } // for

    } catch (IOException exp2) {
      if (LOG.isErrorEnabled()) LOG.error("Trafodion estimate row count encountered exception ", exp2);
      if (t == null)  // don't bury the root cause if an exception also occurred in the for loop
        t = exp2;  
    }

    // don't you just love Java + Maven? it takes 112 characters to specify the type of the next variable :-)
    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.TrafEstimateRowCountResponse.Builder
      responseBuilder = TrafEstimateRowCountResponse.newBuilder();
    responseBuilder.setTotalEntries(totalEntries).
      setTotalSizeBytes(totalSizeBytes).
      setPutKVsSampled(putKVsSampled).
      setNonPutKVsSampled(nonPutKVsSampled).
      setMissingKVsCount(missingKVsCount);

    if (t != null)
    {
      responseBuilder.setHasException(true);
      responseBuilder.setException(t.toString());
    }

    response = responseBuilder.build();
    done.run(response);
  }

  @Override     
  public void lockRequired(RpcController controller,
			   LockRequiredRequest request,
			   RpcCallback<LockRequiredResponse> done) {

    int lockMode = request.getLockMode();
    long transactionId = request.getTransactionId();
    long savepointId = TrxTransactionState.getSavepointId(request.getSavepointId());
    long pSavepointId = TrxTransactionState.getSavepointId(request.getPSavepointId());
    boolean implicitSavepoint = TrxTransactionState.isImplicitSavepoint(request.getSavepointId());
    boolean implicitPSavepoint = TrxTransactionState.isImplicitSavepoint(request.getPSavepointId());
    boolean result = true;
    MemoryUsageException mue = null;
    Throwable t = null;
    String query = Bytes.toString(request.getQueryContext().toByteArray());

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.LockRequiredResponse.Builder lockRequiredResponseBuilder = LockRequiredResponse.newBuilder();

    if (LOG.isTraceEnabled()) LOG.trace("lockRequired - transactionId " + transactionId
            + ", savepointId " + savepointId + " implicit savepoint " + implicitSavepoint
            + " lockMode" + lockMode + ", region " + m_regionDetails);

    if (memoryThrottle == true) {
        if(memoryUsageWarnOnly == true)  {
            if (LOG.isWarnEnabled()) {
                LOG.warn("lockRequired - performing memoryPercentage " + memoryPercentage + ", warning memory usage exceeds indicated percentage");
            }
        }
        else {
          mue = new MemoryUsageException("lockRequired memory usage exceeds " + memoryUsageThreshold + " percent, trxId is " + transactionId);
          if (LOG.isTraceEnabled()) LOG.trace("lockRequired - performing memoryPercentage " + memoryPercentage + ", generating memory usage exceeds indicated percentage exception");
        }
    }

    if (mue == null) {
      try {
        TrxTransactionState state = this.beginTransIfNotExist(transactionId, -1/*startId*/);
        lock(transactionId, savepointId, pSavepointId, lockMode, implicitSavepoint, query);
      } catch(Throwable e) {
        result = false;
        t = e;
      }
    }

     if (LOG.isTraceEnabled()) LOG.trace("lockRequired - transactionId " + transactionId + " savepointId " + savepointId + " lockMode" + lockMode + ", result is " + result);

     lockRequiredResponseBuilder.setHasException(false);

     if (t != null){
       lockRequiredResponseBuilder.setHasException(true);
       lockRequiredResponseBuilder.setException(t.toString());
     }

     if (mue != null){
       if (LOG.isWarnEnabled()) LOG.warn("lockRequired - performing memoryPercentage " + memoryPercentage
        + ", posting memory usage exceeds indicated percentage");
       lockRequiredResponseBuilder.setHasException(true);
       lockRequiredResponseBuilder.setException(mue.toString());
     }

     LockRequiredResponse lockRequiredResponse = lockRequiredResponseBuilder.build();

     done.run(lockRequiredResponse);
  }

  @Override
  public void releaseLock(RpcController controller,
                           ReleaseLockRequest request,
                           RpcCallback<ReleaseLockResponse> done) {
    List<Long> transactionIds = request.getTransactionIdsList();
    String requestRegionName = request.getRegionName().toStringUtf8();
    boolean result = true;
    MemoryUsageException mue = null;
    Throwable t = null;

    org.apache.hadoop.hbase.coprocessor.transactional.generated.TrxRegionProtos.ReleaseLockResponse.Builder releaseLockResponseBuilder = ReleaseLockResponse.newBuilder();

    if (LOG.isTraceEnabled()) LOG.trace("releaseLock - transactionIds " + transactionIds + " requestRegionName: " + requestRegionName + ", region " + m_regionName);

    if (memoryThrottle == true) {
        if(memoryUsageWarnOnly == true)  {
            if (LOG.isWarnEnabled()) {
                LOG.warn("releaseLock - performing memoryPercentage " + memoryPercentage + ", warning memory usage exceeds indicated percentage");
            }
        }
        else {
          mue = new MemoryUsageException("releaseLock memory usage exceeds " + memoryUsageThreshold + " percent, trxIds is " + transactionIds);
          if (LOG.isTraceEnabled()) LOG.trace("releaseLock - performing memoryPercentage " + memoryPercentage + ", generating memory usage exceeds indicated percentage exception");
        }
    }

    if (mue == null && (requestRegionName.length() == 0 || m_regionName.equals(requestRegionName))) {
      try {
          unLockRegionAll(transactionIds);
      } catch(Throwable e) {
        result = false;
        t = e;
      }
    }

     releaseLockResponseBuilder.setHasException(false);

     if (t != null){
       releaseLockResponseBuilder.setHasException(true);
       releaseLockResponseBuilder.setException(t.toString());
     }

     if (mue != null){
       if (LOG.isWarnEnabled()) LOG.warn("lockRequired - performing memoryPercentage " + memoryPercentage
        + ", posting memory usage exceeds indicated percentage");
       releaseLockResponseBuilder.setHasException(true);
       releaseLockResponseBuilder.setException(mue.toString());
     }

     ReleaseLockResponse releaseLockResponse = releaseLockResponseBuilder.build();

     done.run(releaseLockResponse);
  }
  
  public RetCode lock(long tid, byte[] rowKey, int lockMode, final String query) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return RetCode.OK;
      }
      if (transactionsById.get(tid) == null) {
          checkRetCode(RetCode.CANCEL_FOR_ROLLBACK);
      }
      checkAndCreateLockManager();
      RowKey rowKeyString = getRowidFromRowKey(rowKey);
      if (LOG.isTraceEnabled()) LOG.trace("Row Lock tid:" + tid + " regionName:" + m_regionName + " rowKeyString:" + rowKeyString + " lockMode:" + lockMode);
      RetCode retCode = lockManager.lockAcquire(tid, rowKeyString, lockMode, lockTimeOut, query);
      checkRetCode(retCode);
      if (LOG.isTraceEnabled()) LOG.trace("Row Lock Success tid: " + tid + " regionName:" + m_regionName + " rowKeyString:" + rowKeyString + " lockMode:" + lockMode);
      return retCode;
  }

  public RetCode lockRegionTx(long tid, byte[] rowKey, int lockMode, final String query) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return RetCode.OK;
      }
      if (transactionsById.get(tid) == null) {
          checkRetCode(RetCode.CANCEL_FOR_ROLLBACK);
      }
      checkAndCreateLockManager();
      RowKey rowKeyString = getRowidFromRowKey(rowKey);
      if (LOG.isTraceEnabled()) LOG.trace("Row Lock tid:" + tid + " regionName:" + m_regionName + " rowKeyString:" + rowKeyString + " lockMode:" + lockMode);
      RetCode retCode = lockManager.lockAcquire(tid, rowKeyString, lockMode, lockTimeOut, query);
      if (retCode != RetCode.OK && retCode != RetCode.OK_LOCKED && retCode != RetCode.OK_WITHRETRY) {
          unLockRegionAll(tid);
          throw getException(retCode);
      }
      if (LOG.isTraceEnabled()) LOG.trace("Row Lock Success tid: " + tid + " regionName:" + m_regionName + " rowKeyString:" + rowKeyString + " lockMode:" + lockMode);
      return retCode;
  }

  public RetCode lock(long tid, long savepointId, long pSavepointId, byte[] rowKey, int lockMode, boolean implicitSavepoint, final String query) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return RetCode.OK;
      }
      if (transactionsById.get(tid) == null) {
          checkRetCode(RetCode.CANCEL_FOR_ROLLBACK);
      }
      checkAndCreateLockManager();
      RowKey rowKeyString = getRowidFromRowKey(rowKey);
      if (LOG.isTraceEnabled()) LOG.trace("Row Lock tid:" + tid + " savepointId:" + savepointId + " implicitSavepoint:" + implicitSavepoint + " pSavepointId:" + pSavepointId + " regionName:" + m_regionName + " rowKeyString:" + rowKeyString + " lockMode:" + lockMode);
      RetCode retCode = lockManager.lockAcquire(tid, savepointId, pSavepointId, rowKeyString, lockMode, lockTimeOut, implicitSavepoint, query);
      checkRetCode(retCode);
      if (LOG.isTraceEnabled()) LOG.trace("Row Lock Success tid: " + tid + " savepointId:" + savepointId + " implicitSavepoint:" + implicitSavepoint + " pSavepointId:" + pSavepointId + " regionName:" + m_regionName + " rowKeyString:" + rowKeyString + " lockMode:" + lockMode);
      return retCode;
  }

  public RetCode lockRegionTx(long tid, long savepointId, byte[] rowKey, int lockMode, final String query) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return RetCode.OK;
      }
      if (transactionsById.get(tid) == null) {
          checkRetCode(RetCode.CANCEL_FOR_ROLLBACK);
      }
      checkAndCreateLockManager();
      RowKey rowKeyString = getRowidFromRowKey(rowKey);
      if (LOG.isTraceEnabled()) LOG.trace("Row Lock tid:" + tid + " savepointId:" + savepointId + " regionName:" + m_regionName + " rowKeyString:" + rowKeyString + " lockMode:" + lockMode);
      RetCode retCode = lockManager.lockAcquire(tid, savepointId, rowKeyString, lockMode, lockTimeOut, query);
      if (retCode != RetCode.OK && retCode != RetCode.OK_LOCKED && retCode != RetCode.OK_WITHRETRY) {
          unLockRegionAll(tid, savepointId);
          throw getException(retCode);
      }
      if (LOG.isTraceEnabled()) LOG.trace("Row Lock Success tid: " + tid + " savepointId:" + savepointId + " regionName:" + m_regionName + " rowKeyString:" + rowKeyString + " lockMode:" + lockMode);
      return retCode;
  }

  public RetCode tryLock(long tid, byte[] rowKey, int lockMode, final String query) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return RetCode.OK;
      }
      if (transactionsById.get(tid) == null) {
          checkRetCode(RetCode.CANCEL_FOR_ROLLBACK);
      }
      checkAndCreateLockManager();
      RowKey rowKeyString = getRowidFromRowKey(rowKey);
      if (LOG.isTraceEnabled()) LOG.trace("Row tryLock tid:" + tid + " regionName:" + m_regionName + " rowKeyString:" + rowKeyString + " lockMode:" + lockMode);
      RetCode retCode = lockManager.lockAcquire(tid, rowKeyString, lockMode, lockTimeOut, query);
      checkRetCode(retCode);
      if (LOG.isTraceEnabled()) LOG.trace("Row tryLock Success tid: " + tid + " regionName:" + m_regionName + " rowKeyString:" + rowKeyString + " lockMode:" + lockMode);
      return retCode;
  }

  public RetCode tryLock(long tid, long savepointId, long pSavepointId, byte[] rowKey, int lockMode, boolean implicitSavepoint, final String query) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return RetCode.OK;
      }
      if (transactionsById.get(tid) == null) {
          checkRetCode(RetCode.CANCEL_FOR_ROLLBACK);
      }
      checkAndCreateLockManager();
      RowKey rowKeyString = getRowidFromRowKey(rowKey);
      if (LOG.isTraceEnabled()) LOG.trace("Row tryLock tid:" + tid + " savepointId:" + savepointId + " implicitSavepoint:" + implicitSavepoint + " pSavepointId:" + pSavepointId + " regionName:" + m_regionName + " rowKeyString:" + rowKeyString + " lockMode:" + lockMode);
      RetCode retCode = lockManager.lockAcquire(tid, savepointId, pSavepointId, rowKeyString, lockMode, lockTimeOut, implicitSavepoint, query);
      checkRetCode(retCode);
      if (LOG.isTraceEnabled()) LOG.trace("Row tryLock Success tid: " + tid + " savepointId:" + savepointId + " implicitSavepoint:" + implicitSavepoint + " pSavepointId:" + pSavepointId + " regionName:" + m_regionName + " rowKeyString:" + rowKeyString + " lockMode:" + lockMode);
      return retCode;
  }

  public RetCode tryLock(long tid, long savepointId, long pSavepointId, int lockMode, boolean implicitSavepoint, final String query) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return RetCode.OK;
      }
      if (transactionsById.get(tid) == null) {
          checkRetCode(RetCode.CANCEL_FOR_ROLLBACK);
      }
      checkAndCreateLockManager();
      if (LOG.isTraceEnabled()) LOG.trace("Table tryLock tid:" + tid + " savepointId:" + savepointId + " implicitSavepoint:" + implicitSavepoint + " pSavepointId:" + pSavepointId + " regionName:" + m_regionName + " lockMode:" + lockMode);
      RetCode retCode = lockManager.lockAcquire(tid, savepointId, pSavepointId, lockMode, lockTimeOut, implicitSavepoint, query);
      checkRetCode(retCode);
      if (LOG.isTraceEnabled()) LOG.trace("Table tryLock Success tid: " + tid + " savepointId:" + savepointId + " implicitSavepoint:" + implicitSavepoint + " pSavepointId:" + pSavepointId + " regionName:" + m_regionName + " lockMode:" + lockMode);
      return retCode;
  }
  
  public void unLock(long tid, byte[] rowKey, int lockMode) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return;
      }
      checkAndCreateLockManager();
      RowKey rowKeyString = getRowidFromRowKey(rowKey);
      if (LOG.isDebugEnabled()) LOG.debug("Row unLock tid:" + tid + " regionName:" + m_regionName + " rowKeyString: " + rowKeyString + " lockMode: " + lockMode);
      Boolean success = lockManager.lockRelease(tid, rowKeyString, lockMode);
      if (!success) {
          throw new IOException("failed to get unLock ");
      }
      if (LOG.isDebugEnabled()) LOG.debug("Row unLock Success tid:" + tid + " regionName:" + m_regionName + " rowKeyString:" + rowKeyString + " lockMode:" + lockMode);
  }

  public void unLock(long tid, long savepointId, byte[] rowKey, int lockMode) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return;
      }
      checkAndCreateLockManager();
      RowKey rowKeyString = getRowidFromRowKey(rowKey);
      if (LOG.isDebugEnabled()) LOG.debug("Row unLock tid:" + tid + " savepointId:" + savepointId + " regionName:" + m_regionName + " rowKeyString: " + rowKeyString + " lockMode: " + lockMode);
      Boolean success = lockManager.lockRelease(tid, savepointId, rowKeyString, lockMode);
      if (!success) {
          throw new IOException("failed to get unLock ");
      }
      if (LOG.isDebugEnabled()) LOG.debug("Row unLock Success tid:" + tid + " savepointId:" + savepointId + " regionName:" + m_regionName + " rowKeyString:" + rowKeyString + " lockMode:" + lockMode);
  }

  public RetCode lock(long tid, int lockMode, final String query) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return RetCode.OK;
      }
      if (transactionsById.get(tid) == null) {
          checkRetCode(RetCode.CANCEL_FOR_ROLLBACK);
      }
      checkAndCreateLockManager();
      if ((lockMode == LockMode.LOCK_RS || lockMode == LockMode.LOCK_RX) && !LockConstants.LOCK_ENABLE_DEADLOCK_DETECT) {
          return RetCode.OK;
      }
      if (LOG.isTraceEnabled()) LOG.trace("Table Lock tid:" + tid + " regionName:" + m_regionName + " lockMode:" + lockMode);
      RetCode retCode = lockManager.lockAcquire(tid, lockMode, lockTimeOut, query);
      checkRetCode(retCode);
      if (LOG.isTraceEnabled()) LOG.trace("Table Lock Success tid:" + tid + " regionName:" + m_regionName + " lockMode:" + lockMode);
      return retCode;
  }

  public RetCode lock(long tid, long savepointId, long pSavepointId, int lockMode, boolean implicitSavepoint, final String query) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return RetCode.OK;
      }
      if (transactionsById.get(tid) == null) {
          checkRetCode(RetCode.CANCEL_FOR_ROLLBACK);
      }
      checkAndCreateLockManager();
      if (LOG.isTraceEnabled()) LOG.trace("Table Lock tid:" + tid + " savepointId:" + savepointId + " implicitSavepoint:" + implicitSavepoint + " pSavepointId:" + pSavepointId + " regionName:" + m_regionName + " lockMode:" + lockMode);
      RetCode retCode = lockManager.lockAcquire(tid, savepointId, pSavepointId, lockMode, lockTimeOut, implicitSavepoint, query);
      checkRetCode(retCode);
      if (LOG.isTraceEnabled()) LOG.trace("Table Lock Success tid:" + tid + " savepointId:" + savepointId + " implicitSavepoint:" + implicitSavepoint + " pSavepointId:" + pSavepointId + " regionName:" + m_regionName + " lockMode:" + lockMode);
      return retCode;
  }

  public void unLock(long tid, int lockMode) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return;
      }
      checkAndCreateLockManager();
      if (LOG.isDebugEnabled()) LOG.debug("Table unLock tid:" + tid + " regionName:" + m_regionName + " lockMode: " + lockMode);
      Boolean success = lockManager.lockRelease(tid, lockMode);
      if (!success) {
          throw new IOException("failed to get unLock ");
      }
      if (LOG.isDebugEnabled()) LOG.debug("Table unLock Success tid:" + tid + " regionName:" + m_regionName + " lockMode:" + lockMode);
  }

  public void unLock(long tid, long savepointId, int lockMode) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return;
      }
      checkAndCreateLockManager();
      if (LOG.isDebugEnabled()) LOG.debug("Table unLock tid:" + tid + " savepointId:" + savepointId + " regionName:" + m_regionName + " lockMode: " + lockMode);
      Boolean success = lockManager.lockRelease(tid, savepointId, lockMode);
      if (!success) {
          throw new IOException("failed to get unLock ");
      }
      if (LOG.isDebugEnabled()) LOG.debug("Table unLock Success tid:" + tid + " savepointId:" + savepointId + " regionName:" + m_regionName + " lockMode:" + lockMode);
  }

  public void unLockRegionAll(long tid) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return;
      }
      checkAndCreateLockManager();
      if (LOG.isTraceEnabled()) LOG.trace("unLockRegionAll tid:" + tid + " regionName:" + m_regionName);
      Boolean success = lockManager.lockReleaseAll(tid);
      if (!success) {
          throw new IOException("failed to get unLockRegionAll ");
      }
      if (LOG.isTraceEnabled()) LOG.trace("unLockRegionAll Success tid:" + tid + " regionName:" + m_regionName);
  }

  public void unLockRegionAll(List<Long> tids) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return;
      }
      checkAndCreateLockManager();
      if (LOG.isTraceEnabled()) LOG.trace("unLockRegionAll tids:" + tids + " regionName:" + m_regionName);
      Boolean success = lockManager.lockReleaseAll(tids);
      if (!success) {
          throw new IOException("failed to get unLockRegionAll ");
      }
      if (LOG.isTraceEnabled()) LOG.trace("unLockRegionAll Success tids:" + tids + " regionName:" + m_regionName);
  }

  public void unLockRegionAll(long tid, long savepointId) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return;
      }
      checkAndCreateLockManager();
      if (LOG.isTraceEnabled()) LOG.trace("unLockRegionAll tid:" + tid + " savepointId:" + savepointId + " regionName:" + m_regionName);
      Boolean success = lockManager.lockReleaseAll(tid, savepointId);
      if (!success) {
          throw new IOException("failed to get unLockRegionAll ");
      }
      if (LOG.isTraceEnabled()) LOG.trace("unLockRegionAll Success tid:" + tid + " savepointId:" + savepointId + " regionName:" + m_regionName);
  }

  public void unLockRegionAll() throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return;
      }
      checkAndCreateLockManager();
      if (LOG.isTraceEnabled()) LOG.trace("unLockRegionAll regionName:" + m_regionName);
      lockManager.lockReleaseAll();
      if (LOG.isTraceEnabled()) LOG.trace("unLockRegionAll Success regionName:" + m_regionName);
  }

  public void unLockAll(long tid) {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return;
      }
      List<Long> txIDs = new ArrayList<Long>();
      txIDs.add(tid);
      if (LOG.isWarnEnabled()) {
          LOG.warn("unLockAll: " + txIDs);
      }
      rsServer.unLockAll(txIDs);
  }

  public void flushSvptToTx(long tid, long savepointId) {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return;
      }
      checkAndCreateLockManager();
      if (LOG.isTraceEnabled()) LOG.trace("flushSvptToTx tid:" + tid + " savepointId:" + savepointId + " regionName:" + m_regionName);      
      lockManager.flushSvptToTx(tid, savepointId);
  }

  /*public void rwLock(Lock lock) throws IOException {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return;
      }
      if (LOG.isTraceEnabled()) LOG.trace("rwLock lock:" + lock);
      boolean lockRet = false;
      try {
          lockRet = lock.tryLock(lockTimeOut, TimeUnit.MILLISECONDS);
      } catch (Exception e) {
          lockRet = false;
          LOG.error("failed to rwLock: ", e);
      }
      if (!lockRet) {
          throw new IOException(new LockTimeOutException("failed to get rwLock:" + lock));
      }
  }

  public void rwUnLock(Lock lock) {    
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return;
      }
      if (LOG.isTraceEnabled()) LOG.trace("rwUnLock lock:" + lock);
      try {
          lock.unlock();
      } catch (Exception e) {
          LOG.error("failed to unlock rwLock", e);
      }
  }*/

  // transform isolation level to array index
  /*  transform rule          in ComTransInfo.h  enum IsolationLevel
      READ_UNCOMMITTED_ACCESS_   = 00 -> 0
      READ_COMMITTED_ACCESS_     = 10 -> 1
      REPEATABLE_READ_ACCESS_    = 20 -> 2
      SERIALIZABLE_ACCESS_       = 30 -> use readCommitted  in ex_transaction.cpp  isolationLevel default is TransMode::SERIALIZABLE_
      ACCESS_TYPE_NOT_SPECIFIED_ = -1 -> use readCommitted
  */
  public int transformIsolationLevel(int isolation) {
      if (isolation == 0) {
          return READUNCOMMITTED;
      } else if (isolation == 10) {
          return READCOMMITTED;
      } else if (isolation == 20) {
          return REPEATEABLEREAD;
      } else if (isolation == 30) {
          return READCOMMITTED;
      } else if (isolation == -1) {
          return READCOMMITTED;
      }else {
          throw new RuntimeException("Isolation level " + isolation + " Not support");
      }
  }

  private RowKey getRowidFromRowKey(byte[] rowKey) {
      return new RowKey(rowKey);
  }

  private IOException getException(RetCode retCode) {
      switch (retCode) {
          case TIMEOUT:
              return new IOException(new LockTimeOutException("LockTimeOutException failed to get lock "));
          case FINAL_TIMEOUT:
              return new IOException(new LockTimeOutException("Final LockTimeOutException failed to get lock "));
          case CANCEL_FOR_DEADLOCK:
              return new IOException(new DeadLockException("DeadLockException failed to get lock Region: " + m_regionName));
          case CANCEL_FOR_ROLLBACK:
              return new IOException(new LockTimeOutException("LockTimeOutException failed to get lock for transaction rollbacked Region: " + m_regionName));
          case CANCEL_FOR_SPLIT:
              return new IOException("FailedToLockException failed to get lock for region split Region: " + m_regionName);
          case CANCEL_FOR_MOVE:
              return new IOException("FailedToLockException failed to get lock for region move Region: " + m_regionName);
          case CANCEL_FOR_NEW_RPC_REQUEST:
              return new IOException("FailedToLockException failed to get lock for new rpc request arrived Region: " + m_regionName);
          case CANCEL_FOR_INTENTLOCK_FAIL:
              return new IOException("FailedToLockException failed to get lock for intent lock failed Region: " + m_regionName);
          case CANCEL_FOR_OTHER_REASON:
              return new IOException("FailedToLockException failed to get lock for other reason Region: " + m_regionName);
          case CANCEL_FOR_NOT_ENOUGH_LOCK_RESOURCES:
              return new IOException(new LockNotEnoughResourcsException("LockNotEnoughResourcsException failed to get lock for not enough lock resources Region: " + m_regionName));
          case CANCEL_FOR_CLOSING_REGION:
              return new IOException("closing region, no more transactional activity allowed. Region: " + m_regionName);
          case CANCEL_FOR_OOM:
              return new IOException(new OutOfMemoryError("No enough memory on regionServer " + lv_hostName));
          default:
            return new IOException("FailedToLockException failed to get lock for unexpected retCode " + retCode + " Region: " + m_regionName);
      }
  }
  
 private void tmpLockRange(byte[] startkey, byte[] endkey, long tid)
  {
     synchronized(tmpRangeLock) {
        long currentts = TrxEnvironmentEdgeManager.currentTime();
        trafLockInfo tli = new trafLockInfo(tid, currentts);
        tli.setStartKey(startkey);
        tli.setEndKey(endkey);
        tli.setIsRead();
        tmpRangeLock.add(tli);
     }
  }


   private boolean checkRangeLock(ByteArrayKey k, long tid ) {
      if( enableTmpReadWriterLock == false) return false; 
        synchronized(tmpRangeLock) {
          for(trafLockInfo lk : tmpRangeLock){
            if( Bytes.equals(lk.getStartKey(), HConstants.EMPTY_START_ROW ) )
              {
                if( Bytes.equals(lk.getEndKey(), HConstants.EMPTY_END_ROW ) ) {
                  if(tid != lk.getTid())
                    return true;
                }
                else {
                  if( Bytes.compareTo( k.getBytesArray(), lk.getEndKey()) <= 0) {
                    if(tid != lk.getTid())
                      return true;
                  }
                }
              }

            if( Bytes.equals(lk.getEndKey(), HConstants.EMPTY_END_ROW ) )
            {
                if( Bytes.equals(lk.getStartKey(), HConstants.EMPTY_START_ROW ) ) {
                  if(tid != lk.getTid())
                    return true;
                }
                else {
                  if( Bytes.compareTo( k.getBytesArray(), lk.getStartKey()) >= 0) {
                    if(tid != lk.getTid())
                      return true;
                  }
                }
            }

            if( Bytes.compareTo(k.getBytesArray(), lk.getStartKey()) > 0  &&
                Bytes.compareTo(k.getBytesArray(), lk.getEndKey() ) < 0)  //in the range
            {
                if(tid != lk.getTid())
                   return true;
            }

            if( Bytes.equals(k.getBytesArray() , lk.getStartKey()) ) {
               if(tid != lk.getTid())
                  return true;
            }

            if( Bytes.equals(k.getBytesArray() , lk.getEndKey()) ) {
               if(tid != lk.getTid())
                  return true;
            }
          }
        return false;
      }
    }


  private boolean isFinalLockException(Throwable error) {
      String errorMsg = error.getMessage();
      Throwable cause = error.getCause();
      String causeMsg = null;
      if (cause != null) {
          causeMsg = cause.toString();
      }
      if (errorMsg != null &&
           errorMsg.contains("Final LockTimeOutException")) {
          return true;
      }
      if (causeMsg != null &&
           causeMsg.contains("Final LockTimeOutException")) {
          return true;
      }
      return false;
  }

  private boolean isLockException(Throwable error) {
      String errorMsg = error.getMessage();
      Throwable cause = error.getCause();
      String causeMsg = null;
      if (cause != null) {
          causeMsg = cause.toString();
      }

      if (errorMsg != null &&
           ((errorMsg.contains("LockTimeOutException") &&
           !errorMsg.contains("for transaction rollbacked") &&
           !errorMsg.contains("Final"))
           ||
          (errorMsg.contains("FailedToLockException") &&
           !errorMsg.contains("for region split") &&
           !errorMsg.contains("for region move")))) {
          return true;
      }
      if (causeMsg != null &&
          ((causeMsg.contains("LockTimeOutException") &&
          !errorMsg.contains("for transaction rollbacked") &&
          !errorMsg.contains("Final"))
          ||
          (causeMsg.contains("FailedToLockException") &&
           !causeMsg.contains("for region split") &&
           !causeMsg.contains("for region move")))) {
          return true;
      }

      return false;
  }

  private boolean skipLock() {
      return (LockConstants.LOCK_SKIP_META_TABLE && (m_isTrafodionMetadata || m_isTrafodionStatTable || m_isTrafodionBRTable));
  }

  public void removeLockManager() {
      if (LockConstants.ENABLE_ROW_LEVEL_LOCK) {
          rsServer.removeLockManager(m_regionName);
      }
  }

  private void checkAndCreateLockManager() {
      if (lockManager == null) {
          synchronized (rsServer) {
              if (lockManager != null) {
                  return;
              }
              this.lockManager = new LockManager(this.m_regionName, this.m_regionEncodedName, this.regionInfo.toByteArray(), (m_isTrafodionMetadata || m_isTrafodionStatTable));
          }
      }
  }

  public static void switchSelectLockMode() {
      if (LockConstants.ENABLE_LOCK_FOR_SELECT) {
          lockMapping[READCOMMITTED][SEL_ROW_LOCK] = LockMode.LOCK_S;
          lockMapping[READCOMMITTED][SEL_TAB_LOCK] = LockMode.LOCK_S;
      } else {
          lockMapping[READCOMMITTED][SEL_ROW_LOCK] = LockMode.LOCK_NO;
          lockMapping[READCOMMITTED][SEL_TAB_LOCK] = LockMode.LOCK_IS;
      }
  }

  private Object[] checkLockedInGetScanner(Scan scan, int isolationLevel, int lockMode) {
      Object[] result = new Object[3];
      int isoLevel = transformIsolationLevel(isolationLevel);

      boolean fullTableScan = isFullTableScan(scan); 
      boolean singleRowScan = (!Bytes.equals(scan.getStartRow(), HConstants.EMPTY_START_ROW) && (scan.getStartRow().equals(scan.getStopRow())));
      boolean skipSLock = (isoLevel == READCOMMITTED && lockMode != LockMode.LOCK_U && !skipLock() && !LockConstants.ENABLE_LOCK_FOR_SELECT);

      if (singleRowScan) {
          result[0] = SINGLE_ROW_SCAN;
      } else if (fullTableScan) {
          result[0] = FULL_TABLE_SCAN;
      } else {
          result[0] = RANGE_SCAN;
      }
      if (LockConstants.ENABLE_ROW_LEVEL_LOCK && 
          ((LockConstants.ENABLE_TABLELOCK_FOR_FULL_SCAN && fullTableScan) ||
          singleRowScan || skipSLock)) {
              result[1] = true;
      } else {
          result[1] = false;
      }
      result[2] = false;
      return result;
  }

  private boolean isFullTableScan(Scan scan) {
      byte[] sKey = regionInfo.getStartKey();
      byte[] endKey = regionInfo.getEndKey();
      byte[] startRow = scan.getStartRow();
      byte[] stopRow = scan.getStopRow();

      if (LOG.isTraceEnabled()) {
          LOG.error("isFullTableScan: sKey: " + Arrays.toString(sKey) + " startRow: " + Arrays.toString(startRow) +
              " endKey: " + Arrays.toString(endKey) + " stopRow: " + Arrays.toString(stopRow) + " region: " + m_regionName);
      }
      if ((Bytes.equals(startRow, HConstants.EMPTY_START_ROW) || Bytes.equals(startRow, sKey)) &&
         (Bytes.equals(stopRow, HConstants.EMPTY_END_ROW) || Bytes.equals(stopRow, endKey))) {
         return true;
      }
      return false;
  } 

  private void checkAndGetRow(long txID, long svptID, byte[] rowID, List<Cell> cellResults) {
     RegionScanner scanner = null;
     try {
         Get get = new Get(rowID);
         Scan scan = new Scan(get);
         scan.setSmall(true);
         scanner = this.t_Region.getScanner(scan);
         if (scanner != null) {
             scanner.next(cellResults);
         }
     } catch (Exception e) {
         LOG.error("failed to checkAndGetRow: " + txID + " " + svptID + " " + Arrays.toString(rowID) + " " + m_regionName);
     } finally {
         if (scanner != null) {
             try {
                 scanner.close();
             } catch (Exception e) {
                 LOG.error("failed to close scanner in checkAndGetRow: " + txID + " " + svptID + " " + Arrays.toString(rowID) + " " + m_regionName);
             }
         }
     }
  }

  private void checkRetCode(RetCode retCode) throws IOException {
      if (retCode != RetCode.OK && retCode != RetCode.OK_LOCKED && retCode != RetCode.OK_WITHRETRY) {
          throw getException(retCode);
      }
  }

  private static synchronized  EndpointCostStats getEndpointCostStats(Long transId, boolean delete) {
    if (RSConstants.RECORD_TIME_COST_COPRO < 0)
	return null;

    EndpointCostStats stats = transStatMap.get(transId);
    if (stats == null && delete == false) {
      stats = ecsQueue.poll();
      if (stats == null)
        stats = new EndpointCostStats();
      transStatMap.put(transId, stats);
    }
    if (delete)
      transStatMap.remove(transId);
    return stats;
  }

  private static synchronized  void releaseEndpointCostStats(EndpointCostStats ecs) {
    if (ecs != null) {
      ecs.clear();
      ecsQueue.offer(ecs);
    }
  }

  private void recordCommitPendingTxForLock(long txID) {
      if (!LockConstants.ENABLE_ROW_LEVEL_LOCK || skipLock()) {
          return;
      }
      checkAndCreateLockManager();
      lockManager.recordCommitPendingTx(txID);
  }

  public static void checkAndSetLockTimeOut(int lockTimeOutToSet) {
      if (lockTimeOutToSet > TrxRegionEndpoint.hbaseRpcTimeout) {
          lockTimeOut = TrxRegionEndpoint.hbaseRpcTimeout - 1000;
      } else {
          lockTimeOut = lockTimeOutToSet;
      }
  }
  private void printMemoryUsage(String where) {
      if (memoryBean == null)
          memoryBean = ManagementFactory.getMemoryMXBean();
      long memUsed = memoryBean.getHeapMemoryUsage().getUsed();
      long memMax = memoryBean.getHeapMemoryUsage().getMax();
      if (memMax <= 0)
        return;
      int percent = (int)(memUsed * 1.0 / memMax * 100);
      LOG.info("[MEM] total: " + String.valueOf(memMax) + " inuse: " +
          String.valueOf(memUsed) + " in " + String.valueOf(percent) + " % on " + where);
  }

  private void checkWriteActionMemSize(long txId, TrxTransactionState state, int factor)
    throws IOException {
      if (RSConstants.REGION_MEMORY_HIGHLOAD_THRESHOLD == 100)
        return;
      if (factor == 0)
        return;
      if (memoryBean == null)
        memoryBean = ManagementFactory.getMemoryMXBean();
      long memUsed = memoryBean.getHeapMemoryUsage().getUsed();
      long memMax = memoryBean.getHeapMemoryUsage().getMax();
      if (memMax <= 0)
        return;
      int percent = (int)(memUsed * 1.0 / memMax * 100);
      if (percent < RSConstants.REGION_MEMORY_WARNING_THRESHOLD)
        return;
      long payloadMemSize = 0;
      if (state != null)
        payloadMemSize = state.getWriteOrderingLength();

      //get current JVM heap size
      long needSize = payloadMemSize * factor;

      if (LOG.isDebugEnabled() || (RSConstants.PRINT_TRANSACTION_LOG & COMMIT_MEMORY_CHECK_LOG_MARK) > 0)
        printMemoryUsage("estimateBinlogSize() needSize " + needSize);


      //recheck
      memUsed = memoryBean.getHeapMemoryUsage().getUsed();
      memMax = memoryBean.getHeapMemoryUsage().getMax();
      if (memMax <= 0)
        return;
      percent = (int)((needSize + memUsed) * 1.0 / memMax * 100);
      //no enough memories
      if (percent > RSConstants.REGION_MEMORY_HIGHLOAD_THRESHOLD) {
        LOG.warn("regionServer " + lv_hostName + " total memory " + memMax + " inuse memory " +
          memUsed + " in " + percent + " % commit need memory " + needSize + " do System.GC() tx " + txId
          + " on checkWriteActionMemSize()");
        //trigger GC
        System.gc();
        memUsed = memoryBean.getHeapMemoryUsage().getUsed();
        memMax = memoryBean.getHeapMemoryUsage().getMax();
        if (memMax <= 0)
          return;
        percent = (int)((needSize + memUsed) * 1.0 / memMax * 100);
        LOG.warn("regionServer " + lv_hostName + " total memory " + memMax + " inuse memory " +
          memUsed + " in " + percent + " % commit need memory " + needSize + " done System.GC() tx " + txId
            + " on checkWriteActionMemSize()");
        //recheck
        if (percent > RSConstants.REGION_MEMORY_HIGHLOAD_THRESHOLD) {
            LOG.warn("regionServer " + lv_hostName + " total memory " + memMax + " inuse memory " +
            memUsed + " in " + percent + " % commit need memory " + needSize + " kill tx " + txId 
            + " on checkWriteActionMemSize()");
            //recycling memories & set status
            //do it on upper try-catch
            throw new IOException("No enough memory on regionServer " + lv_hostName);
        }
      }
  }

  private void checkMemeoryUsage(long txId) throws IOException {
    if (RSConstants.REGION_MEMORY_HIGHLOAD_THRESHOLD == 100)
        return;
    if (memoryBean == null)
        memoryBean = ManagementFactory.getMemoryMXBean();
    long memUsed = memoryBean.getHeapMemoryUsage().getUsed();
    long memMax = memoryBean.getHeapMemoryUsage().getMax();
    int percent = (int)(memUsed * 1.0 / memMax * 100);
    if (percent > RSConstants.REGION_MEMORY_HIGHLOAD_THRESHOLD) {
        LOG.warn("checkMemeoryUsage outOfMemory regionServer " + lv_hostName + " total memory " + memMax + " inuse memory " +
          memUsed + " in " + percent + " % kill tx " + txId);
        throw new IOException("No enough memory on regionServer " + lv_hostName);
    }
  }

}

//1}
