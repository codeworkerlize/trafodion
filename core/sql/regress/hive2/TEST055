-- Tests for operations on AVRO tables
--
-- @@@ START COPYRIGHT @@@
--
-- Licensed to the Apache Software Foundation (ASF) under one
-- or more contributor license agreements.  See the NOTICE file
-- distributed with this work for additional information
-- regarding copyright ownership.  The ASF licenses this file
-- to you under the Apache License, Version 2.0 (the
-- "License"); you may not use this file except in compliance
-- with the License.  You may obtain a copy of the License at
--
--   http://www.apache.org/licenses/LICENSE-2.0
--
-- Unless required by applicable law or agreed to in writing,
-- software distributed under the License is distributed on an
-- "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-- KIND, either express or implied.  See the License for the
-- specific language governing permissions and limitations
-- under the License.
--
-- @@@ END COPYRIGHT @@@

sh regrhadoop.ksh fs -mkdir  /user/trafodion/hive/exttables/customer_ddl;
sh regrhadoop.ksh fs -mkdir  /user/trafodion/hive/exttables/customer_ddl_avro;
sh regrhadoop.ksh fs -mkdir  /user/trafodion/hive/exttables/customer_temp_avro;

sh regrhadoop.ksh fs -rm   /user/trafodion/hive/exttables/customer_ddl/*;
sh regrhadoop.ksh fs -rm   /user/trafodion/hive/exttables/customer_ddl_avro/*;
sh regrhadoop.ksh fs -rm   /user/trafodion/hive/exttables/customer_temp_avro/*;

--- setup Avro tables
sh regrhive.ksh -v -f $REGRTSTDIR/TEST055_a.avro.sql;

insert overwrite table hive.hive.customer_ddl
select
    c_customer_sk,
    c_customer_id,
    c_current_cdemo_sk,
    c_current_hdemo_sk,
    c_current_addr_sk,
    c_first_shipto_date_sk,
    c_first_sales_date_sk,
    c_salutation,
    c_first_name,
    c_last_name,
    c_preferred_cust_flag,
    c_birth_day,
    c_birth_month,
    c_birth_year,
    c_birth_country,
    c_login,
    c_email_address,
    c_last_review_date
from hive.hive.customer
where c_customer_sk < 25000;

log LOG055 clear;

set schema hive.hive;
set terminal_charset utf8;

cqd AUTO_QUERY_RETRY_WARNINGS 'ON';
cqd HIVE_MAX_STRING_LENGTH_IN_BYTES '32' ;
cqd hist_missing_stats_warning_level '0';
cqd HIST_ROWCOUNT_REQUIRING_STATS '50000';
------------------------------------------------------------
-- Testing query plan invalidation in the compiler, but
-- not the executor. Perform DML/DDL operations on a
-- table and try re-executing the old plan as well as
-- getting a query cache hit and updating the changed
-- Hive and HDFS metadata
------------------------------------------------------------

prepare s1 from 
  select c_preferred_cust_flag,
         count(*) 
  from customer_temp_avro
  group by 1 
  order by 1
  ;
execute s1;
-- expect 0 rows

prepare s1part from 
  select c_preferred_cust_flag,
         count(*) 
  from customer_p_avro
  group by 1 
  order by 1
  ;
execute s1part;
-- expect 0 rows

insert into hive.hive.hivenonp_avro
values -- partition 1,one
       (1,1,1,'one', timestamp '2001-01-01 01:23:45.678901', timestamp '2001-01-01 00:00:00'),
       (11,11,1,'one', timestamp '2001-01-01 01:23:45.678901', timestamp '2001-01-01 00:00:00'),
       -- partition 2,two
       (2,2,2,'two', timestamp '2002-02-02 02:34:56.789012', timestamp '2020-02-29 00:00:00'),
       (22,22,2,'two', timestamp '2002-02-02 00:00:00.000000', timestamp '2020-02-29 00:00:00'),
       (222,222,2,'two', timestamp '2002-02-02 02:34:56.789012', timestamp '2020-02-29 00:00:00'),
       -- partition 3,three
       (3,3,3,'three', timestamp '2003-03-03 03:45:57.890123', timestamp '2003-03-31 00:00:00'),
       -- partition 3 or partition 3,four
       (34,34,3,'four', timestamp '2004-04-04 04:56:18', timestamp '2004-04-04 00:00:00'),
       -- partition -5,five
       (-55,-55,-5,'five', timestamp '2004-04-04 04:56:18', timestamp '2005-05-05 00:00:00');
select * from hive.hive.hivenonp_avro;

insert into hive.hive.hivepis_avro select id, col2, p1, p2 from hive.hive.hivenonp_avro;
insert into hive.hive.hivepts_avro select id, col2, p1t, p2 from hive.hive.hivenonp_avro;
insert into hive.hive.hivepi_avro  select id, col2, p1 from hive.hive.hivepis_avro;
insert overwrite table hive.hive.hivepi_avro  select id, col2, p1 from hive.hive.hivepis_avro;
-- error, insert overwrite table not allowed for partitioned tables

prepare display_rows_accessed from
select val4_txt, val4
from table(statistics(null,null))
where tdb_name like '%_SCAN %';

select * from hive.hive.hivepis_avro;
select * from hive.hive.hivepts_avro;
select * from hive.hive.hivepi_avro;

control query shape cut;

-- insert some data and add one more partition
sh regrhive.ksh -v -f $REGRTSTDIR/TEST055_b.avro.sql;

-- customer_ddl_avro table is about 3 MB, make a plan with >= 2 ESPs
cqd HIVE_MIN_BYTES_PER_ESP_PARTITION '1000000';
cqd hive_max_string_length_in_bytes '32000';

prepare partinsert from
insert into hive.hive.customer_p_avro
select 
    c_customer_sk,
    c_customer_id,
    c_current_cdemo_sk,
    c_current_hdemo_sk,
    c_current_addr_sk,
    c_first_shipto_date_sk,
    c_first_sales_date_sk,
    c_salutation,
    c_first_name,
    c_last_name,
    c_birth_day,
    c_birth_month,
    c_birth_year,
    c_birth_country,
    c_login,
    c_email_address,
    c_last_review_date,
    c_preferred_cust_flag
from hive.hive.customer_ddl <<+cardinality 2.5e4 >>
where c_customer_sk < 20000
      -- blank partition column values not yet supported
      and char_length(c_preferred_cust_flag) <> 0
order by c_customer_sk;

-- go back to the smaller string length
cqd HIVE_MAX_STRING_LENGTH_IN_BYTES '32' ;

-- verify that we are indeed seeing a parallel plan
select count(*)
from table(explain(null,'PARTINSERT'))
where operator = 'ESP_EXCHANGE';

explain options 'f' partinsert;

execute partinsert;

insert into customer_temp_avro 
select * from customer 
where c_customer_sk between 20000 and 39999;

-- query cache hit, no validation at all
  select c_preferred_cust_flag,
         count(*) 
  from customer_ddl_avro 
  group by 1 
  order by 1
  ;

-- vary query to avoid query cache hit
prepare s2 from 
  select c_preferred_cust_flag,
         count(c_customer_sk) 
  from customer_ddl_avro 
  group by 1 
  order by 1
  ;

prepare s2part from
  select c_preferred_cust_flag,
         count(c_customer_sk) -- avoid query cache
  from customer_p_avro 
  group by 1 
  order by 1
  ;
execute s1;
-- because we don't invalidate in the executor,
-- this should still return 0 rows

execute s2;
-- should get an NATable cache
-- hit, we should notice the change in the table
-- and return the correct result

execute s1part;
-- because we don't invalidate in the executor,
-- this should still return 0 rows

execute s2part;
-- although this should get an NATable cache
-- hit, we should notice the change in the table
-- and return the correct result

-- add duplicate rows to customer_p_avro
insert into customer_p_avro
select 
    c_customer_sk,
    c_customer_id,
    c_current_cdemo_sk,
    c_current_hdemo_sk,
    c_current_addr_sk,
    c_first_shipto_date_sk,
    c_first_sales_date_sk,
    c_salutation,
    c_first_name,
    c_last_name,
    c_birth_day,
    c_birth_month,
    c_birth_year,
    c_birth_country,
    c_login,
    c_email_address,
    c_last_review_date,
    c_preferred_cust_flag
from customer_ddl
where c_customer_sk between 20000 and 24999
      -- blank partition column values not yet supported
      and char_length(c_preferred_cust_flag) <> 0
order by c_customer_sk;

-- no query cache hit, but NATable cache hit
prepare s3 from 
  select count(*) 
  from customer_ddl_avro 
  ;

-- no query cache hit, but NATable cache hit
prepare s3part from
  select c_preferred_cust_flag,
         count(c_customer_id) 
  from customer_p_avro 
  group by 1 
  order by 1
  ;
execute s1;
-- s1 should still return 0 rows - for now
execute s2;
execute s3;
execute s1part;
-- s1 should still return 0 rows - for now
execute s2part;
execute s3part;

-- overwrite customer_p_avro with auto-generated partitions
sh regrhive.ksh -v -f $REGRTSTDIR/TEST055_d.avro.sql;

prepare s4 from 
  select c_preferred_cust_flag,
         count(*) 
  from customer_ddl_avro 
  group by 1 
  order by 1
  ;
prepare s4part from
  select c_preferred_cust_flag,
         count(*) 
  from customer_p_avro 
  group by 1 
  order by 1
  ;
execute s2;
execute s4;
execute s2part;
-- error 8442 since the files we are trying to open no longer exist
execute s4part;

-- partition elimination on AVRO table
select * from hive.hive.hivepio_avro where p1=2;
execute display_rows_accessed;
select * from hive.hive.hivepio_avro where p1 in (1,3);
execute display_rows_accessed;
select * from hive.hive.hivepdo_avro where p1d >= date '2002-12-31';
execute display_rows_accessed;

-- this pred can neither be pushed to AVRO nor used as
-- a partition elimination predicate
select * from hive.hive.hivepio_avro where p1=1 or col2<10;

-- tests for avro timestamp mismatch check
cqd auto_query_retry_warnings 'ON';

process hive statement 'drop table tavro';
process hive statement 'create table tavro(a int) stored as avro';

select a from hive.hive.tavro;

sh echo "insert into tavro values (1);" > TEST055_junk;
sh regrhive.ksh -f TEST055_junk;

select a from hive.hive.tavro;
insert into hive.hive.tavro values (2);
select a from hive.hive.tavro;

process hive statement 'drop table tavro';
process hive statement 'create table tavro(a int, b smallint) stored as avro';

sh echo "insert into tavro values (1,2);" > TEST055_junk;
sh regrhive.ksh -f TEST055_junk;

--sh echo "select * from tavro;" > TEST055_junk;
--sh regrhive.ksh -f TEST055_junk | tee -a LOG055;

select a from hive.hive.tavro;
select b from hive.hive.tavro;

select * from hive.hive.tavro;

insert into hive.hive.tavro values (3,4);
--sh echo "select * from tavro;" > TEST055_junk;
--sh regrhive.ksh -f TEST055_junk | tee -a LOG055;
select * from hive.hive.tavro;

-- tests for avro CHAR/VARCHAR/DECIMAL datatypes
cqd auto_query_retry_warnings 'ON';
cqd hive_max_string_length_in_bytes '5';

-- run against AVRO table
drop external table if exists tavro10 for hive.hive.tavro10;
process hive statement 'drop table tavro10';
process hive statement 'create table tavro10(a char(2), b varchar(3), c char(5), d varchar(6), e string, f string, g char(2), h varchar(3), i char(3), j varchar(3), k decimal(5,2), l decimal(19,0), m decimal, n boolean, o date) stored as avro';

obey TEST055(extTabQueries);

-- test for decimal datatype with precision and scale
drop table if exists t_avo;
create table t_avo (c1 decimal, c2 decimal(10,2)) stored as avro;
insert into t_avo values (1.0,1.0),(2.0,2.0),(3.0,3.0);
select * from t_avo;

-- get stats
process hive statement 'drop table tavro';
process hive statement 'create table tavro(a int, b smallint) stored as avro';
insert into tavro values (1,2);
invoke table(avro stats());
select left(trim(schema_name) || '.' || trim(object_name), 14),
  file_num, 'FileSize: ' || cast(file_size as varchar(10)), row_count
from table(avro stats(hive.hive.tavro));
get avro stats for table hive.hive.tavro;
process hive statement 'drop table tavro';

log;
exit;

?section extTabQueries
invoke hive.hive.tavro10;
showddl hive.hive.tavro10;

insert into hive.hive.tavro10 values 
   ('ab', 'cde', 'ab12345', 'cde', 'ab', 'cde', 'ab', 'cde', '11', '222',
   123.24, 1234567890123456789, 123456, true, date '2017-01-02');

sh echo  "insert into tavro10 values ('ba', 'cde', 'ab54321', 'cde', 'ab', 'cde', 'ab', 'cde', '11', '222', 123.24, 1234567890123456789, 123456, true,'2018-03-04');" > TEST055_junk;
sh regrhive.ksh -f TEST055_junk;
                                   
select * from hive.hive.tavro10 order by 1;

drop external table if exists tavro10 for hive.hive.tavro10;
create external table tavro10 
        (a char(2), b varchar(3),
         c char(5), d varchar(6), 
         e char(2), f varchar(3),
         g char(2) character set utf8, h varchar(3) character set utf8,
         i tinyint, j int)
     for hive.hive.tavro10;

showddl hive.hive.tavro10;

insert into hive.hive.tavro10 values
  ('x', 'yz', 'x', 'yz', 'x', 'yz', 'x', 'yz', 33, 444,
   123.24, 1234567890123456789, 123456, false , date '1016-01-01');

sh echo  "insert into tavro10 values ('xx', 'cde', 'ab', 'cde', 'ab', 'cde', 'ab', 'cde', '11', '222', 123.24, 1234567890123456789, 123456, true, null);" > TEST055_junk;
sh regrhive.ksh -f TEST055_junk;

select * from hive.hive.tavro10 order by 1 desc;

get avro read schema for table hive.hive.tavro10;
get avro write schema for table hive.hive.tavro10;
get avro schema for table hive.hive.tavro10;

-- error cases

-- overflow error during insert. Not currently detected.
insert into hive.hive.tavro10 values
  ('x', 'yz', 'x', 'yz', 'x', 'yz', 'x', 'yz', 333, 444, 1, NULL, 1, true);

-- incommpatible datatype against external table
cqd allow_incompatible_assignment 'OFF';
insert into hive.hive.tavro10 values 
   ('ab', 'cde', 'ab', 'cde', 'ab', 'cde', 'ab', 'cde', '11', '222', 1, 1, 1, true, null);
cqd allow_incompatible_assignment reset;

-- number of values less than number of columns
insert into hive.hive.tavro10 values 
   ('ab', 'cde', 'ab', 'cde', 'ab', 'cde', 'ab', 'cde');

-- overflow error detected during select
truncate table hive.hive.tavro10;
sh echo "insert into tavro10 values ('a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', '555', '666', 1, 1, 1, false, null);" > TEST055_junk;
sh regrhive.ksh -f TEST055_junk;
select * from hive.hive.tavro10 order by 1;

-- incompatible values in hive table validated and detected during select
truncate table hive.hive.tavro10;
sh echo "insert into tavro10 values ('a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 1, 1, 1, false, null);" > TEST055_junk;
sh regrhive.ksh -f TEST055_junk;
select * from hive.hive.tavro10 order by 1;

-- drop tables
drop external table if exists tavro10 for hive.hive.tavro10;
process hive statement 'drop table tavro10';
cleanup table hive.hive.tavro10;

