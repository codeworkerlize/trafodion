-- Tests for parquet file access
--
-- @@@ START COPYRIGHT @@@
--
-- Licensed to the Apache Software Foundation (ASF) under one
-- or more contributor license agreements.  See the NOTICE file
-- distributed with this work for additional information
-- regarding copyright ownership.  The ASF licenses this file
-- to you under the Apache License, Version 2.0 (the
-- "License"); you may not use this file except in compliance
-- with the License.  You may obtain a copy of the License at
--
--   http://www.apache.org/licenses/LICENSE-2.0
--
-- Unless required by applicable law or agreed to in writing,
-- software distributed under the License is distributed on an
-- "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-- KIND, either express or implied.  See the License for the
-- specific language governing permissions and limitations
-- under the License.
--
-- @@@ END COPYRIGHT @@@

log LOG040 clear;
obey TEST040(setup);
obey TEST040(tests);
log;
exit;

?section setup
--------------------------------------------------------------------------

set schema hive.hive;


cqd HIVE_MAX_STRING_LENGTH_IN_BYTES '20' ;
cqd mode_seahive 'ON';
cqd traf_enable_parquet_format 'ON';
cqd HIST_ROWCOUNT_REQUIRING_STATS '50000';
cqd hive_use_ext_table_attrs 'ON';
cqd hist_missing_stats_warning_level '0';
cqd ORC_NJS_PROBES_THRESHOLD '1000000';
cqd HIVE_MIN_NUM_ESPS_PER_DATANODE '0';

prepare explainIt from
  select substring(cast(SEQ_NUM+100 as char(3)),2,2) s,
         substring(operator,1,16) operator,
         cast(LEFT_CHILD_SEQ_NUM as char(2)) lc,
         cast(RIGHT_CHILD_SEQ_NUM as char(2)) rc,
         substring
         (substring(substring(tname from (1+locate('.',tname))),1,case locate(')',tname) when 0 then 0 else locate(')',substring(tname from (1+locate('.',tname))))-1 end),
         (locate('.',substring(tname from (1+locate('.',tname)))))+1,
         10
        ) tab_name
         from table (explain(NULL,'XX'))
         order by 1 desc;

register hive table if not registered store_sales_parquet;
register hive table if not registered customer_parquet;
register hive table if not registered store_sales_sorted_parquet;

?section tests

--------------------------------------------------------------------------
-- PARQUET file metadata info
--invoke hive.hive.store_parquet;
--
-- select one row from PARQUET table
select [first 1] * from hive.hive.store_parquet;

-- select all rows from PARQUET table
select * from hive.hive.store_parquet order by s_store_sk;

-- select of few columns with WHERE predicate
select s_store_sk, left(s_store_id, 20) from hive.hive.store_parquet where s_store_sk < 7;

-- select count of rows 
select count(*) from hive.hive.store_parquet;

-- count(*) pushdown on a table in non-default hive schema
drop table if exists hive.t040hivesch.tpcount;
create schema if not exists hive.t040hivesch;
create table hive.t040hivesch.tpcount(a int) stored as parquet;
insert into hive.t040hivesch.tpcount values (2);
explain options 'f' select count(*) from hive.t040hivesch.tpcount;
select count(*) from hive.t040hivesch.tpcount;
drop table hive.t040hivesch.tpcount;
drop schema hive.t040hivesch;

-- explain of join between 2 PARQUET tables
prepare XX from select x.s_suite_number, y.s_street_name
 from hive.hive.store_parquet x, hive.hive.store_parquet y
  where x.s_store_sk = y.s_store_sk;
execute explainIt;

-- execute of join between 2 PARQUET tables
execute XX;

-- explain of join between hive(hdfs) and PARQUET tables
control query shape join(scan(path 'STORE'), scan(path 'STORE_PARQUET'));
prepare XX from select x.s_suite_number, y.s_street_name
 from hive.hive.store x, hive.hive.store_parquet y
  where x.s_store_sk = y.s_store_sk;
control query shape cut;
execute explainIt;

-- execute of join between hive(hdfs) and PARQUET tables
execute XX;

-- column list pushdown test
cqd parquet_columns_pushdown 'OFF';
showplan option 'tr' select s_store_sk from store_parquet;
select s_store_sk from store_parquet;
cqd parquet_columns_pushdown 'ON';
showplan option 'tr' select s_store_sk from store_parquet;
select s_store_sk from store_parquet;

-- predicate pushdown to PARQUET layer
cqd parquet_pred_pushdown 'OFF';
select s_store_sk from store_parquet where s_store_sk = 3;
select s_store_sk from store_parquet where s_store_sk < 2;
select s_store_sk from store_parquet where s_store_sk >= 11;
select s_store_sk from store_parquet where s_store_sk >= 4 and s_store_sk < 6;
select s_store_sk from store_parquet where s_store_sk in (7,8,9);
showplan option 'tr' select s_store_sk from store_parquet where s_store_sk = 3;

cqd parquet_pred_pushdown 'ON';
select s_store_sk from store_parquet where s_store_sk = 3;
select s_store_sk from store_parquet where s_store_sk < 2;
select s_store_sk from store_parquet where s_store_sk >= 11;
select s_store_sk from store_parquet where s_store_sk >= 4 and s_store_sk < 6;
select s_store_sk from store_parquet where s_store_sk in (7,8,9);
showplan option 'tr' select s_store_sk from store_parquet where s_store_sk = 3;

-- local join predicate is not pushed down
prepare XX from select * from store_sales_parquet where ss_sold_date_sk = ss_item_sk ;
select cast(tokenstr('parquet_search_arguments', description, 'executor_predicates')
        as char(400))
         from table (explain(NULL,'XX'))
where position('parquet_search_arguments' in description)  > 0 ;

-- Boolean constant predicate is not pushed down
prepare XX from select * from store_sales_parquet where 1=2;
select cast(tokenstr('parquet_search_arguments', description, 'executor_predicates')
        as char(400))
         from table (explain(NULL,'XX'))
where position('parquet_search_arguments' in description)  > 0 ;

-- aggregate pushdown to PARQUET layer
cqd parquet_aggr_pushdown 'ON';
explain options 'f' select count(*) from store_parquet;
select count(*) from store_parquet;
select count(*), count(*) from store_parquet;
select min(s_store_sk) from store_parquet;
select max(s_store_sk) from store_parquet;
select sum(s_store_sk) from store_parquet;
select count(*), min(s_store_sk), max(s_store_sk), sum(s_store_sk) 
   from store_parquet;
explain options 'f' select count(*), min(s_store_sk), max(s_store_sk), 
   sum(s_store_sk) from store_parquet;

explain options 'f'
  select count(*) from hive.hive.store_parquet union all 
  select count(*) from hive.hive.store_parquet;
select count(*) from hive.hive.store_parquet union all 
  select count(*) from hive.hive.store_parquet;

explain options 'f'
  select min(s_store_sk) from hive.hive.store_parquet union all 
  select min(s_store_sk) from hive.hive.store_parquet;
select min(s_store_sk) from hive.hive.store_parquet union all 
  select min(s_store_sk) from hive.hive.store_parquet;

explain options 'f' select count(s_store_sk) from store_parquet;
select count(s_store_sk) from store_parquet;

explain options 'f' select count(*) from store_parquet
  having sum(s_store_sk) = 78;
select count(*) from store_parquet having sum(s_store_sk) = 78;

select count(*) from store_parquet having sum(s_store_sk) = 77;

cqd parquet_aggr_pushdown 'OFF';
explain options 'f' select count(*), min(s_store_sk), max(s_store_sk), 
   sum(s_store_sk) from store_parquet;
select count(*), min(s_store_sk), max(s_store_sk), sum(s_store_sk) 
   from store_parquet;

-- pushdown on parquet decimal column
process hive ddl 'drop table tprqdec';
process hive ddl 'create table tprqdec (a decimal(4,1), b decimal(22,4)) stored as parquet';
insert into tprqdec values (1,1);
select min(a) from tprqdec;
select min(b) from tprqdec;

-- test query cache 
prepare xx from select cd_gender from customer_demographics_parquet where cd_gender = 'male' ;
select num_hits, num_params from table(querycacheentries('user', 'local')) 
where substring(text, 1, 16) = 'select cd_gender' order by 1,2;

prepare xx from select cd_gender from customer_demographics_parquet where cd_gender = 'female' ;
select num_hits, num_params from table(querycacheentries('user', 'local')) 
where substring(text, 1, 16) = 'select cd_gender' order by 1,2;


-- test external table attributes
set schema trafodion.sch;
drop external table if exists store_sales_parquet for hive.hive.store_sales_parquet;
create external table store_sales_parquet 
  for hive.hive.store_sales_parquet;
invoke hive.hive.store_sales_parquet;

set schema hive.hive;
prepare s from select * from store_sales_parquet where ss_item_sk = 1;
explain s;

-- join with nested join
?ignore
cqd orc_njs 'on';
control query shape nested_join(scan(path 'CUSTOMER_PARQUET'), 
      scan(path 'STORE_SALES_PARQUET'));
prepare s from select * from customer_parquet, store_sales_parquet 
    where store_sales_parquet.ss_item_sk = customer_parquet.c_customer_sk;
explain options 'f' s;
explain s;
cqd orc_njs reset;
?ignore

-- join with parallel nested join

control query shape off;
cqd HIVE_USE_EXT_TABLE_ATTRS 'off';
cqd ncm_orc_costing 'on';
cqd orc_njs 'on';
cqd parallel_num_esps '4';

prepare s from
select [last 0] ss_net_profit from
date_dim_parquet dim, store_sales_sorted_parquet ss
where
dim.d_date_sk = ss.ss_sold_date_sk
and d_year in (2001) and d_dom = 30 -- produce 12 rows
;

explain options 'f' s;

cqd HIVE_USE_EXT_TABLE_ATTRS reset;
cqd ncm_orc_costing reset;
cqd orc_njs reset;
cqd parallel_num_esps reset;


-- more external table tests

control query shape cut;
set schema trafodion.sch;
drop external table if exists date_dim_parquet for hive.hive.date_dim_parquet;
cqd volatile_table_find_suitable_key 'SYSTEM';
create external table date_dim_parquet 
  (d_date_sk int, d_date_id varchar(100 bytes) character set utf8, d_date date, 
   d_month_seq int, d_week_seq int, d_quarter_seq int, d_year int, d_dow int,
   d_moy int, d_dom int, d_qoy int, d_fy_year int, d_fy_quarter_seq int,
   d_fy_week_seq int,
   d_day_name varchar(120 bytes) character set utf8, d_quarter_name varchar(200 bytes) character set utf8, d_holiday varchar(100 bytes) character set utf8,
   d_weekend varchar(100 bytes) character set utf8, d_following_holiday varchar(100 bytes) character set utf8, 
   d_first_dom int, d_last_dom int, d_same_day_ly int, d_same_day_lq int,
   d_current_day varchar(100 bytes) character set utf8, d_current_week varchar(111 bytes) character set utf8,
   d_current_month varchar(200 bytes) character set utf8, d_current_quarter varchar(100 bytes) character set utf8, 
   d_current_year varchar(100 bytes) character set utf8)
  for hive.hive.date_dim_parquet;
invoke hive.hive.date_dim_parquet;
showddl hive.hive.date_dim_parquet;
prepare s from select * from hive.hive.date_dim_parquet where d_date = date '2016-01-27';
explain s;

drop external table if exists date_dim_parquet for hive.hive.date_dim_parquet;
create external table date_dim_parquet 
  (d_date_sk int, d_date_id varchar(100 bytes) character set utf8, d_date date)
  for hive.hive.date_dim_parquet;
invoke hive.hive.date_dim_parquet;
showddl hive.hive.date_dim_parquet;
prepare s from select * from hive.hive.date_dim_parquet where d_date = date '2016-01-27';
explain s;


-- error cases
drop external table if exists date_dim_parquet for hive.hive.date_dim_parquet;

-- column d_date_skk doesn't exist in native hive table
create external table date_dim_parquet 
  (d_date_skk int)
  for hive.hive.date_dim_parquet;

-- del/update not supported on parquet or hive
prepare s from delete from hive.hive.store2_sales_parquet;
prepare s from update hive.hive.store2_sales_parquet set ss_ext_tax = 1;
prepare s from delete from hive.hive.store_sales;
prepare s from update hive.hive.store_sales set ss_ext_tax = 1;

-- upsert/insert cannot specify column list and must provide all column values.
prepare s from upsert into hive.hive.store2_sales_parquet values (1);
prepare s from upsert using load into hive.hive.store2_sales_parquet values (1);
prepare s from insert into hive.hive.store2_sales_parquet values (1);
prepare s from update hive.hive.store2_sales_parquet set ss_net_paid = 1;        
prepare s from upsert into hive.hive.store2_sales_parquet(ss_sold_date_sk) values (1);
prepare s from insert into hive.hive.store2_sales_parquet(ss_sold_date_sk) values (1);
prepare s from upsert into hive.hive.store_sales(ss_sold_date_sk) values (1);
prepare s from insert into hive.hive.store_sales(ss_sold_date_sk) values (1);
prepare s from upsert into hive.hive.store_sales values (1);
prepare s from insert into hive.hive.store_sales values (1);


-- test min-max optimization

update statistics for table hive.hive.date_dim on every column sample;
update statistics for table hive.hive.time_dim on every column sample;

cqd PARQUET_PRED_PUSHDOWN 'ON';
cqd GEN_HSHJ_MIN_MAX_OPT 'off';
cqd parallel_num_esps '4';
cqd nested_joins 'off';

prepare xx from select count(*) from
hive.hive.store2_sales_parquet, -- sorted on ss_sold_date_sk
hive.hive.date_dim, 
hive.hive.time_dim
 where ss_sold_date_sk = d_date_sk and
       ss_sold_date_sk = t_time_sk and d_year = 2001 and t_hour = 10 ;

-- display the push-down predicates, which should include the 
-- min/max expressions from dimension table date_dim and time_dim.
select cast(tokenstr('parquet_search_arguments', description, 'executor_predicates')
        as char(400))
         from table (explain(NULL,'XX'))
where position('parquet_search_arguments' in description)  > 0 ;

execute xx;

cqd parallel_num_esps reset;
cqd nested_joins reset;

-- test NJ into a sorted PARQUET table

cqd parquet_pred_pushdown 'ON';
cqd orc_njs 'ON';
cqd parallel_num_esps '4';
cqd HIVE_USE_EXT_TABLE_ATTRS 'off';

prepare xx from select count(*) from hive.hive.customer_parquet, hive.hive.store_sales_sorted_parquet
    where ss_sold_date_sk = c_customer_sk
   and c_first_sales_date_sk = 4;

explain xx;
explain options 'f' xx;
execute xx;

cqd orc_njs reset;
cqd parallel_num_esps reset;
cqd HIVE_USE_EXT_TABLE_ATTRS reset;

-- test aggregates pushdown (parquet)

-- test aggregates pushdown
cqd parquet_aggr_pushdown 'ON';

-- pushdown feasible
cqd attempt_esp_parallelism 'OFF';
prepare xx from
select min(ss_sold_date_sk), max(ss_sold_date_sk)
from hive.hive.store2_sales_parquet;

explain options 'f' xx;

-- pushdown feasible
prepare xx from
select ss_sold_date_sk from hive.hive.store2_sales_parquet where
ss_sold_date_sk >
(select count(*) from hive.hive.store2_sales_parquet);

explain options 'f' xx;


-- pushdown not feasible due to distinct
prepare xx from
select
count(distinct ss_sold_date_sk)
from hive.hive.store2_sales_parquet;

explain options 'f' xx;

--test cardinality

set schema hive.hive;
 
-- single scan
prepare xx from
select SS_ITEM_SK,SS_ADDR_SK  from store_sales_parquet where
ss_sold_date_sk = 2 and
SS_ADDR_SK in (1,3,4,4);

explain options 'f' xx;

-- join
prepare xx from
select a.SS_ITEM_SK, b.SS_ADDR_SK  from
store_sales_parquet a ,store_sales_parquet b
where
a.ss_sold_date_sk = b.ss_sold_date_sk
;

explain options 'f' xx;

update statistics for table store_sales_parquet_p on every column no sample;

-- compile time elimination
prepare xx from
select SS_ITEM_SK,SS_ADDR_SK  from store_sales_parquet_p where
ss_sold_date_sk = 2451241
;

explain options 'f' xx;

-- NJ into a parquet table
cqd hash_joins 'off';
cqd merge_joins 'off';
cqd PARQUET_NJS 'on';

prepare xx from 
select s.ss_sold_date_sk from customer_parquet c, store_sales_parquet_p s
where ss_sold_date_sk = c_customer_sk
and c_first_sales_date_sk = 4;

explain options 'f' xx;


------------------------------------
-- test parallel aggr push down for hive tables

-- reset some CQDs used previously that can affect parallelism.
cqd attempt_esp_parallelism reset;
cqd HIVE_MIN_NUM_ESPS_PER_DATANODE reset;

--------------------
-- against PARQUET table
--------------------

-- # of data files is 284 in store_sales_parquet_p, larger than 
-- the value of the threashold CQD parallel_aggr_pushdown of 200. 
-- Should get a parallel plan.

cqd parallel_aggr_pushdown '200';
control query shape exchange(cut) ;
prepare xx from select count(*) from hive.hive.store_sales_parquet_p;
control query shape cut ;
explain options 'f'  xx;
execute xx;

-- increase the value of the threashold CQD parallel_aggr_pushdown to 
-- a quite large value.  Should get a serial plan.
cqd parallel_aggr_pushdown '100000';
prepare xx from select count(*) from hive.hive.store_sales_parquet_p;
explain options 'f'  xx;
execute xx;


--------------------
-- against ORC table
--------------------


-- # of data files is 2 in store_sales_orc, larger than 
-- the value of the threashold CQD parallel_aggr_pushdown of 1. 
-- Should get a parallel plan.
cqd parallel_aggr_pushdown '1'; 
prepare xx from select count(*) from hive.hive.store_sales_orc;
explain options 'f'  xx;
execute xx;

-- force a serial plan by increasing the threshold value.
cqd parallel_aggr_pushdown '10'; 

-- If the following CQD is kept on, we will return a MAYBE status 
-- from GroupByAgg::decideFeasibleToTransformForAggrPushdown()
-- which will not shutdown parallel plan. The parallel and the serial
-- aggregate plan will compete based on cost.
-- If the following CQD is turned off, we will get a serial plan definitely.

cqd ORC_PARTITION_ONLY_PUSHDOWN 'off';

prepare xx from select count(*) from hive.hive.store_sales_orc;
explain options 'f'  xx;

execute xx;




