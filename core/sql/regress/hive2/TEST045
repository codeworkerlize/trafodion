-- -*- mode: sql; coding: utf-8 -*-
-- Tests for insert into PARQUET tables
--
-- @@@ START COPYRIGHT @@@
--
-- Licensed to the Apache Software Foundation (ASF) under one
-- or more contributor license agreements.  See the NOTICE file
-- distributed with this work for additional information
-- regarding copyright ownership.  The ASF licenses this file
-- to you under the Apache License, Version 2.0 (the
-- "License"); you may not use this file except in compliance
-- with the License.  You may obtain a copy of the License at
--
--   http://www.apache.org/licenses/LICENSE-2.0
--
-- Unless required by applicable law or agreed to in writing,
-- software distributed under the License is distributed on an
-- "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-- KIND, either express or implied.  See the License for the
-- specific language governing permissions and limitations
-- under the License.
--
-- @@@ END COPYRIGHT @@@

sh regrhadoop.ksh fs -mkdir  /user/trafodion/hive/exttables/customer_ddl;
sh regrhadoop.ksh fs -mkdir  /user/trafodion/hive/exttables/customer_ddl_parquet;
sh regrhadoop.ksh fs -mkdir  /user/trafodion/hive/exttables/customer_temp_parquet;

sh regrhadoop.ksh fs -rm   /user/trafodion/hive/exttables/customer_ddl/*;
sh regrhadoop.ksh fs -rm   /user/trafodion/hive/exttables/customer_ddl_parquet/*;
sh regrhadoop.ksh fs -rm   /user/trafodion/hive/exttables/customer_temp_parquet/*;

--- setup Parquet tables
sh regrhive.ksh -v -f $REGRTSTDIR/TEST045_a.parquet.sql;

insert overwrite table hive.hive.customer_ddl
select
    c_customer_sk,
    c_customer_id,
    c_current_cdemo_sk,
    c_current_hdemo_sk,
    c_current_addr_sk,
    c_first_shipto_date_sk,
    c_first_sales_date_sk,
    c_salutation,
    c_first_name,
    c_last_name,
    c_preferred_cust_flag,
    c_birth_day,
    c_birth_month,
    c_birth_year,
    c_birth_country,
    c_login,
    c_email_address,
    c_last_review_date
from hive.hive.customer
where c_customer_sk < 25000;

log LOG045 clear;

set schema hive.hive;
set terminal_charset utf8;

cqd parquet_legacy_timestamp_format 'ON';

cqd AUTO_QUERY_RETRY_WARNINGS 'ON';
cqd HIVE_MAX_STRING_LENGTH_IN_BYTES '32' ;
cqd hist_missing_stats_warning_level '0';
cqd HIST_ROWCOUNT_REQUIRING_STATS '50000';
------------------------------------------------------------
-- Testing query plan invalidation in the compiler, but
-- not the executor. Perform DML/DDL operations on a
-- table and try re-executing the old plan as well as
-- getting a query cache hit and updating the changed
-- Hive and HDFS metadata
------------------------------------------------------------

prepare s1 from 
  select c_preferred_cust_flag,
         count(*) 
  from customer_temp_parquet
  group by 1 
  order by 1
  ;
execute s1;
-- expect 0 rows

prepare s1part from 
  select c_preferred_cust_flag,
         count(*) 
  from customer_p_parquet
  group by 1 
  order by 1
  ;
execute s1part;
-- expect 0 rows

insert into hive.hive.hivenonp_parquet
values -- partition 1,one
       (1,1,1,'one', timestamp '2001-01-01 01:23:45.678901', timestamp '2001-01-01 00:00:00'),
       (11,11,1,'one', timestamp '2001-01-01 01:23:45.678901', timestamp '2001-01-01 00:00:00'),
       -- partition 2,two
       (2,2,2,'two', timestamp '2002-02-02 02:34:56.789012', timestamp '2020-02-29 00:00:00'),
       (22,22,2,'two', timestamp '2002-02-02 00:00:00.000000', timestamp '2020-02-29 00:00:00'),
       (222,222,2,'two', timestamp '2002-02-02 02:34:56.789012', timestamp '2020-02-29 00:00:00'),
       -- partition 3,three
       (3,3,3,'three', timestamp '2003-03-03 03:45:57.890123', timestamp '2003-03-31 00:00:00'),
       -- partition 3 or partition 3,four
       (34,34,3,'four', timestamp '2004-04-04 04:56:18', timestamp '2004-04-04 00:00:00'),
       -- partition -5,five
       (-55,-55,-5,'five', timestamp '2004-04-04 04:56:18', timestamp '2005-05-05 00:00:00');
select * from hive.hive.hivenonp_parquet;

insert into hive.hive.hivepis_parquet select id, col2, p1, p2 from hive.hive.hivenonp_parquet;
insert into hive.hive.hivepts_parquet select id, col2, p1t, p2 from hive.hive.hivenonp_parquet;
insert into hive.hive.hivepi_parquet  select id, col2, p1 from hive.hive.hivepis_parquet;
insert overwrite table hive.hive.hivepi_parquet  select id, col2, p1 from hive.hive.hivepis_parquet;
-- error, insert overwrite table not allowed for partitioned tables

prepare display_rows_accessed from
select val4_txt, val4
from table(statistics(null,null))
where tdb_name like '%_SCAN %';

select * from hive.hive.hivepis_parquet;
select * from hive.hive.hivepts_parquet;
select * from hive.hive.hivepi_parquet;

control query shape cut;

-- insert some data and add one more partition
sh regrhive.ksh -v -f $REGRTSTDIR/TEST045_b.parquet.sql;

-- customer_ddl_parquet table is about 3 MB, make a plan with >= 2 ESPs
cqd HIVE_MIN_BYTES_PER_ESP_PARTITION '1000000';
cqd hive_max_string_length_in_bytes '32000';

prepare partinsert from
insert into hive.hive.customer_p_parquet
select 
    c_customer_sk,
    c_customer_id,
    c_current_cdemo_sk,
    c_current_hdemo_sk,
    c_current_addr_sk,
    c_first_shipto_date_sk,
    c_first_sales_date_sk,
    c_salutation,
    c_first_name,
    c_last_name,
    c_birth_day,
    c_birth_month,
    c_birth_year,
    c_birth_country,
    c_login,
    c_email_address,
    c_last_review_date,
    c_preferred_cust_flag
from hive.hive.customer_ddl <<+cardinality 2.5e4 >>
where c_customer_sk < 20000
      -- blank partition column values not yet supported
      and char_length(c_preferred_cust_flag) <> 0
order by c_customer_sk;

-- go back to the smaller string length
cqd HIVE_MAX_STRING_LENGTH_IN_BYTES '32' ;

-- verify that we are indeed seeing a parallel plan
select count(*)
from table(explain(null,'PARTINSERT'))
where operator = 'ESP_EXCHANGE';

explain options 'f' partinsert;

execute partinsert;

insert into customer_temp_parquet 
select * from customer 
where c_customer_sk between 20000 and 39999;

-- query cache hit, no validation at all
  select c_preferred_cust_flag,
         count(*) 
  from customer_ddl_parquet 
  group by 1 
  order by 1
  ;

-- vary query to avoid query cache hit
prepare s2 from 
  select c_preferred_cust_flag,
         count(c_customer_sk) 
  from customer_ddl_parquet 
  group by 1 
  order by 1
  ;

prepare s2part from
  select c_preferred_cust_flag,
         count(c_customer_sk) -- avoid query cache
  from customer_p_parquet 
  group by 1 
  order by 1
  ;
execute s1;
-- because we don't invalidate in the executor,
-- this should still return 0 rows

execute s2;
-- should get an NATable cache
-- hit, we should notice the change in the table
-- and return the correct result

execute s1part;
-- because we don't invalidate in the executor,
-- this should still return 0 rows

execute s2part;
-- although this should get an NATable cache
-- hit, we should notice the change in the table
-- and return the correct result

-- add duplicate rows to customer_p_parquet
insert into customer_p_parquet
select 
    c_customer_sk,
    c_customer_id,
    c_current_cdemo_sk,
    c_current_hdemo_sk,
    c_current_addr_sk,
    c_first_shipto_date_sk,
    c_first_sales_date_sk,
    c_salutation,
    c_first_name,
    c_last_name,
    c_birth_day,
    c_birth_month,
    c_birth_year,
    c_birth_country,
    c_login,
    c_email_address,
    c_last_review_date,
    c_preferred_cust_flag
from customer_ddl
where c_customer_sk between 20000 and 24999
      -- blank partition column values not yet supported
      and char_length(c_preferred_cust_flag) <> 0
order by c_customer_sk;

-- no query cache hit, but NATable cache hit
prepare s3 from 
  select count(*) 
  from customer_ddl_parquet 
  ;

-- no query cache hit, but NATable cache hit
prepare s3part from
  select c_preferred_cust_flag,
         count(c_customer_id) 
  from customer_p_parquet 
  group by 1 
  order by 1
  ;
execute s1;
-- s1 should still return 0 rows - for now
execute s2;
execute s3;
execute s1part;
-- s1 should still return 0 rows - for now
execute s2part;
execute s3part;

-- overwrite customer_p_parquet with auto-generated partitions
sh regrhive.ksh -v -f $REGRTSTDIR/TEST045_d.parquet.sql;

prepare s4 from 
  select c_preferred_cust_flag,
         count(*) 
  from customer_ddl_parquet 
  group by 1 
  order by 1
  ;
prepare s4part from
  select c_preferred_cust_flag,
         count(*) 
  from customer_p_parquet 
  group by 1 
  order by 1
  ;
execute s2;
execute s4;
execute s2part;
-- error 8442 since the files we are trying to open no longer exist
execute s4part;

-- partition elimination on PARQUET table
select * from hive.hive.hivepio_parquet where p1=2;
execute display_rows_accessed;
select * from hive.hive.hivepio_parquet where p1 in (1,3);
execute display_rows_accessed;
select * from hive.hive.hivepdo_parquet where p1d >= date '2002-12-31';
execute display_rows_accessed;

-- this pred can neither be pushed to PARQUET nor used as
-- a partition elimination predicate
select * from hive.hive.hivepio_parquet where p1=1 or col2<10;

cqd parquet_legacy_timestamp_format reset;

log;
